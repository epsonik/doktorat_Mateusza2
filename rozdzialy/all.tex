\chapter{Wstęp}
Automatyczne generowanie podpisów do obrazów jest zadaniem interdyscyplinarnym, łączącym obszary widzenia komputerowego oraz przetwarzania języka naturalnego, którego celem jest synteza zdania adekwatnego do zawartości wizualnej. Proces ten stanowi obliczeniową próbę symulacji ludzkiej zdolności do semantycznej interpretacji i opisu sceny wizualnej. Wymaga to nie tylko identyfikacji obiektów, lecz również rozpoznania ich atrybutów oraz zrozumienia ich wzajemnych relacji przestrzennych i semantycznych.

Problematyka ta posiada głębokie korzenie filozoficzne, odnoszące się do fundamentalnej relacji między obrazem a słowem. Zgodnie z teorią przedstawioną przez Ludwiga Wittgensteina, zdanie stanowi logiczny model faktu~\cite{Wittgenstein1997traktat}, w związku z czym zadanie automatycznego generowania podpisów do obrazów staje się próbą stworzenia językowego odpowiednika dla sceny wizualnej. 

Podejście do analizowanego problemu można pogłębić, traktując go w kategoriach semiotycznych, gdzie obraz jest postrzegany nie jako prosta kopia rzeczywistości, ale jako złożony system znaków wizualnych~\cite{Burzynska2006teorie}. Proces generowania podpisu staje się wówczas tłumaczeniem wizualnego systemu semiotycznego na system lingwistyczny~\cite{Eco1972Pejzaz}. Również fenomenologia dostarcza inspiracji, postulując, że patrzenie na obraz nie jest procesem pasywnym, lecz intencjonalnym aktem poznawczym~\cite{Ingarden1970Studia}. Ludzki umysł aktywnie selekcjonuje istotne elementy sceny wizualnej, a następnie syntetyzuje ich właściwości, co dla sztucznej inteligencji implikuje konieczność symulacji tego procesu.

Jednakże wyzwaniem jest zachowanie wierności znaczenia i sensu sceny na obrazie, co można opisać za pomocą analogii do koncepcji granic interpretacji~\cite{Eco2008Interpretacja}. Koncepcja ta zakłada, że dzieło – w tym przypadku obraz – samo narzuca ograniczenia co do tego, jak może być rozumiane. W tej analogii model generujący podpisy pełni rolę "czytelnika" obrazu, a jego sukces zależy od zdolności do działania w granicach wyznaczonych przez dane wizualne. Poprawnie wygenerowany podpis jest zatem formą trafnej interpretacji, podczas gdy błędy, takie jak generowanie nieistniejących obiektów, stanowią przykład nadinterpretacji. Problem badawczy tej pracy koncentruje się zatem na stworzeniu modeli zdolnych do interpretacji, a nie niekontrolowanej nadinterpretacji.

Współczesne badania nad sztuczną inteligencją są zdominowane przez nurty koneksjonistyczne i ucieleśnione (\gls{gls:embodied-ai}), które, mimo znaczących różnic, w praktyce wzajemnie się uzupełniają. Koneksjonizm naśladuje strukturę mózgu za pomocą głębokich sieci neuronowych~\cite{Lacey2002dictionary}, natomiast ucieleśniona AI zakłada, że rozwój sztucznej inteligencji wymaga, aby wchodziła ona w fizyczną interakcję ze środowiskiem~\cite{Lin2023EmbeddedAI}. Próbą matematycznej symulacji ludzkiej percepcji stał się mechanizm uwagi, który pozwala maszynie świadomie wybierać, na które fragmenty danych powinna zwrócić uwagę. Zamiast przetwarzać obraz holistycznie, model w trakcie syntezy kolejnych słów dynamicznie alokuje zasoby obliczeniowe, koncentrując się na tych regionach obrazu, które są w danym momencie najbardziej relewantne~\cite{Stefanini2021Show}. Istotnym celem rozprawy jest ocena skuteczności modeli typu koder-dekoder oraz analiza wpływu, jaki wywiera na nią rozszerzenie o mechanizm uwagi.

Podstawowym zadaniem automatycznego generowania podpisów do obrazów jest transformacja danych wizualnych -- surowej macierzy pikseli -- w semantycznie spójny podpis do obrazu. Zgodnie z funkcjonalnym podejściem do języka, inspirowanym późną filozofią Wittgensteina, proces ten można interpretować jako nadawanie obrazowi konkretnego kontekstu użycia~\cite{Biggs2021WittPictureInv}. Tworząc podpis, system zamienia pasywną reprezentację wizualną w aktywne, weryfikowalne stwierdzenie o rzeczywistości. Problematyka badawcza tej pracy koncentruje się zatem na projektowaniu i optymalizacji architektur neuronowych zdolnych do niezawodnego przeprowadzania tej transformacji.

Postęp w dziedzinie automatycznego generowania podpisów do obrazów, napędzany przez rozwój coraz bardziej zaawansowanych architektur, prowadzi do systematycznej poprawy jakości generowanych podpisów. Jednakże, wzrost skuteczności modeli jest inherentnie skorelowany z gwałtownym wzrostem ich złożoności obliczeniowej i liczby parametrów. Tworzy to istotną barierę dla praktycznych wdrożeń, szczególnie na platformach o ograniczonych zasobach. Prowadzi to do rosnącej luki między teoretycznymi możliwościami modeli a ich realną użytecznością.

Rozprawa doktorska, osadzona w przedstawionych ramach teoretycznych, ma na celu rozwój dziedziny automatycznego generowania podpisów do obrazów poprzez analizę i udoskonalenie istniejących metod. Głównym zadaniem badawczym jest optymalizacja modeli, w efekcie której rośnie wierność i trafność generowanych podpisów, przy jednoczesnym uwzględnieniu ograniczeń związanych ze złożonością obliczeniową. Znaczenie tych badań wynika z szerokiego spektrum potencjalnych zastosowań, obejmujących technologie asystujące dla osób z niepełnosprawnością wzroku, usprawnianie semantycznego wyszukiwania informacji w zbiorach wizualnych oraz budowanie bardziej intuicyjnych interfejsów człowiek-komputer. Zgodnie z technicznym obrazem świata Jean-Paula Sartre'a, działanie inżynieryjne nie jest celem samym w sobie, lecz aktem ukierunkowanym na konkretną użyteczność~\cite{Sartre1998TechniczyObraz}, co nadaje pracy głębszy wymiar humanistyczny i społeczny.


\section{Cel rozprawy}
Celem rozprawy doktorskiej jest opracowanie i weryfikacja  metod doskonalenia systemów służących do automatycznego generowania podpisów do obrazów. Postawiony cel badawczy jest realizowany poprzez maksymalizację jakości generowanych podpisów oraz optymalizację wydajności obliczeniowej modeli. W aspekcie jakościowym badania koncentrują się na maksymalizacji wartości metryk jakościowych stosowanych w zadaniu automatycznego generowania podpisów do obrazów, takich jak BLEU-1 do BLEU-4, CIDEr czy SPICE. Równolegle, w wymiarze wydajnościowym praca adresuje problem złożoności obliczeniowej. Dążenie to realizowane jest poprzez minimalizację rozmiaru modelu neuronowego, przy jednoczesnym zachowaniu jego zdolności predykcyjnych na niezdegradowanym poziomie oraz przez skrócenie czasu treningu, ewaluowanego za pomocą liczby epok niezbędnych do osiągnięcia zbieżności modelu.

Badania są realizowane dwutorowo. Pierwszy kierunek badań koncentruje się na analizie i modyfikacji architektur neuronowych typu koder-dekoder. W ramach drugiego kierunku badawczego badane są modele wzbogacone o mechanizm uwagi, gdzie każde słowo wiązane jest z konkretnym fragmentem obrazu.

\section{Hipoteza badawcza}
Główna hipoteza badawcza rozprawy zakłada, że optymalizacja komponentów składowych w ramach ugruntowanych architektur typu koder-dekoder oraz modeli z mechanizmem uwagi pozwala na osiągnięcie istotnej poprawy jakości generowanych podpisów do obrazów. Poprawa ta jest porównywalna z efektami wprowadzania fundamentalnie nowych topologii sieci. Zamiast dążyć do opracowania nowatorskich architektur, praca postuluje, że klucz do zwiększenia skuteczności leży w empirycznym doborze i precyzyjnym dostrojeniu istniejących komponentów.

W celu weryfikacji powyższego założenia, sformułowano cztery hipotezy szczegółowe. 

(H1) Wybór sieci szkieletowej w koderze wizualnym ma decydujące znaczenie dla jakości semantycznej generowanych podpisów. Nowoczesne sieci szkieletowe oparte na sieciach splotowych, takie jak Xception czy Densenet dostarczają bogatszej i bardziej relewantnej reprezentacji wizualnej niż starsze modele jak VGG. Przekłada się to bezpośrednio na wyższą trafność i szczegółowość podpisów mierzonych metrykami CIDEr i SPICE.

(H2) Metoda fuzji tekstu i obrazu oraz struktura dekodera językowego warunkują finalną skuteczność modelu. Zakłada się, że strategia łączenia cech wizualnych i tekstowych oparta na konkatenacji (\gls{gls:concatenation}) wektorów jest skuteczniejsza od ich sumowania, ponieważ zapobiega utracie informacji i pozwala modelowi na naukę bardziej złożonych interakcji.

(H3) Architektury rekurencyjne o zredukowanej złożoności, jak GRU mogą osiągnąć wyniki porównywalne z bardziej złożonymi modelami LSTM przy jednoczesnym obniżeniu kosztów obliczeniowych w przypadku generowania stosunkowo krótkich sekwencji tekstowych.

(H4) Istnieje efekt synergii pomiędzy architekturą kodera wizualnego a konfiguracją dekodera językowego. Optymalna wydajność systemu nie jest jedynie sumą wydajności jego najlepszych, odizolowanych komponentów. Istnieje specyficzna, najlepsza kombinacja sieci szkieletowej (\gls{gls:backbone-network}), modelu osadzeń słów, metody fuzji modalności oraz struktury sieci rekurencyjnej. Jej identyfikacja umożliwia maksymalizację jakości generowanych podpisów.

Weryfikacja powyższych hipotez zostanie przeprowadzona w rozdziałach eksperymentalnych począwszy od Rozdziału~\ref{rozdzial:badania_podstawowej_architektury_koder_dekoder}. Badania te obejmą systematyczne porównanie wydajności różnych konfiguracji modelu na standardowym zbiorze danych Microsoft COCO, z wykorzystaniem ugruntowanego zestawu metryk ewaluacyjnych.

\section{Zakres pracy}

Rozprawa doktorska koncentruje się na analizie, optymalizacji i weryfikacji empirycznej modeli uczenia głębokiego przeznaczonych do automatycznego generowania podpisów do obrazów. Zakres pracy obejmuje aspekty teoretyczne oraz szczegółowe badania eksperymentalne, realizowane w ramach dwóch głównych paradygmatów architektonicznych. Klasycznych modeli typu koder-dekoder oraz modeli wzbogaconych o mechanizm uwagi.

Szczegółowy zakres pracy obejmuje:
\begin{itemize}
    \item  \textbf{Przegląd literatury i podstawy teoretyczne:} Systematyzacja wiedzy dotyczącej ewolucji metod automatycznego podpisywania obrazów, od podejść kompozycyjnych po zaawansowane architektury neuronowe. Szczegółowe omówienie komponentów składowych systemów, w tym koderów wizualnych (splotowe sieci neuronowe, sieci szkieletowe), dekoderów językowych (rekurencyjne sieci neuronowe LSTM i GRU, modele osadzeń słów) oraz wariantów mechanizmu uwagi (m.in. uwaga miękka, przestrzenna, adaptacyjna, uwaga własna).
    
    \item \textbf{Metodologia badań i ewaluacji:} Charakterystyka wykorzystywanych zbiorów danych, ze szczególnym uwzględnieniem referencyjnego zbioru Microsoft COCO. Analiza i dobór metryk ewaluacji automatycznej (BLEU, ROUGE, METEOR, CIDEr, SPICE) oraz omówienie roli oceny ludzkiej w weryfikacji jakości semantycznej i lingwistycznej generowanych podpisów.
    \item \textbf{Badania podstawowej architektury koder-dekoder:} Empiryczna weryfikacja wpływu doboru komponentów składowych na jakość generowanych podpisów i złożoność obliczeniową modelu. Zakres badań obejmuje analizę porównawczą różnych sieci szkieletowych (m.in. VGG, ResNet, DenseNet, Xception), metod fuzji modalności (wstrzykiwanie wstępne, fuzja przez dodawanie i konkatenację) oraz struktur dekodera językowego (LSTM, GRU) i modeli osadzeń (GloVe, FastText).
    \item \textbf{Badania modeli z mechanizmem uwagi:} Analiza i implementacja zaawansowanych mechanizmów uwagi w architekturach koder-dekoder. Weryfikacja skuteczności modeli wykorzystujących uwagę przestrzenną, adaptacyjną oraz hybrydowych mechanizmów uwagi własnej w kontekście poprawy trafności i szczegółowości generowanych podpisów. 
    
    \item \textbf{Analiza porównawcza i walidacja:} Systematyczne porównanie wydajności opracowanych modeli w oparciu o zdefiniowane metryki jakościowe i wydajnościowe. Analiza jakościowa generowanych podpisów, w tym kategoryzacja błędów (np. halucynacje obiektów, błędy w liczeniu) oraz ocena zdolności do generalizacji na danych spoza dystrybucji treningowej.
\end{itemize}
Praca ogranicza się do analizy obrazów statycznych i generowania podpisów w formie pojedynczych zdań denotatywnych. Poza zakresem badań pozostają zagadnienia generowania opisów wideo, generowania podpisów narracyjnych oraz optymalizacja modeli z wykorzystaniem metod uczenia ze wzmocnieniem.

\section{Struktura pracy}
Rozprawa składa się z siedmiu rozdziałów, uzupełnionych o bibliografię oraz wykaz stosowanych skrótów i symboli.

Rozdział 1 stanowi wprowadzenie do problematyki automatycznego generowania podpisów do obrazów. Przedstawiono w nim tło teoretyczne i motywację badawczą. Sformułowano cel pracy, skoncentrowany na optymalizacji jakościowej i wydajnościowej modeli, postawiono hipotezy badawcze dotyczące doskonalenia istniejących architektur oraz określono zakres pracy.

Rozdział 2 zawiera systematyczny przegląd literatury przedmiotu. Dokonano analizy ewolucji metod, począwszy od podejść kompozycyjnych, poprzez paradygmat koder-dekoder, aż po modele wykorzystujące mechanizm uwagi i architekturę transformatorową. Rozdział kończy identyfikacja luki badawczej.

Rozdział 3 przedstawia podstawy teoretyczne i komponenty składowe systemów do automatycznego generowania podpisów. Szczegółowo omówiono koder wizualny w tym sieci szkieletowe oraz dekoder językowy, gdzie omówiono metody reprezentacji słów i sieci rekurencyjne. Przedstawiono strategie integracji danych multimodalnych i warianty mechanizmu uwagi.

Rozdział 4 poświęcony jest metodyce ewaluacji i charakterystyce wykorzystywanych zbiorów danych. Dokonano przeglądu referencyjnych zbiorów danych oraz krytycznej analizy automatycznych metryk oceny jakości podpisów maszynowych (m.in. BLEU, CIDEr, SPICE). Omówiono również rolę oceny ludzkiej oraz teoretyczną analizę wyzwań związanych z językami fleksyjnymi, na przykładzie języka polskiego.

Rozdział 5 rozpoczyna część eksperymentalną, realizując pierwszy kierunek badawczy. Prezentuje wyniki badań nad optymalizacją podstawowej architektury koder-dekoder. Przeanalizowano wpływ doboru komponentów (sieci szkieletowe, osadzenia słów, typ sieci RNN – LSTM i GRU) oraz strategii integracji modalności (fuzja i wstrzykiwanie wstępne) na skuteczność i wydajność obliczeniową modelu.

Rozdział 6 realizuje drugi kierunek badawczy. Zawiera wyniki badań nad modelami koder-dekoder wzbogaconymi o mechanizm uwagi. Skoncentrowano się na analizie empirycznej i optymalizacji synergii między komponentem wizualnym a językowym w celu poprawy trafności semantycznej generowanych podpisów.

Rozdział 7 stanowi podsumowanie rozprawy. Zawiera syntezę uzyskanych wyników, weryfikację postawionych hipotez badawczych, wnioski końcowe oraz wskazanie kierunków dalszych badań.
\chapter{Przegląd literatury}
Nadrzędnym celem automatycznego generowania podpisów do obrazów jest stworzenie systemu zdolnego do wygenerowania trafnego i płynnego podpisu dla danej sceny wizualnej. Wymaga to pokonania tzw. luki semantycznej -- rozbieżności między niskopoziomową, numeryczną reprezentacją obrazu w postaci pikseli a wysokopoziomową, symboliczną strukturą języka naturalnego.

Realizacja tego celu napotyka na szereg  wyzwań. Podstawową trudnością jest inherentna subiektywność i wieloznaczność interpretacji wizualnej, gdzie identyfikacja istotnych elementów sceny może mieć wiele wariantów. System musi zatem radzić sobie z tą wieloznacznością, generując podpisy uwzględniające najbardziej prawdopodobne interpretacje. Ponadto, specyfika zastosowania często wymaga dostosowania stylu i kontekstu podpisów -- podpis do obrazu w encyklopedii będzie się różnił od podpisu tego samego obrazu w mediach społecznościowych. Wyzwaniem jest więc generowanie podpisów, które są nie tylko gramatycznie poprawne, ale także precyzyjne, zwięzłe i adekwatne do treści obrazu, przy jednoczesnym zachowaniu spójności językowej oraz przyjemnego w odbiorze stylu.

W ramach analizy metod automatycznego generowania podpisów do obrazów można wyróżnić różnorodne formaty narracyjne, począwszy od rozbudowanych akapitów, poprzez enumeratywne listy szczegółowo opisujące poszczególne elementy obrazu, aż po zwięzłe zdania podsumowujące cały obraz. W pracy skoncentrowano się na modelach generujących pojedyncze zdanie, które stanowi syntetyczny opis zawartości obrazu. Systemy te będą określane mianem "systemów automatycznego podpisywania obrazów", a "podpisem" generowane przez nie zdanie. Tym samym produktem wyjściowym działania systemu będzie "podpis automatyczny", stanowiący sedno treści wizualnej. 

Przyjęta metodologia formułowania podpisów opierała się na czterech zasadach. Nadrzędnym wymogiem była wierność deskryptywna, definiowana jako precyzyjne odzwierciedlenie obserwowalnych elementów, takich jak obiekty, ich atrybuty, relacje przestrzenne i akcje. Zasada ta została dopełniona poprzez wymóg obiektywizmu, który wyklucza wszelkie subiektywne oceny, interpretacje, nacechowanie emocjonalne oraz wnioskowanie wykraczające poza bezpośredni materiał wizualny. Ponadto, każdy podpis musiał charakteryzować się zwięzłością i ograniczać się jedynie do informacji niezbędnych do zrozumienia przedstawionej sytuacji. Finalnie, każdy podpis musiał spełniać formalne standardy poprawności językowej, takie jak poprawność gramatyczna i językowa.

Rozdział przedstawia systematyczny przegląd literatury, śledząc ewolucję metod automatycznego podpisywania obrazów. Rozpoczyna się od analizy wczesnych podejść kompozycyjnych, by następnie przejść do omówienia paradygmatu koder--dekoder, który zdominował erę głębokiego uczenia. W dalszej części szczegółowo opisano mechanizm uwagi oraz modele oparte na architekturze transformatora. Rozdział zamyka prezentacja alternatywnych kierunków badawczych oraz podsumowanie, które identyfikuje lukę badawczą adresowaną w rozprawie.

\section{Metody kompozycyjne}
Wczesne systemy automatycznego generowania podpisów do obrazów konstruowały podpisy na podstawie predefiniowanych reguł lub wzorców, wykorzystując w tym celu uprzednio zidentyfikowane na obrazie obiekty i inne istotne komponenty wizualne. Mimo iż podejścia te cechowały się niską elastycznością oraz ograniczoną zdolnością do adaptacji w nowych kontekstach, ich wkład w postęp badań nad automatycznym generowaniem podpisów do obrazów jest niezaprzeczalny. W tej grupie można wyróżnić metody oparte na szablonach oraz metody oparte na wyszukiwaniu~\cite{Bai2018Survey}.

Metody oparte na szablonach opierały się na gotowych szablonach budowy zdań, gdzie puste miejsca uzupełniane były rezultatami analizy treści obrazu. W podejściu tym sztywno zdefiniowany szablon determinuje składnię zdania, podczas gdy zadaniem algorytmów jest jedynie dostarczenie odpowiednich informacji do wstawienia w luki. Przykładowo, struktura szablonu może przyjąć formę:
"Na obrazie widzimy [ilość] [kategoria obiektu] podczas [czynność]".

Proces generowania podpisu rozpoczyna się od detekcji obiektów, wraz z określającymi je atrybutami. Następnie, dla każdego obiektu, w zależności od zastosowanej metody, pozyskiwane są istotne informacje, takie jak kolor, rozmiar, kształt, kategoria oraz relacje przestrzenne z innymi obiektami. Kolejnym krokiem jest selekcja najbardziej odpowiedniego szablonu z predefiniowanego zbioru, oparta na kryteriach takich jak liczba wykrytych obiektów, ich typy oraz ogólna charakterystyka obrazu. W ostatniej fazie szablon jest uzupełniany zidentyfikowanymi obiektami i ich atrybutami. W efekcie powstaje pełne zdanie opisujące zawartość obrazu. 

W pracy~\cite{Yang2011Corpus} zaproponowano metodę wykorzystującą szablon o stałej strukturze składniowej: [rzeczownik, czasownik, scena, przyimek]. W celu jego wypełnienia, detektor identyfikuje obiekty (rzeczownik), a deskryptor GIST~\cite{Torralba2003Vi} określa typ sceny. Następnie, służą one do wypełnienia pozycji rzeczownika i sceny w szablonie. Na podstawie tych informacji model językowy Gigaword~\cite{Graff2003Gigaword} generuje zbiór pasujących czasowników i przyimków, tworząc w ten sposób zestaw zdań kandydujących. Z tego zbioru za pomocą Ukrytych Modeli Markowa~\cite{Payandeh2023DeepRepresentationLearning} selekcjonowany jest finalny podpis poprzez wybór najbardziej prawdopodobnej sekwencji słów.

Z kolei w podejściu przedstawionym w pracy~\cite{Kulkarni2011SimpleImgDesc} scenę wizualną zamodelowano za pomocą struktury grafowej, gdzie węzły reprezentują obiekty, ich atrybuty oraz wzajemne relacje przestrzenne. Do wnioskowania o najbardziej prawdopodobnej konfiguracji tego grafu dla danego obrazu zastosowano warunkowe pola losowe (conditional random fields, CRF)~\cite{Sutton2012CRF}.  Wydedukowane w ten sposób najważniejsze komponenty sceny są następnie wstawiane w odpowiednie miejsca predefiniowanego szablonu, tworząc finalny podpis.

Działanie metody~\cite{Ushiku2015Common} polega na stworzeniu wspólnej przestrzeni multimodalnej (\gls{gls:multimodal}), w której fragmenty obrazów i odpowiadające im semantycznie frazy tekstowe są umieszczane blisko siebie. Zamiast generować zdanie słowo po słowie, model ten wykorzystuje tę przestrzeń do wyszukiwania dla danego obrazu całych, bogatych w znaczenie fraz. Taka struktura pozwala na współdzielenie kontekstu semantycznego między frazami, co sprawia, że generowane podpisy są bardziej naturalne i zbliżone do ludzkich. Ostateczne zdanie jest konstruowane z najlepiej dopasowanych fraz przy użyciu algorytmu przeszukiwania wiązkowego (beam search)~\cite{Ushiku2012Efficient}.

Ograniczenia sztywnych szablonów zmotywowały rozwój metod bardziej elastycznych, które konstruowały zdania w sposób kompozycyjny lub z wykorzystaniem struktur gramatycznych. W pracy~\cite{Mitchel2012} zaproponowano dwuetapowy proces, oddzielający ekstrakcję treści wizualnej od generowania warstwy językowej. W pierwszym kroku obraz jest przekształcany w zbiór słów kluczowych opisujących obiekty, akcje i relacje. Istotnym elementem tej metody jest faza druga, w której ten zbiór jest filtrowany z użyciem statystyk współwystępowania słów w celu eliminacji semantycznie niespójnych kombinacji. Dopiero z tak oczyszczonych danych trójgramowy model językowy Europarl~\cite{Koehn2005Europarl} generuje płynne i gramatycznie poprawne zdanie końcowe.

W pracach~\cite{Elliott2013Image, Elliott2015Describing} wprowadzono wizualną reprezentację zależności \gls{VDR} – strukturę kodującą relacje przestrzenne między obiektami a regionami obrazu. Do jej konstruowania zdefiniowano wizualną gramatykę zależności, na podstawie której opracowano dwa modele generujące podpisy z wykorzystaniem szablonów. W dalszym rozwoju tej koncepcji zautomatyzowano proces budowy \gls{VDR}, aby naśladował ludzki sposób podpisywania obrazów , wykorzystując w tym celu detektor obiektów oraz zbiór wzorcowych podpisów.

Odmienną strategię przyjęto w metodach opartych na wyszukiwaniu~\cite{Bai2018Survey}. Paradygmat ten zakłada, że w obszernej bazie danych obrazów z podpisami można odnaleźć przykłady wizualnie podobne do obrazu wejściowego, a ich istniejące podpisy wykorzystać do sformułowania nowego.

Proces rozpoczynał się od ekstrakcji z obrazu wejściowego globalnych deskryptorów wizualnych, takich jak \gls{HOG} oraz \gls{SIFT}~\cite{Lowe2004SIFT}. Opisują one ogólną zawartość obrazu, uwzględniając informacje o kolorach, kształtach, teksturach czy obiektach i ich konturach. Należy podkreślić, że były to cechy projektowane ręcznie, w odróżnieniu od reprezentacji uczonych automatycznie w późniejszych modelach neuronowych. 

W kolejnym kroku uzyskane deskryptory wykorzystywano do indeksowania obrazów w bazie danych, co umożliwia jej efektywne przeszukiwanie. Dla zadanego obrazu wejściowego system znajdował obrazy o najbardziej zbliżonych wektorach cech, gdzie podobieństwo kwantyfikowano za pomocą miar odległości takich jak odległość euklidesowa lub kosinusowa. Finalny podpis był konstruowany poprzez transfer najbardziej dopasowanego podpisu, fuzję kilku z nich lub ich adaptację do nowego kontekstu.

Jedną z pierwszych prac w tym nurcie była publikacja~\cite{Farhadi2010} w której autorzy zaproponowali mapowanie obrazu na wspólną, trójelementową przestrzeń semantyczną [obiekt, akcja, scena]. Tego typu reprezentacja była uzyskiwana za pomocą losowych pól Markova~\gls{MRF}~\cite{Li1994MarkovMRFinCV}. Wygenerowany w ten sposób wektor semantyczny służył do wyszukania w bazie dostępnych podpisów zdania najbardziej pasującego, gdzie jako miarę podobieństwa zastosowano~\cite{Lin1998AnID}.

Inne podejście, zaprezentowane w pracy~\cite{Ordonez2011Im2Text}, bazowało na wieloaspektowym wyszukiwaniu podobieństwa. Obrazy, charakteryzowane za pomocą deskryptorów GIST, porównywano pod względem czterech kryteriów: kształtu obiektów, ich atrybutów, akcji oraz typu sceny. Dla każdego z nich tworzono odrębne rankingi podobieństwa, które następnie agregowano w jeden wynik końcowy. Do agregacji wykorzystywano model regresji liniowej oraz maszyny wektorów nośnych (\gls{SVM}), optymalizowaną względem metryki BLEU.

Rozwinięciem tej koncepcji była metodologia opisana w pracy~\cite{Kuznetsova2012Collective}. Zamiast tworzyć jeden globalny ranking, autorzy zastosowali strategię wyszukiwania podobnych obrazów dla każdej pojedynczej encji (np. obiektu, atrybutu) wykrytej w obrazie wejściowym. W rezultacie powstawał zbiór fraz odpowiadających poszczególnym elementom sceny. Finalny podpis generowano z odfiltrowanego zbioru najbardziej adekwatnych fraz. W późniejszych badaniach rozwiązanie to zostało udoskonalone poprzez wprowadzenie hierarchicznej, drzewiastej reprezentacji zdań.

W podobnym duchu, w pracy~\cite{Gupta2012Choosing} z podpisów przypisanych do podobnych obrazów wyodrębniano frazy, które następnie szeregowano i transformowano do ustrukturyzowanych, trójelementowych form gramatycznych. Finalny podpis generowano z trzech najwyżej ocenionych struktur.

Istotnym postępem było opracowanie metod opartych na tworzeniu wspólnej, multimodalnej przestrzeni osadzeń, w której zarówno obrazy, jak i ich podpisy są reprezentowane jako wektory. W metodzie~\cite{Hodosh2013Senetence} wspólną przestrzeń konstruowano za pomocą metody \gls{KCAA}~\cite{Bach2003Kernel} i optymalizowano algorytmem RankSVM~\cite{Joachim2002Optimizing}. W tak zbudowanej przestrzeni zdania szeregowano na podstawie podobieństwa kosinusowego między wektorami cech obrazów a wektorami cech podpisów.

W podejściu~\cite{Socher2014Grounded} podpisy ze zbioru treningowego były parsowane na drzewa zależności z wykorzystaniem narzędzia Stanford Parser~\cite{Etal2006generating}, a cechy obrazów służące do wyszukiwania pochodziły z modelu Imagenet~\cite{Szegedy2014Going}. Z kolei w pracy~\cite{KirosSZ2014Unifying} trenowano wspólną przestrzeń osadzeń obraz--zdanie, która odzwierciedlała regularności językowe. Co istotne, strukturalne elementy zdania, takie jak znaczniki części mowy, były oddzielone od jego treści i nie były trenowane równolegle z przestrzenią osadzeń, celem redukcji szumu semantycznego. Dzięki tak zdefiniowanej przestrzeni osadzeń możliwe stało się wykonywanie operacji arytmetycznych na wektorach reprezentujących obrazy i zdania, a w efekcie wyszukiwanie semantycznie podobnych obrazów. 

Innym przykładem była praca~\cite{Mason2014nonparametric}, gdzie podpisy konstruowano na podstawie częstości słów w podpisach do obrazów podobnych do zadanego. Celem było zminimalizowanie błędu estymacji wizualnej poprzez statystyczną agregację najczęściej występujących terminów.

Zarówno metody oparte na szablonach, jak i na wyszukiwaniu, wykazywały fundamentalne ograniczenia. Ich skuteczność była ściśle uzależniona od zakresu i jakości korpusu istniejących podpisów. Prowadziło to do generowania podpisów, które były jedynie rekompozycją gotowych konstrukcji składniowych zaczerpniętych z istniejących zbiorów danych, a nie autentycznym podpisem do obrazu. Taka zależność skutkowała generowaniem podpisów często nieadekwatnych do analizowanej sceny wizualnej, szczególnie w sytuacjach, gdy scena zawierała elementy nietypowe lub rzadko spotykane w dostępnych zbiorach danych. 
 
\section{Podstawowe modele neuronowe do automatycznego podpisywania obrazów}
Ograniczenia metod kompozycyjnych skłoniły badaczy do poszukiwania rozwiązań, w których model uczy się mapowania z domeny wizualnej do językowej w ramach jednej, zintegrowanej sieci neuronowej. W tym celu zaadaptowano z dziedziny tłumaczenia maszynowego architekturę koder-dekoder. Podejście to stało się fundamentem dla dominującej większości nowoczesnych systemów automatycznego generowania podpisów do obrazów.

Architektura koder-dekoder składa się z dwóch komplementarnych komponentów. Zadaniem kodera jest przetworzenie danych wejściowych – w tym przypadku obrazu – na wektorową reprezentację o stałej długości, zwaną wektorem kontekstu. Jest to skondensowana informacja semantyczna o obrazie. Następnie dekoder, będący rekurencyjnym modelem językowym, generuje sekwencyjnie podpis, warunkując każde kolejne słowo na wektorze kontekstu oraz słowach wygenerowanych w poprzednich krokach.

W typowej implementacji rolę kodera pełnią głębokie splotowe sieci neuronowe, wstępnie wytrenowane na wielkoskalowych zbiorach danych do zadania klasyfikacji obrazów. Funkcję dekodera najczęściej realizują rekurencyjne sieci neuronowe~\gls{RNN}, zwłaszcza warianty o rozszerzonej pamięci, takie jak~\gls{LSTM}~\cite{Hochreiter1997LSTM} czy \gls{GRU}~\cite{Cho2014Properties} (opisane szczegółowo w Sekcji~\ref{sekcja:sieci-rekurencyjne}). Ich zdolność do modelowania długoterminowych zależności w danych sekwencyjnych umożliwiała generowanie spójnych i gramatycznie poprawnych zdań.

Kierunek rozwoju tej architektury wyznaczył kanoniczny model~\cite{Vinyals2015Show}, który jako jeden z pierwszych zademonstrował jej skuteczność. Wczesne badania koncentrowały się głównie na ewolucji komponentu kodera, badając zastosowanie różnych ekstraktorów cech, takich jak VGG~\cite{Chen2015Minds, Mao2014DeepCW}, Googlenet~\cite{Wu2016WhatValue, You2016Semantic}, a w późniejszym okresie bardziej zaawansowanych architektur, jak Resnet~\cite{Rennie2017SelfCriticalST, Yao2017ICCV} czy Oxfordnet~\cite{Jia2015Guiding}. W podejściach tych globalny wektor cech pozyskiwano z aktywacji jednej z ostatnich warstw w pełni połączonych sieci, co dostarczało bogatej semantycznie, syntetycznej reprezentacji całej sceny wizualnej.

Równolegle eksplorowano alternatywne strategie modyfikujące przepływ informacji. Prace takie jak~\cite{Mao2014DeepCW} skupiały się na mapowaniu cech wizualnych i reprezentacji słów do wspólnej przestrzeni multimodalnej. Inne, jak~\cite{Gan2017Semantic, Yao2017ICCV}, zamiast globalnej reprezentacji, wykorzystywały detekcję obiektów lub tagów semantycznych jako wejście dla dekodera LSTM. Pojawiły się również podejścia dwuetapowe, gdzie najpierw identyfikowano kluczowe atrybuty obrazu, a dopiero w drugim kroku model językowy używał ich do generowania podpisu~\cite{Wu2016WhatValue}.

Z kolei w pracy~\cite{Chen2015Minds} zaproponowano integrację sieci RNN z dodatkową warstwą ukrytą, która rekonstruowała cechy wizualne na podstawie generowanych słów. Dzięki temu model mógł uwzględniać długoterminowe zależności wizualne poprzez porównywanie wewnętrznej reprezentacji obrazu z jego rzeczywistymi cechami. 

Mimo wysokiej skuteczności, podstawowa architektura koder--dekoder narzuca fundamentalne ograniczenia. Dekoder na wejściu przyjmuje wektor kontekstu, który jest wektorem cech z ostatniej warstwy sieci szkieletowej. Cechy te są syntetyczną informacją semantyczną ze wszystkich warstw sieci szkieletowej. Podejście to narzuca fundamentalne ograniczenie, gdyż synteza wszystkich warstw sieci szkieletowej do jednego, statycznego wektora prowadzi do utraty istotnych detali z płytszych warstw sieci szkieletowej. Jednakże efektywne wykorzystanie tych złożonych, skomplikowanych reprezentacji wymagało rozwiązania do efektywnego przetwarzania takiej ilości danych. Odpowiedzią stał się mechanizm uwagi, który umożliwia efektywne przetwarzanie całej mapy cech obrazu.

\section{Wprowadzenie i rozwój mechanizmu uwagi}
Mechanizm uwagi zastąpił statyczny wektor kontekstu wizualnego wektorem, który jest obliczany na nowo dla każdego generowanego słowa w zdaniu wyjściowym. W każdym kroku dekodowania model uczy się alokować wagi uwagi dla poszczególnych fragmentów całej mapy cech. Wagi te kwantyfikują stopień istotności danego fragmentu obrazu dla predykcji bieżącego słowa. Ostateczny wektor kontekstu, przekazywany do dekodera, jest zatem ważonym zbiorem wejściowych cech obrazu. Pozwala to na wzmocnienie istotności jedynie tych cech obrazu, które są istotne dla aktualnie generowanego słowa, ograniczając tym samym szum globalnego kontekstu sceny wizualnej.

Pierwsze implementacje mechanizmu uwagi w zadaniu automatycznego generowania podpisów do obrazów opierały się na architekturze odgórnej (top--down), wywodzącej się z prac nad tłumaczeniem maszynowym~\cite{Bahdanau2015NeuralMT}. W tym paradygmacie stan ukryty dekodera RNN w danym kroku czasowym pełni funkcję zapytania. Na jego podstawie obliczane są wagi dla zbioru wektorów cech wizualnych, które stanowią regularną siatkę przestrzenną pochodzącą z jednej z ostatnich warstw sieci szkieletowej. Ważona suma tych wektorów tworzy wektor kontekstu, który jest następnie wykorzystywany przez dekoder do predykcji kolejnego słowa w sekwencji.

Praca~\cite{Xu2015ShowAttendTell} zaadaptowała i rozwinęła tę koncepcję, wprowadzając dwa kontrastujące ze sobą warianty uwagi. Deterministyczna uwaga miękka (soft attention) agreguje informacje z całej sceny wizualnej, konstruując wektor kontekstu jako ważoną sumę wszystkich cech. Wiąże się to jednak ze znacznym kosztem obliczeniowym. W przeciwieństwie do niej, uwaga twarda (hard attention) w każdym kroku czasowym wybiera tylko jeden fragment siatki cech, co czyni ją znacznie bardziej efektywną pod względem obliczeniowym. Pomimo wyższych wymagań obliczeniowych, uwaga miękka, dzięki swojej zdolności do agregacji informacji z całej sceny, stała się punktem wyjścia dla dalszych badań.

Ważnym kierunkiem rozwoju stało się wzbogacanie wejściowej reprezentacji wizualnej o dodatkowe informacje z zewnętrznych źródeł. W pracy~\cite{Tavalkoyi2017PayingAttentionIstotneRegiony} autorzy wykorzystali w tym celu predykcje z wyspecjalizowanych modeli istotności wizualnej~\cite{HUANG2006489, RTAVAKOLI201710}. Celem integracji tego typu wektorów było dostarczenie modelowi bardziej granularnych i semantycznie bogatych informacji, co miało przełożyć się na wzrost jego skuteczności. Jeszcze inną strategią było agregowanie reprezentacji z wielu heterogenicznych architektur sieci szkieletowych, jak Resnet~\cite{He2015Deep}, InceptionV3~\cite{Szegedy2016RethinkingTI}, Densenet~\cite{huang2017densely} oraz Inception-ResnetV2~\cite{Szegedy2017InceptionV4} w celu uzyskania bardziej kompletnego i zróżnicowanego podpisu do sceny wizualnej~\cite{Jiang2018RecurrentFusion}. 

Równoległym nurtem badań była próba integracji danych o ludzkiej percepcji. Wykazano bowiem, że informacja o tym, na jakich obszarach obrazu ludzie skupiają wzrok, może znacząco poprawić jakość i trafność podpisów. W pracy~\cite{Sugano2016SeeingW} zaproponowano wykorzystanie znormalizowanych histogramów skupienia wzroku jako dodatkowego sygnału dla modelu. Histogramy te, kodujące przestrzenny rozkład ludzkiej uwagi, były scalane z cechami obrazu i tekstu. Dzięki temu generowane podpisy lepiej odwzorowywały ludzki sposób postrzegania i priorytetyzacji informacji wizualnej.

Ostatnią z istotnych modyfikacji było udoskonalenie samego procesu iteracyjnego w pętli dekodera. Zamiast jednokrotnego obliczania wektora kontekstu w każdym kroku, w pracy~\cite{Yang2016} zaproponowano architekturę z dodatkową, rekurencyjną siecią recenzującą. Sieć ta, we współpracy z mechanizmem uwagi, iteracyjnie udoskonalała stany ukryte dekodera, generując udoskonalony wektor kontekstu, który służył jako wejście dla modułu uwagi w kolejnej iteracji. Takie podejście pozwalało na bardziej precyzyjne i kontekstowe skupianie uwagi w miarę postępów generowania zdania.


Ograniczeniem uwagi odgórnej, operującej na regularnej siatce cech, jest arbitralny i niezależny od treści obrazu charakter tego rodzaju podziału przestrzennego. W konsekwencji kolejny etap ewolucji mechanizmu uwagi polegał na zastąpieniu sztywnej siatki cech elastycznym zbiorem semantycznie istotnych regionów obrazu. Podejście to, określane mianem uwagi oddolnej, wprowadza wstępny, sterowany danymi etap, którego celem jest identyfikacja wyróżniających się obiektów i ich atrybutów w scenie wizualnej.

Nowatorską pracą w tym nurcie jest model zaproponowany w~\cite{Anderson2018BottomUpAT}, który skutecznie łączy mechanizmy uwagi oddolnej i odgórnej. W pierwszym, oddolnym (bottom-up) etapie, który jest sterowany wyłącznie danymi wejściowymi, detektor obiektów Faster R-CNN~\cite{Ren2015Faster} identyfikuje w obrazie zbiór propozycji regionów o wysokim znaczeniu semantycznym. Każdy region jest reprezentowany przez dedykowany wektor cech. Dopiero w drugim, odgórnym (top-down) etapie, mechanizm uwagi, sterowany kontekstem z dekodera, oblicza rozkład wag dla tak przygotowanego zbioru wektorów. W ten sposób uwaga nie jest rozpraszana na mało istotne tło, lecz od początku operuje na bogatych semantycznie reprezentacjach. Przełożyło się to na wzrost precyzji i szczegółowości generowanych podpisów, ustanawiając nowy standard w tej dziedzinie.

Paradygmat ten stał się podstawą dla licznych dalszych badań, które koncentrowały się na udoskonaleniu interakcji między regionami a procesem dekodowania. Przykładowo, model~\cite{Anderson2018BottomUpAT} kierował uwagę na jeden nowy region w każdym kroku generowania słowa. W odpowiedzi na to ograniczenie, autorzy pracy~\cite{Huang2019adaptively} zaproponowali adaptacyjny moduł uwagi, który w każdym kroku decyduje, czy skierować uwagę na kolejny region, czy też wygenerować kolejne słowo na podstawie dotychczasowego kontekstu. Umożliwiło to opisanie jednego regionu wieloma słowami. Rola i skuteczność wykorzystania regionów jako podstawowych jednostek dla mechanizmu uwagi zostały potwierdzone w późniejszych pracach, takich jak~\cite{Quin2019LookBackRegions, Ke2019ReflectiveRegions, Wang2020ShowRecallRegions}.

Dotychczas omówione mechanizmy uwagi modelowały relacje między dekoderem a zbiorem cech wizualnych. Uwaga własna, wprowadzona w pracy~\cite{Vaswani2017AttentionIA} modeluje interakcje wewnątrz pojedynczego zbioru reprezentacji. Zgodnie z tym założeniem każdy element sekwencji wejściowej określa swoją nową reprezentację, uwzględniając wszystkie pozostałe elementy. Model uczy się oceniać wzajemne dopasowanie między każdą parą elementów, na podstawie czego tworzy wagi uwagi. Wagi te określają, jak ważny jest każdy inny element dla zrozumienia tego bieżącego. Ostatecznie, nowa, wzbogacona o kontekst reprezentacja każdego elementu powstaje jako ważona kombinacja informacji od wszystkich elementów w sekwencji.

Początkowe zastosowania uwagi własnej w generowaniu podpisów do obrazów koncentrowały się na jednoczesnym modelowaniu relacji wizualnych i semantycznych. Przykładowo, architektura~\cite{Li2019Entangled} rozdzielała analizę wizualną, w ramach której uwaga własna bada relacje między regionami, od analizy semantycznej, polegającej na identyfikacji zależności między kategoriami obiektów. Podobne podejście zaprezentowano w pracy \cite{Yang2019Collate}, gdzie uwaga własna posłużyła do modelowania interakcji między parami obiektów, co wzbogaciło reprezentację obiektów przed ich przetworzeniem przez dekoder. 

Istotnym ograniczeniem wczesnych modeli była jednak ignorancja relacji przestrzennych między obiektami. W odpowiedzi na ten problem, w pracy \cite{Herdade2019Image} zaproponowano moduł relacji geometrycznych, który koryguje wagi uwagi, dodając do nich składnik oparty na cechach geometrycznych ramek ograniczających obiekty. W modelu znormalizowanej uwagi \cite{Guo2020Normalized} posunięto się o krok dalej, definiując finalne wagi jako wypadkową zarówno podobieństwa wizualnego, jak i względnego położenia geometrycznego par obiektów.

Standardowe modele uwagi analizują głównie bezpośrednie zależności między parami elementów, aby modelować bardziej złożone relacje, autorzy~\cite{Pan2020XLinear} zaproponowali architekturę łączącą uwagę własną z metodą redukcji dwuliniowej (\gls{gls:bilinear-pooling}). Pozwoliło to na modelowanie, jak dany fragment obrazu wpływa na interakcje między innymi. Dążenie do kodowania wielopoziomowych zależności było również motywacją prac \cite{Cornia2020Meshed, Cornia2020SMART}, w których standardowy mechanizm uwagi rozszerzono o zewnętrzny zbiór uczących się wektorów pamięci, służących do kodowania i przechowywania globalnych zależności między obiektami.

Fundamentalnym wyzwaniem w mechanizmach uwagi własnej pozostaje ich złożoność obliczeniowa $O(n^2)$ oraz tendencja do generowania gęstych macierzy uwagi, w których wiele wag jest bliskich zeru, lecz niezerowych, co może rozpraszać uwagę modelu. W celu przeciwdziałania temu zjawisku, w pracy \cite{Jiang2021Multigate} zastosowano mechanizm bramek, który maskuje wagi uwagi poniżej wyznaczanego progu. Metoda ta zachowuje istotne elementy obrazu, skupiając uwagę jedynie na kluczowych informacjach.  


Równolegle do ewolucji głównych paradygmatów uwagi rozwijano szereg mechanizmów pomocniczych, mających na celu udoskonalenie procesu generowania podpisów. Jednym z wyzwań było generowanie słów o charakterze funkcjonalnym, jak spójniki, przyimki, które nie mają bezpośredniego odzwierciedlenia w obrazie. W odpowiedzi na ten problem w pracy \cite{Lu2017KnowingWT} zaproponowano koncepcję strażnika wizualnego. Jest to mechanizm bramkujący, który decyduje, czy w danym kroku predykcja dekodera powinna być warunkowana kontekstem wizualnym, czy też wyłącznie informacjami z już wygenerowanej sekwencji słów. Koncepcję tę rozwijano w wielu kierunkach. Jednym z nich było uzależnienie decyzji bramki od dodatkowych, zewnętrznych sygnałów, takich jak predefiniowane szablony zdań \cite{Lu2018NeuralBTTemplates} lub wyróżnione regiony obrazu \cite{Cornia2019ShowCASterowanie}. Inne podejście koncentrowało się na bezpośrednim sterowaniu przepływem informacji wizualnej, gdzie mechanizm strażnika dynamicznie aktywował lub dezaktywował cechy obrazu na wejściu do dekodera \cite{Deng2020DensenetAdaptive}.

Innym kierunkiem badań było zwiększenie zdolności ekspresji samego dekodera poprzez zastosowanie architektur wielowarstwowych. Podejście to opiera się na założeniu, że ułożenie kilku warstw rekurencyjnych w stos \cite{Gao2019Deliberate} pozwala na naukę hierarchicznych reprezentacji lingwistycznych. Niższe warstwy mogą modelować zależności składniowe, podczas gdy wyższe – abstrakcyjne relacje semantyczne. Głębszy model językowy jest w stanie formułować bardziej precyzyjne zapytania do mechanizmu uwagi, co przekłada się na poprawę jakości generowanych podpisów. Implementacje tego podejścia przybierały różne formy, od prostych, dwuwarstwowych architektur typu LRCN \cite{Donahue2017LongTerm}, przez moduły uwagi refleksyjnej modelujące relacje wewnątrz zdania \cite{Ke2019Reflective}, aż po rozdzielenie strumieni przetwarzania dla cech wizualnych i językowych w osobnych modułach LSTM w celu ich lepszej integracji \cite{Wang2019Hierarchical}.

Naturalną konsekwencją rozwoju obu tych nurtów stało się ich połączenie w architekturach hybrydowych. Przykładem jest model z pracy \cite{Gao2019Deliberate}, który integruje wielowarstwowy dekoder z zaawansowanym mechanizmem uwagi. Architektura ta realizuje dwuetapowe udoskonalanie wag uwagi. Pierwsza warstwa LSTM generuje wstępny rozkład wag uwagi, który jest następnie korygowany przez drugą warstwę, wyposażoną w mechanizm strażnika wizualnego, bazujący na omówionej wcześniej koncepcji \cite{Lu2017KnowingWT}. Strażnik blokuje wpływ cech wizualnych przy generowaniu słów o funkcji czysto syntaktycznej, a ostateczny podpis, uwzględniający zarówno istotność regionów obrazu, jak i strukturę językową, jest generowany przez drugą warstwę LSTM na podstawie udoskonalonych wag.

\section{Architektura transformatorowa}
Architektura transformatorowa zmieniła paradygmat przetwarzania danych sekwencyjnych, eliminując pętle rekurencyjne na rzecz operacji opartych wyłącznie na mechanizmie uwagi~\cite{Vaswani2017AttentionIA}. Rezygnacja z sekwencyjnego przetwarzania umożliwiła efektywne przetwarzanie wsadowe i obliczenia równoległe. Jednocześnie zastosowanie uwagi własnej do modelowania globalnych zależności w danych znacząco zwiększyło zdolność sieci do przechwytywania długoterminowych kontekstów, zarówno wizualnych, jak i językowych.

Struktura transformatora jest oparta na architekturze koder-dekoder. Koder, składający się ze stosu identycznych warstw, przetwarza na wejściu sekwencję wektorów cech charakteryzujących regiony obrazu. W każdej warstwie mechanizm uwagi własnej aktualizuje reprezentację danego regionu w oparciu o kontekst dostarczany przez wszystkie pozostałe. W ten sposób powstają bogate w kontekst reprezentacje wizualne, kodujące złożone relacje między obiektami. 

Dekoder transformatora generuje sekwencję wyjściową słowo po słowie. Jego warstwy, oprócz warstwy uwagi własnej i sieci w pełni połączonych, zawierają moduł uwagi krzyżowej. Uwaga własna w dekoderze jest maskowana, co gwarantuje, że predykcja bieżącego słowa zależy wyłącznie od słów już wygenerowanych. Następnie, w module uwagi krzyżowej, reprezentacje językowe kierują uwagę na wyjście z kodera wizualnego. Ten mechanizm pozwala dekoderowi na dynamiczne integrowanie najbardziej relewantnych informacji wizualnych w procesie generowania każdego kolejnego słowa. 

Elastyczność architektury transformatorowej sprawiła, że stała się ona podstawą dla licznych modyfikacji i rozszerzeń w dziedzinie generowania podpisów do obrazów~\cite{Luo2021DualLevelCTTransformator, Herdade2019Image, Guo2020Normalized}. Część badań skupiła się na udoskonaleniu sterowania mechanizmem uwagi. Przykładowo, w pracy~\cite{Yan2021Task} wprowadzono rozwiązanie, w którym podczas generowania słów o charakterze czysto kontekstowym (niewizualnym), uwaga dekodera jest kierowana nie na cechy obrazu, a na zbiór dodatkowych, trenowanych wektorów. Podejście to jest funkcjonalnym odpowiednikiem mechanizmu strażnika wizualnego, zaimplementowanego w architekturze transformatorowej.

Innym kierunkiem rozwoju jest integracja modelu z zewnętrznymi źródłami wiedzy. W pracy~\cite{Sarto22Retrieval} standardowy dekoder rozszerzono o mechanizm wyszukiwania, który identyfikuje w zewnętrznej bazie danych obrazy podobne wizualnie. Dalej mechanizm bramkowania dynamicznie decyduje, czy w danym kroku generowania słowa polegać na kontekście lokalnym, czy na informacjach pochodzących z odnalezionych obrazów podobnych wizualnie.

Wszechstronnym narzędziem kontroli przepływu informacji w transformatorach okazały się również mechanizmy bramkujące służące do kontroli przepływu informacji na różnych poziomach architektury. Wykorzystuje się je do dynamicznego ważenia wpływu poszczególnych warstw kodera na proces dekodowania \cite{Cornia2020Meshed}, do filtrowania macierzy uwagi w celu skupienia się na kluczowych zależnościach \cite{Jiang2021Multigate}, a także do warunkowania istotności cech wizualnych w zależności od globalnego kontekstu zdania \cite{Ji2020ImprovingIC}.

Podsumowując, architektura transformatorowa, dzięki efektywności obliczeniowej oraz bezprecedensowej zdolności do modelowania złożonych zależności, stanowi obecnie istotną gałąź w dziedzinie automatycznego podpisywania obrazów.

\section{Alternatywne architektury i kierunki badań}
W poszukiwaniu alternatyw dla standardowych dekoderów opartych na sieciach rekurencyjnych, w badaniach nad automatycznym podpisywaniem obrazów eksplorowano zastąpienie mechanizmu rekurencji splotami oraz zmianę paradygmatu generowania z autoregresywnego na nieautoregresywny.

Pierwsza, polega na zastosowaniu architektur w pełni opartych na sieciach splotowych. Była motywowana teoretyczną przewagą CNN w modelowaniu dalekosiężnych zależności oraz możliwością pełnego zrównoleglenia obliczeń~\cite{Aneja2018CVPR}. W modelach tego typu wektor cech obrazu jest łączony z osadzeniami słów, a następnie przetwarzany przez blok warstw splotowych. W odróżnieniu od modeli RNN, które przetwarzają sekwencje słowo po słowie, dekoder CNN operuje na całej sekwencji jednocześnie, co znacząco przyspiesza proces uczenia. Mimo iż podejście to wykazało pewne zalety, takie jak generowanie bardziej zróżnicowanych podpisów i odporność na problem zanikającego gradientu, jego ogólna skuteczność w testach porównawczych okazała się niższa niż w przypadku architektur opartych na RNN z mechanizmem uwagi. W konsekwencji, wraz z gwałtownym rozwojem i dominacją modeli typu Transformer, badania nad dekoderami CNN w tym zastosowaniu straciły na intensywności.

Znacznie bardziej fundamentalną zmianą paradygmatu okazało się generowanie nieautoregresywne, które eliminuje sekwencyjną zależność słów. W przeciwieństwie do modeli autoregresywnych, które generują kolejne słowa na bazie poprzednich, modele nieautoregresywne generują wszystkie słowa jednocześnie i niezależnie. W celu implementacji tego paradygmatu opracowano szereg strategii. Jedną z nich jest wykorzystanie celu treningowego analogicznego do maskowanego modelowania języka, gdzie model uczy się przewidywać losowo zamaskowane słowa na podstawie kontekstu wizualnego i pozostałych słów~\cite{gao2019maskednonautoregressiveimagecaptioning}. Inne podejścia opierają się na iteracyjnym udoskonalaniu, gdzie początkowy, surowy podpis jest generowany w jednym kroku, a następnie wielokrotnie poprawiany przez dedykowane moduły \cite{Fei2020, guo2021fastsequencegenerationmultiagent}.

Główną zaletą modeli nieautoregresywnych jest znacząca redukcja latencji podczas inferencji, wynikająca z równoległego generowania całej sekwencji, co jest kluczowe dla zastosowań czasu rzeczywistego. Co więcej, wyeliminowanie zależności sekwencyjnych zapobiega zjawisku propagacji błędu, w którym pojedynczy błąd kaskadowo wpływa na resztę generowanego zdania. Może to również prowadzić do tworzenia bardziej zróżnicowanych podpisów, gdyż predykcja nie jest ograniczona przez wcześniej wygenerowaną, deterministyczną ścieżkę. Podejście to nie jest jednak pozbawione istotnych wad. Brak jawnych zależności między słowami stwarza ryzyko błędów gramatycznych, powtórzeń oraz utraty spójności semantycznej. Osiągnięcie jakości porównywalnej z modelami autoregresywnymi często wymaga zastosowania skomplikowanych architektur lub wieloetapowych procedur treningowych, które częściowo niwelują pierwotną prostotę tego podejścia.


\chapter{Podstawowe elementy architektury systemu}
\label{rozdzial:elementy_skladowe}

W rozdziale omówiono składowe systemu do automatycznego generowania podpisów do obrazów. Prezentuje ewolucję od podstawowych koncepcji po zaawansowane mechanizmy modelowania multimodalnego.

\section{Architektura koder-dekoder w zadaniach multimodalnych}
Automatyczne generowanie podpisów do obrazów to zadanie polegające na przekształceniu danych wizualnych w sekwencję tekstową o zmiennej długości. Podstawowym podejściem do tego problemu jest jego formalizacja w ramach architektury koder-dekoder, która składa się z dwóch współpracujących ze sobą modułów, jak przedstawiono na Rysunku~\ref{fig:prosta_ilustracja_koder_dekoder}.
\input{wykresy/prosta_ilustracja_koder_dekoder}

Zadaniem modułu kodera jest przetworzenie obrazu na zwartą, numeryczną reprezentację semantyczną, zwaną wektorem kontekstu. Wektor ten koduje kluczowe informacje wizualne dotyczące obiektów, ich atrybutów oraz wzajemnych relacji. Koder rozwiązuje również fundamentalny problem uzgodnienia niesekwencyjnej natury obrazu z sekwencyjnym trybem pracy modelu koder-dekoder, transformując macierz pikseli w sekwencję wektorów cech. Następnie, zadaniem dekodera jest iteracyjne generowanie sekwencji wyjściowej na podstawie otrzymanego wektora kontekstu. Dzięki reprezentacji dostarczonej przez koder, dekoder może – często z wykorzystaniem mechanizmu uwagi – selektywnie skupiać się na najistotniejszych regionach obrazu na każdym kroku generowania kolejnego słowa.

Kanoniczna implementacja tej architektury opiera się na połączeniu dwóch wyspecjalizowanych sieci neuronowych. Rolę kodera pełni sieć szkieletowa oparta głównie na splotowej sieci neuronowej (Convolutional Neural Network, CNN), wyspecjalizowana w ekstrakcji hierarchicznego zbioru cech wizualnych. Rolę dekodera odgrywa natomiast rekurencyjna sieć neuronowa (Recurrent Neural Network, RNN), która posiada naturalną zdolność do modelowania zależności w danych sekwencyjnych. W kolejnych podrozdziałach (Sekcje~\ref{sekcja:koder} oraz \ref{sekcja:dekoder}) szczegółowo omówiono budowę i zasady działania każdego z tych komponentów.

\section{Koder wizualny -- ekstrakcja cech z obrazu}
\label{sekcja:koder}
Koder wizualny w systemach generowania podpisów do obrazów odpowiada za transformację obrazu wejściowego z postaci siatki pikseli do numerycznej reprezentacji semantycznej, zwanej mapą cech, która jest zawsze efektem działania sieci szkieletowej stosującej wielowarstwową sieć CNN. Mapa cech obrazu składa się z wektorów cech, gdzie każdy zawiera cechy danego fragmentu obrazu. Reprezentacja ta musi kodować kluczowe informacje o zawartości sceny — obiekty, ich atrybuty oraz wzajemne relacje przestrzenne — w formie umożliwiającej ich interpretację przez dekoder językowy. Proces ten, określany ekstrakcją cech obrazu, jest etapem, którego jakość bezpośrednio determinuje precyzję i trafność generowanego podpisu.



\subsection{Splotowe sieci neuronowe}
\label{rozdzial:sieci_splotowe}
\input{wykresy/schemat_cnn}
Splotowe sieci neuronowe stanowią fundamentalny element architektur szkieletowych stosowanych w zadaniach automatycznego generowania podpisów do obrazów. Ich architektura, inspirowana biologicznym systemem wzrokowym, jest z natury wyspecjalizowana w efektywnym przetwarzaniu danych o strukturze siatki, takich jak obrazy cyfrowe. Zdolność do hierarchicznego uczenia się cech wizualnych – od prostych krawędzi po złożone obiekty – pozwala na transformację danych wejściowych z przestrzeni pikseli w gęstą, semantycznie bogatą reprezentację wektorową~\cite{LeCun2015Deep}. Główną funkcją sieci splotowej jest zatem ekstrakcja cech, czyli przekształcenie obrazu w skondensowaną reprezentację numeryczną, stanowiącą dane wejściowe dla dekodera językowego w modelach koder-dekoder.

Typowa architektura CNN składa się z sekwencji bloków obliczeniowych, z których każdy realizuje określoną operację matematyczną. Bloki te są ułożone w taki sposób, aby stopniowo redukować wymiarowość przestrzenną danych wejściowych, jednocześnie zwiększając liczbę wymiarów mapy cech. Dzięki temu kodowane są coraz bardziej abstrakcyjne informacje semantyczne. Ogólny schemat tej architektury został zilustrowany na Rysunku~\ref{fig:schemat_cnn}

Bloki obliczeniowe CNN zbudowane są z warstw splotowych, funkcji aktywacji oraz warstw redukcji wymiarów. Warstwy splotowe wykonują operację dyskretnego splotu, która jest istotą działania sieci CNN. Polega ona na przesuwaniu niewielkiej macierzy wag, określanej filtrem, po całej powierzchni obrazu wejściowego. Dla każdego położenia filtra obliczany jest iloczyn skalarny między jego wartościami a odpowiadającym mu fragmentem obrazu. Wyniki tych operacji tworzą nową macierz, zwaną mapą cech, która reprezentuje aktywacje dla danej cechy w różnych lokalizacjach przestrzennych. Formalnie, dla obrazu wejściowego $\mathbf{I}$ o elementach reprezentujących stopnie jasności pikseli $I(i,j)$ oraz filtra $\mathbf{K}$ operację splotu mapy cech $\mathbf{Y}$ można zdefiniować jako~\cite{goodfellow2017deep, Osowski2018SieciNeuronowe}:
\begin{equation}
Y(i, j) = \sum I_{i, j} \odot K .
\end{equation}
gdzie \gls{symb:odot} to iloczyn Hadamarda.

Bezpośrednio po operacji splotu stosowana jest nieliniowa funkcja aktywacji, wprowadzająca nieliniowość do modelu. Jest to warunek konieczny w modelowaniu złożonych zależności w danych. Najczęściej stosowaną funkcją aktywacji w głębokich sieciach neuronowych jest ReLu (\gls{relu})~\cite{goodfellow2017deep, Osowski2018SieciNeuronowe}. Jej popularność wynika z prostoty obliczeniowej i efektywności w procesie uczenia. W celu rozwiązania problemu "umierających neuronów" opracowano warianty takie jak Leaky ReLu czy ELU (Exponential Linear Unit)~\cite{goodfellow2017deep}. Mimo popularności ReLu i jej pochodnych, w niektórych architekturach wciąż wykorzystuje się klasyczne funkcje, takie jak funkcja sigmoidalna~\cite{Han1995Sigmoid}. 

Innym rodzajem warstwy jest warstwa agregacji (\gls{gls:pooling-layer}), której celem jest progresywna redukcja przestrzennej rozdzielczości map cech. Realizuje ona dwie fundamentalne funkcje. Po pierwsze, zmniejszając wymiary map cech, ogranicza liczbę parametrów w kolejnych warstwach (w szczególności w pełni połączonych) oraz redukuje ogólną złożoność obliczeniową modelu. Ponadto  wprowadza pewien stopień niezmienności względem lokalnych translacji (\gls{gls:translation-invariance}), co czyni reprezentacje cech bardziej odpornymi na niewielkie deformacje lub przesunięcia obiektu w danych wejściowych.

W praktyce dominuje strategia agregacji maksimum~\gls{gls:max-pooling} oraz agregacji średnią (\gls{gls:average-pooling})~\cite{Gu2018RecentAdvances}. Agregacja maksimum polega na wyborze maksymalnej wartości aktywacji w predefiniowanym sąsiedztwie. Mechanizm ten wydobywa najbardziej wyraźne cechy, zachowując informację o ich obecności, niezależnie od dokładnej lokalizacji w danym oknie. Agregacja średnią natomiast uśrednia wszystkie aktywacje w oknie. Skutkuje to wygładzeniem reprezentacji i zmniejszeniem jej wariancji, zachowując informację o ogólnej intensywności cechy na danym obszarze.

Efektem działania  wielowarstwowej sieci splotowej służącej do ekstrakcji cech obrazu jest zawsze mapa cech.

\subsection{Sieci szkieletowe}
\label{rozdzial:reprezentacja_obrazu}
\input{tabele/zestawienie_cnn}

Sieć szkieletowa to głęboka splotowa sieć neuronowa, która pełni rolę uniwersalnego ekstraktora cech wizualnych. Kluczowym elementem jest jej wstępne trenowanie (pre-training) na wielkoskalowym zbiorze danych, najczęściej ImageNet, w zadaniu klasyfikacji. Dzięki temu procesowi, zwanemu uczeniem transferowym, sieć uczy się hierarchicznej reprezentacji cech – od prostych krawędzi i tekstur w niższych warstwach, po złożone obiekty w warstwach głębszych. Taka wytrenowana sieć stanowi następnie fundament "szkielet" dla bardziej złożonych architektur, które są dostosowywane do specyficznych zadań, wykorzystując bogatą reprezentację wizualną dostarczoną przez szkielet.

Ważnym etapem przygotowania sieci szkieletowej jest jej trenowanie wstępne (\gls{gls:pre-training})w ramach paradygmatu uczenia transferowego. Proces ten polega na nadzorowanym uczeniu głębokiej sieci CNN na wielkoskalowym, zróżnicowanym zbiorze danych, najczęściej referencyjnym ImageNet, w zadaniu klasyfikacji obrazów. Nadrzędnym celem tego procesu jest wyuczenie uniwersalnego, hierarchicznego ekstraktora cech wizualnych, a nie maksymalizacja metryk klasyfikacyjnych. W rezultacie niższe warstwy sieci specjalizują się w detekcji prostych atrybutów, takich jak krawędzie, gradienty czy tekstury, które w warstwach głębszych są agregowane do reprezentacji złożonych struktur i obiektów. Wagi tak wytrenowanego modelu tworzą ekstraktor cech, gotowy do adaptacji w docelowym zadaniu automatycznego podpisywania obrazów przy znacznie zredukowanym zapotrzebowaniu na dane treningowe.

Do najczęściej wykorzystywanych i najbardziej wpływowych architektur należą VGG w wersjach VGG16 i VGG19, Inception, w tym InceptionV2 i InceptionV3, Resnet50, Resnet101 i Resnet152, Densenet jak Densenet121 i Densenet201, Xception oraz Mobilenet. Architektury te zostaną przedstawione w porządku chronologicznym, pokazując ewolucję od prostszych, głębokich sieci do bardziej złożonych i zoptymalizowanych struktur.

W celu zilustrowania różnic w skuteczności i charakterystyce poszczególnych architektur, w Tabeli~\ref{tab:zestawienie_cnn} przedstawiono porównanie ich wydajności w standardowym zadaniu klasyfikacji na zbiorze ImageNet, wraz z rozmiarem wektora cech generowanego przez każdą z nich.

W Tabeli~\ref{tab:zestawienie_cnn} kolumna sieć szkieletowa identyfikuje konkretną, wstępnie wytrenowaną sieć szkieletową. Rozmiar wektora cech obrazu określa wymiar wektora cech z ostatniej warstwy sieci szkieletowej przed blokiem klasyfikacyjnym. TOP-1 mierzy odsetek przypadków, w których predykcja o najwyższym prawdopodobieństwie jest zgodna z klasą referencyjną, natomiast dokładność TOP-5 określa odsetek przypadków, w których prawidłowo nadana klasa znajduje się w zbiorze pięciu najbardziej prawdopodobnych predykcji.

Analiza danych wskazuje, że architektury takie jak Xception 79,0\% TOP-1 oraz Resnet152V2 78,0\% TOP-1 wykazują najwyższą skuteczność klasyfikacji, co potwierdza efektywność zaawansowanych rozwiązań topologicznych, takich jak sploty odseparowane wgłębnie (\gls{gls:depthwise-separable-convolution}) i połączenia rezydualne (\gls{gls:residual-connection}). Po drugie, widoczny jest kompromis między dokładnością a wydajnością obliczeniową – modele z rodziny Mobilenet charakteryzują się najniższą precyzją, co jest celowym zabiegiem projektowym w celu ich optymalizacji dla środowisk o ograniczonych zasobach. Widać także ewolucję architektur, starsze sieci VGG, mimo generowania najdłuższego wektora cech wynoszącego 4096, osiągają niższą skuteczność niż nowsze modele, jak Resnet czy Xception, które produkują krótszy wektor o długości 2048. Świadczy to o tym, że innowacje w topologii sieci mają większy wpływ na jej zdolności reprezentacyjne niż sama ekspansja przestrzeni cech.


\subsubsection{VGG}
Architektura VGG (Visual Geometry Group)~\cite{Simonyan15VeryDeep} ustanowiła paradygmat projektowy, w którym głębokość sztucznej sieci neuronowej jest kluczowym czynnikiem warunkującym jej skuteczność w przetwarzaniu obrazów. W przeciwieństwie do wcześniejszych modeli, architektura VGG udowodniła, że skuteczność modelu można systematycznie zwiększać poprzez stosowanie prostej, jednorodnej, ale bardzo głębokiej struktury.

Podstawowy moduł obliczeniowy architektury VGG składa się z sekwencji dwóch lub trzech warstw splotowych z filtrami 3x3, gdzie każda jest aktywowana funkcją ReLu. Zasadniczą cechą tej koncepcji jest zastąpienie pojedynczych warstw o dużych polach recepcyjnych (np. 7x7) kaskadą warstw z małymi filtrami. Taka dekompozycja, przy zachowaniu tożsamego efektywnego pola recepcyjnego, umożliwia pogłębienie nieliniowości modelu oraz znaczącą redukcję liczby parametrów.

Strukturę sieci definiuje naprzemienne stosowanie bloków splotowych i warstw redukcji wymiaru. Redukcja jest realizowana przez operację agregacji maksimum w oknie 2x2 z krokiem 2. Operacja ta pełni dwie funkcje. Po pierwsze, zmniejsza rozdzielczość przestrzenną map cech, co prowadzi do redukcji liczby parametrów i zapotrzebowania na zasoby obliczeniowe. Po drugie, wprowadza do sieci niezmienniczość na translacje, czyli sieć jest mniej wrażliwa na niewielkie zmiany położenia lub kształtu obiektów na obrazie, ponieważ w danym fragmencie obrazu zachowywana jest jedynie informacja o maksymalnej aktywacji neuronu. Taki schemat konstrukcyjny prowadzi do ekstrakcji hierarchii cech – od prostych do coraz bardziej złożonych.

Końcowy etap architektury VGG to klasyfikator złożony z trzech warstw w pełni połączonych, który przetwarza spłaszczone mapy cech w celu wygenerowania rozkładu prawdopodobieństwa dla klas docelowych. Mimo swojej prostoty, głębokie cechy wizualne generowane przez VGG okazały się niezwykle uniwersalne. Dzięki temu modele VGG, wstępnie wytrenowane na zbiorze ImageNet, stały się uniwersalnym narzędziem do ekstrakcji cech w szerokim spektrum zadań wizji komputerowej.

\subsubsection{Inception}
W odpowiedzi na rosnące koszty obliczeniowe i liczbę parametrów w architekturach, które zwiększały skuteczność poprzez homogeniczne pogłębianie głębokości sieci, jak VGG, zaproponowano architekturę Inception, pierwotnie znaną jako Googlenet~\cite{Szegedy2014Going}. Metoda zakłada zwiększenie możliwości reprezentacji sieci poprzez konstruowanie zoptymalizowanych, poszerzonych bloków obliczeniowych, zdolnych do efektywnego przetwarzania cech w wielu skalach jednocześnie.

U podstaw Inception leży zasada aproksymacji struktur rzadkich przy użyciu gęstych, łatwo dostępnych komponentów obliczeniowych. Zamiast tworzyć w pełni połączone warstwy, które są kosztowne obliczeniowo i podatne na przeuczenie, architektura wykorzystuje połączenia rzadkie. Inspiracją dla tego podejścia były badania neurobiologiczne, sugerujące, że w korze wzrokowej neurony połączone są w sposób lokalny i rozproszony. W Inception wysoce skorelowane jednostki neuronowe są grupowane, co redukuje liczbę parametrów modelu. Podejście to wspiera również niezmienniczość w translacji.

Centralnym elementem architektury jest moduł Inception, który w swojej podstawowej formie składa się z czterech równoległych ścieżek przetwarzających tę samą mapę cech wejściowych. Ścieżki te zawierają operacje splotu z filtrami o różnych rozmiarach (1x1, 3x3, 5x5) oraz operację redukcji przez maksimum (3x3). Taka konstrukcja pozwala sieci na jednoczesne wydobywanie zarówno cech lokalnych uchwyconych przez mniejsze filtry, jak i bardziej abstrakcyjnych uchwyconych przez większe filtry. Wyjścia ze wszystkich gałęzi są następnie konkatenowane wzdłuż wymiaru kanałów, tworząc zagregowaną reprezentację cech.

Innowacją architektury Inception, która warunkuje jej wydajność obliczeniową, jest zastosowanie splotów 1x1 przed kosztownymi obliczeniowo splotami 3x3 i 5x5. W efekcie drastycznie zmniejsza się głębokość (liczba kanałów) map cech poddawanych dalszemu przetwarzaniu. Zabieg ten znacząco obniża liczbę parametrów sieci, a w efekcie umożliwia budowę głębokich sieci neuronowych optymalnych obliczeniowo.

Architekturę Inception systematycznie doskonalono w kolejnych wersjach. W InceptionV2 wprowadzono mechanizm normalizacji wsadowej (\gls{gls:batch-normalization}), a sploty $5\times5$ poddano faktoryzacji (\gls{gls:factorization}), zastępując je dwiema następującymi po sobie warstwami splotowymi $3\times3 $. Koncepcję tę rozwinięto w architekturze InceptionV3~\cite{Szegedy2016RethinkingTI}, gdzie zastosowano faktoryzację asymetryczną, rozkładając sploty $n \times n$ na sekwencję splotów $1 \times n$ oraz $n \times 1$. Ponadto, w celu dalszej redukcji parametrów i mitygacji ryzyka przeuczenia, tradycyjne warstwy w pełni połączone w warstwie klasyfikacyjnej zastąpiono globalną agregacją średnią (\gls{GAP}). Rodzina architektur Inception przesunęła paradygmat projektowania sieci z prostej pogoni za głębokością w kierunku tworzenia wysoce zoptymalizowanych i efektywnych obliczeniowo topologii.

\subsubsection{Resnet}
Wraz ze wzrostem głębokości sieci neuronowych ujawnił się problem degradacji dokładności. Zjawisko to polega na nasyceniu, a następnie spadku skuteczności modelu, mimo dodawania kolejnych warstw. Trudności te wynikają w dużej mierze z problemu zanikającego gradientu, który uniemożliwia efektywną optymalizację bardzo głębokich architektur. W odpowiedzi na to wyzwanie opracowano nową klasę modeli, które wprowadzają połączenia skrótowe -- alternatywne, krótsze ścieżki dla przepływu informacji i gradientu przez sieć.

Architektura Resnet (Residual Network)~\cite{He2015Deep} wprowadza mechanizm uczenia rezydualnego (\gls{gls:residual-learning}) w celu rozwiązania problemu degradacji. Zamiast aproksymować docelową funkcję $H(\mathbf{X})$, blok rezydualny uczy się funkcji rezydualnej $F(\mathbf{X})$, zdefiniowanej jako $F(\mathbf{X}) := H(\mathbf{X}) - \mathbf{X}$. Oryginalne mapowanie jest następnie odzyskiwane poprzez operację sumowania element po elemencie: $H(\mathbf{X}) = F(\mathbf{X}) + \mathbf{X}$. Implementacja tego rozwiązania jest realizowana za pomocą połączenia skrótowego, które omija co najmniej jedną warstwę i dodaje wejście bloku $\mathbf{X}$ bezpośrednio do jego wyjścia $F(\mathbf{X})$. Innymi słowy, uczenie rezydualne oznacza, że sieć neuronowa nie uczy się bezpośrednio całej, skomplikowanej transformacji danych wejściowych w wyjściowe. Zamiast tego, uczy się "reszty" – czyli różnicy między tym, co sieć powinna zwrócić na wyjściu, a tym, co otrzymała na wejściu. Takie podejście jest znacznie łatwiejsze dla sieci, zwłaszcza gdy pożądana zmiana jest niewielka. Łatwiej jest nauczyć się małej korekty niż całej transformacji od zera.

Podstawowym elementem konstrukcyjnym sieci jest blok rezydualny, składający się z dwóch lub więcej warstw splotowych z nieliniową funkcją aktywacji oraz równoległego połączenia skrótowego. W zależności od głębokości sieci stosuje się różne warianty bloków. W płytszych architekturach, takich jak Resnet18 i Resnet34, wykorzystywane są bloki z dwiema warstwami splotowymi $3\times3$. W głębszych modelach, jak Resnet50, Resnet101 czy Resnet152, wprowadza się zoptymalizowane bloki typu "wąskie gardło". Składają się one z sekwencji trzech warstw splotowych o wymiarach filtrów $1\times1$, $3\times3$ i $1\times1$, celem budowy jeszcze głębszych i wydajniejszych modeli.

\subsubsection{Densenet}
Architektura Densenet (Dense Convolutional Network)~\cite{huang2017densely} stanowi dalszą ewolucję idei połączeń skrótowych, poprzez optymalizację przepływu informacji i gradientu w sieci. Zamiast sumować cechy z poprzedniego bloku jak w Resnet, Densenet wprowadza topologię, w której każda warstwa jest połączona ze wszystkimi poprzedzającymi ją warstwami. 

Istotą architektury Densenet jest blok gęsty, wewnątrz którego kolejne warstwy otrzymują jako wejście konkatenację map cech wygenerowanych przez wszystkie poprzednie warstwy.  Taka struktura promuje ponowne wykorzystanie cech, ponieważ cechy niskiego poziomu z początkowych warstw są bezpośrednio dostępne dla warstw głębszych. Nie tylko łagodzi to problem zanikającego gradientu, ale również zwiększa efektywne wykorzystanie parametrów w sieci. Modele Densenet osiągają wysoką skuteczność przy mniejszej liczbie parametrów niż porównywalne architektury Resnet. Parametrem definiującym wydajność architektury Densenet jest współczynnik wzrostu, który określa liczbę nowych map cech generowanych przez każdą warstwę w bloku. Innymi słowy, każda warstwa dodaje do globalnej wiedzy sieci jedynie niewielką ilość nowych informacji, co redukuje liczbę parametrów.

Ponieważ operacja konkatenacji sukcesywnie zwiększa liczbę kanałów, pomiędzy blokami gęstymi umieszczane są warstwy przejściowe. Składają się one z warstwy normalizacji wsadowej, warstwy splotowej $1\times1$, której celem jest redukcja liczby map cech oraz warstwy agregacji średnią (average pooling) $2\times2$ z krokiem 2, co zmniejsza wymiary przestrzenne.
\subsubsection{Xception}
Rozwój architektur Inception i Resnet pokazał znaczenie rozwoju topologii sieci w poprawie jej skuteczności. Kolejnym krokiem ewolucyjnym było zakwestionowanie samej operacji splotu jako monolitycznego bloku. Architektury Xception i Mobilenet opierają się na hipotezie, że mapowanie korelacji przestrzennych w obrębie jednego kanału oraz korelacji pomiędzy kanałami można od siebie całkowicie oddzielić. Doprowadziło to do opracowania i popularyzacji splotów odseparowanych wgłębnie (\gls{gls:depthwise-separable-convolutions}), które stały się podstawą dla nowej generacji wydajnych obliczeniowo modeli.

Architektura Xception~\cite{Chollet2017Xception} rozwija koncepcję faktoryzacji splotów znaną z Inception. Zamiast dzielić mapy cech na kilka gałęzi jak w module Inception, Xception proponuje pełną dekompozycję standardowej operacji splotu na dwa następujące po sobie etapy.

Pierwszy z nich to splot wgłębny (\gls{gls:depthwise-convolution}), w którym na każdym kanale wejściowym mapy cech operuje jeden, niezależny filtr przestrzenny. Krok ten modeluje wyłącznie korelacje przestrzenne wewnątrz poszczególnych kanałów, bez mieszania informacji pomiędzy nimi. Następnie, w drugim etapie, wyjście splotu wgłębnego jest przetwarzane przez splot punktowy zbudowany z filtrów o wymiarze $1\times1$. Zadaniem tego kroku jest liniowa kombinacja wyjść z poprzedniej operacji w celu modelowania korelacji międzykanałowych i utworzenia nowych map cech.

Struktura sieci Xception to stos 36 warstw splotowych, zorganizowanych w 14 modułów, które tworzą bazę do pozyskiwania cech obrazu. Z wyjątkiem pierwszego i ostatniego modułu, wszystkie pozostałe są połączone za pomocą połączeń rezydualnych. Architektura została podzielona na przepływ wejściowy, który przetwarza dane wejściowe, przepływ środkowy, składający się z ośmiokrotnego powtórzenia bloku splotów odseparowanych wgłębnie, oraz przepływ wyjściowy, który dokonuje końcowych operacji splotowych i klasyfikacji. 

Kompozycja dwuetapowa jest znacznie bardziej wydajna niż standardowy splot, który jednocześnie przetwarza wymiary przestrzenne i kanałowe. Prowadzi to do redukcji zarówno liczby parametrów, jak i kosztu obliczeniowego. Architektura Xception to w istocie liniowy stos modułów opartych na splotach odseparowanych wgłębnie, uzupełniony o połączenia rezydualne, co upraszcza trening, zwłaszcza w przypadku głębokich sieci neuronowych.

\subsubsection{Mobilenet}
Architektura Mobilenet~\cite{Howard2017Mobilenets} podobnie jak Xception wykorzystuje sploty odseparowane wgłębnie, jednakże celem podczas jej projektowania była wydajność w środowiskach o ograniczonych zasobach obliczeniowych, takich jak urządzenia mobilne i systemy wbudowane, a nie wysoka skuteczność. 

Struktura sieci Mobilenet to sekwencja warstw zbudowanych z splotów odseparowanych wgłębnie, gdzie każda została uzupełniona o normalizację wsadową i funkcję aktywacji ReLu. Aby umożliwić elastyczne dostosowanie modelu do konkretnych wymagań sprzętowych, wprowadzono dwa parametry. Mnożnik szerokości kontroluje liczbę kanałów w każdej warstwie, a mnożnik rozdzielczości skaluje rozdzielczość obrazu wejściowego. Oba parametry pozwalają na proporcjonalną redukcję wymiarów całej sieci oraz zmniejszenie kosztów obliczeniowych.

Kolejne wersje architektury wprowadzały dalsze usprawnienia. Model MobilenetV2 zaimplementował odwrócone bloki rezydualne oraz liniową warstwę typu wąskie gardło (\gls{gls:bottleneck}). Dzięki temu usprawniono przepływ gradientu, co zapobiega utracie informacji w warstwach o małej liczbie wymiarów. Z kolei w MobilenetV3 wykorzystano techniki przeszukiwania architektury neuronowej w celu automatycznego dostosowania jej topologii do konkretnych ograniczeń sprzętowych. 

\subsection{Format reprezentacji danych wizualnych dla dekodera}
\input{zdjecia/regiony_vs_siatka}
Przetworzenie obrazu za pomocą sieci szkieletowej prowadzi do uzyskania mapy cech, która składa się z wektorów cech. Każdy wektor cech odpowiada określonemu fragmentowi na regularnej siatce pokrywającej obraz~\cite{Ma2023Grid, Samar2023Enhanced, Yang2024image}, co ilustruje Rysunek~\ref{fig:regiony_vs_siatka}. W literaturze przedmiotu wyróżnia się dwa główne sposoby jej wykorzystania~\cite{Zhao2024RegionFeatures,Yan2024GridFeatures}. 

Pierwszy polega na redukcji całej mapy cech do pojedynczego wektora o stałej długości. Realizuje się to poprzez zastosowanie warstwy GAP lub przez spłaszczanie. W przypadku metody GAP, każda mapa cech o wymiarach $h \times w$ jest redukowana do pojedynczej wartości skalarnej poprzez obliczenie średniej arytmetycznej wszystkich jej aktywacji. W rezultacie macierz cech o wymiarach $c \times h \times w$ zostaje przekształcona w wektor cech o długości $c$, gdzie każdy element wektora odpowiada uśrednionej odpowiedzi jednego z filtrów splotowych na cały obraz. Zaletą tej techniki jest niezależność od przestrzennych wymiarów wejściowych map cech oraz jej zdolność do redukcji nadmiernej liczby parametrów.

Alternatywna technika, spłaszczanie, polega na bezpośredniej wektoryzacji macierzy cech. Operacja ta przekształca mapę cech obrazu w wektor o długości $c \cdot h \cdot w$ poprzez konkatenację wszystkich jego elementów.

Niezależnie od wybranej techniki, oba podejścia prowadzą do stworzenia wektora, który koduje globalną semantykę obrazu. Reprezentacja ta agreguje informacje z całego pola recepcyjnego, identyfikując dominujące obiekty i ogólny kontekst sceny.

Ograniczeniem tej metody jest jednak nieodwracalna utrata jawnej informacji o relacjach przestrzennych między elementami sceny. Proces uśredniania lub spłaszczania eliminuje dane dotyczące lokalizacji poszczególnych cech odpowiadających istotnym elementom obrazu. Wektor wynikowy, choć koduje informację o tym, co znajduje się na obrazie, nie przechowuje wiedzy o tym, gdzie te elementy są umiejscowione względem siebie. Ta dekompozycja struktury przestrzennej istotnie ogranicza zdolność modelu do generowania precyzyjnych i bogatych semantycznie podpisów, zwłaszcza tych, które wymagają zrozumienia wzajemnych interakcji i układu obiektów. W rezultacie generowane podpisy mają tendencję do bycia ogólnikowymi, skupiając się na klasyfikacji sceny lub wymienieniu głównych jej komponentów bez szczegółowego ich scharakteryzowania w kontekście przestrzennym.

Alternatywne podejście zachowuje pełną mapę cech~\cite{Ma2023Grid, Samar2023Enhanced}, pochodzącą z ostatniej warstwy splotowej sieci szkieletowej. Wektory te odpowiadają jednak arbitralnym fragmentom obrazu, wynikającym z nałożenia regularnej siatki na obraz, a nie semantycznie istotnym regionom.

W celu przezwyciężenia tego ograniczenia opracowano techniki ekstrakcji cech regionalnych. Jest to proces dwuetapowy. Najpierw detektor obiektów, jak YOLO czy Faster R-CNN identyfikuje semantycznie istotne obszary, a następnie dla każdego z nich ekstrahowany jest odrębny wektor cech~\cite{Terven2023Yolo, Ren2015Faster}.

Zarówno cechy siatkowe, jak i regionalne są znacznie bogatsze informacyjnie~\cite{Wang2022endtoendtransformerbasedmodel} niż pojedynczy, globalny wektor cech obrazu. Jednak ich efektywne wykorzystanie wymaga od dekodera zdolności do selektywnego skupiania uwagi na najbardziej relewantnych wektorach cech w poszczególnych krokach generowania sekwencji wyjściowej. Ta właśnie potrzeba stała się bezpośrednią motywacją do rozwoju i integracji mechanizmów uwagi w architekturach do automatycznego podpisywania obrazów. Zostaną one omówione w Sekcji~\ref{rozdzial:mechanizm_uwagi}.  


\section{Dekoder językowy--generowanie sekwencji tekstowych}
\label{sekcja:dekoder}
Po etapie wydobywania cech wizualnych w koderze, zadanie syntezy zdania w języku naturalnym przejmuje dekoder. Jest to model językowy, którego zadaniem jest translacja wektorowej reprezentacji obrazu na spójną sekwencję tokenów. Proces ten przebiega sekwencyjnie. Model, przewidując każdy kolejny token, wykorzystuje informacje o tokenach wygenerowanych w poprzednich krokach, zakodowaną w jego stanie ukrytym, oraz stały kontekst wizualny. Aby umożliwić te operacje, słowa muszą być reprezentowane w formie numerycznej – jako gęste wektory liczbowe, określane mianem osadzeń (embeddings)

W sekcji dokonano przeglądu technologii wchodzących w skład architektury dekodera, począwszy od metod numerycznej reprezentacji słów, a skończywszy na sztucznych sieciach neuronowych służących do modelowania złożonych zależności sekwencyjnych.



\subsection{Wstępne przetwarzanie danych}
\label{rozdzial:wstepne_przetwarzanie}
Surowe dane tekstowe ze względu na swoją nieustrukturyzowaną naturę, przed konwersją do postaci numerycznej, wymagają zastosowania wieloetapowego procesu przetwarzania wstępnego. 

Typowy proces wstępnego przetwarzania danych przebiega następująco. W pierwszym kroku
podpisy referencyjne są konwertowane do formatu z małymi literami, celem redukcji liczby unikalnych elementów w słowniku. W kolejnym kroku następuje tokenizacja, czyli podział podpisów na pojedyncze tokeny, gdzie token to podstawowa, atomowa jednostka tekstu, wyodrębniona w procesie tokenizacji, traktowana jako pojedynczy, znaczący element.

Po tokenizacji przeprowadzana jest lematyzacja, inaczej hasłowanie, czyli sprowadzenie wyrazów do ich formy podstawowej, zwanej lematem~\cite{Siino2024Preprocessing}. Lematyzację należy odróżnić od uproszczonego procesu stemmingu, który polega na algorytmicznym odcinaniu przedrostków i przyrostków w celu uzyskania rdzenia wyrazu. W przeciwieństwie do heurystycznego charakteru stemmingu, poprawna identyfikacja lematu wymaga przeprowadzenia analizy morfologicznej słowa, z uwzględnieniem jego kontekstu zdaniowego oraz przynależności do określonej części mowy~\cite{Wolinski2019AutomatycznaAnalizaSkladnikowa}.

Po tokenizacji z tekstu eliminowane są znaki interpunkcyjne oraz inne znaki specjalne. Filtrowane są także słowa funkcyjne (stop words)~\cite{Fox1989StopWords}. Są to powszechnie występujące jednostki językowe o niskiej wartości semantycznej, takie jak spójniki czy przyimki, dla polsiego "i", "oraz", "w", "się", oraz angielskiego "and", "or", "a", "the"~\cite{Sarica2021StopWords}. Celem tych operacji jest redukcja szumu informacyjnego i zmniejszenie wymiarowości przestrzeni cech. W wyniku zastosowania powyższych kroków powstaje oczyszczony korpus tekstowy, na którego podstawie powstaje słownik unikalnych słów w formie podstawowej.

\subsection{Reprezentacja słów}
\label{rozdzial:reprezentacja_slow}
Warunkiem koniecznym do efektywnego przetwarzania danych tekstowych przez głębokie sieci neuronowe jest ich konwersja do postaci numerycznej. W tym celu oczyszczone wcześniej słowa są przekształcane w wektory liczbowe, określane mianem osadzeń (embeddings).

Współczesne metody reprezentacji słów -- wektorów osadzeń klasyfikuje się w ramach dwóch głównych paradygmatów. Pierwszy z nich, oparty na zliczaniu, wykorzystuje globalne statystyki współwystępowania słów w całym korpusie. Drugi, predykcyjny, polega na iteracyjnym uczeniu modelu w zadaniu przewidywania słów w ich lokalnym kontekście semantycznym. Istnieją również podejścia hybrydowe, takie jak model GloVe, łączący cechy obu metod, podczas gdy FastText stanowi przykład klasycznego modelu predykcyjnego.


\subsubsection{Reprezentacja gorącojedynkowa}
Bazową i najbardziej intuicyjną metodą konwersji jest kodowanie gorącojedynkowe (\gls{gls:one-hot-encoding}). W tym podejściu każde słowo ze zdefiniowanego słownika jest reprezentowane przez binarny wektor o długości równej liczbie słów w słowniku. Wektor ten zawiera jedną wartość "1" na pozycji odpowiadającej indeksowi danego słowa, a pozostałe jego elementy są równe "0". Reprezentacja ta, mimo prostoty implementacji, cechuje się dwiema fundamentalnymi wadami. Po pierwsze, generuje ona wektory rzadkie i wysokowymiarowe, co znacząco zwiększa złożoność obliczeniową i wymagania pamięciowe modelu. Po drugie, wektory gorącojedynkowe nie niosą informacji o relacjach semantycznych między słowami. Uniemożliwia to modelowi generalizację wiedzy na podstawie podobieństwa znaczeniowego słów.

\subsubsection{Od reprezentacji dyskretnej do dystrybucyjnej}
Rozwiązanie ograniczeń kodowania gorącojedynkowego przyniosła semantyka dystrybucyjna, ugruntowana w hipotezie dystrybucyjnej. Zgodnie z tą hipotezą, znaczenie słowa jest determinowane przez zbiór kontekstów, w których ono występuje~\cite{Harris1954DistributionalS, Firth1957ASynopsis}. Innymi słowy, wyrazy pojawiające się w podobnych kontekstach językowych mają tendencję do posiadania zbliżonych znaczeń. Implikuje to możliwość ilościowego modelowania znaczenia słów poprzez analizę statystyk ich współwystępowania w dużych korpusach tekstowych. 

Praktyczną realizacją założeń hipotezy dystrybucyjnej są osadzenia słów (\gls{gls:word-embeddings}). Są to gęste, niskowymiarowe wektory, których parametry są uczone w procesie treningu na korpusach tekstowych. W odróżnieniu od reprezentacji gorącojedynkowej, osadzenia mapują słowa na punkty w ciągłej, wielowymiarowej przestrzeni semantycznej. Co istotne, odległość geometryczna między wektorami w tej przestrzeni odzwierciedla podobieństwo semantyczne i syntaktyczne odpowiadających im słów~\cite{Mikolov2013EfficientEO, Pennington2014GLOVE}. Przykładowo, wektory osadzeń słów "kot" i "pies" będą znajdować się blisko siebie, podczas gdy wektor osadzeń czasownika "biec" będzie od nich oddalony.

Ponadto, dobrze wytrenowane osadzenia charakteryzują się zdolnością do odzwierciedlania regularności językowych poprzez proste operacje algebraiczne. Kanonicznym przykładem tej właściwości jest analogia:

$\text{wektor}(\text{"król"}) - \text{wektor}(\text{"mężczyzna"}) + \text{wektor}(\text{"kobieta"}) \approx \text{wektor}(\text{"królowa"})$

Estymacja wag osadzeń jest zintegrowana z treningiem modelu neuronowego. Początkowe wartości macierzy osadzeń mogą być losowe, bądź wykorzystywać wagi wstępnie wytrenowane na zewnętrznym korpusie w ramach transferu wiedzy (\gls{gls:transfer-learning}). Takie podejście wyposaża model w bogatą reprezentację semantyczną już na początkowym etapie uczenia, co przyspiesza uczenie i poprawia wyniki końcowe. Do najważniejszych metod generowania osadzeń słów należy FastText~\cite{Bojanowski2017Enriching} i GloVe~\cite{Pennington2014GLOVE}.

\subsubsection{FastText}
\label{secja:fasttext}
Model FastText~\cite{Bojanowski2017Enriching} generuje wektory poprzez uczenie się przewidywania słów w ich lokalnym kontekście. Każde słowo reprezentowane jest jako suma wektorów jego n-gramów znakowych, czyli podsłów o długości $n$ znaków. W odróżnieniu od metod operujących na całych słowach, FastText modeluje jednostki leksykalne mniejsze niż słowo.

Formalnie, każde słowo $w$ jest dekomponowane na zbiór n-gramów znakowych $G(w)$. Zbiór ten obejmuje samo słowo $w$ oraz wszystkie jego podciągi znaków o długości od $n_{\text{min}}$ do $n_{\text{max}}$, po uprzednim dodaniu do słowa symboli oznaczających jego początek $<$ i koniec $>$. Reprezentacja wektorowa słowa $\mathbf{v(w) }$ jest definiowana jako suma wektorów składowych $\mathbf{z_g}$, przypisanych do każdego n-gramu ze zbioru $G(w)$, zgodnie z równaniem:
\begin{equation}
\mathbf{v(w)}= \sum_{g \in G(w)} \mathbf{z_g},
\end{equation}
gdzie wektory n-gramów $\mathbf{z_g}$ są parametrami modelu uczonymi w procesie treningu.

Podejście oparte na podsłowach wykazuje dwie istotne zalety. Po pierwsze, model efektywnie uwzględnia morfologiczną strukturę słów. Uwzględnienie podsłów pozwala na uchwycenie podobieństw między wyrazami o wspólnym rdzeniu – na przykład słowa "kot" i "koty" dzielą n-gram "kot", dzięki czemu ich reprezentacje wektorowe stają się sobie bliskie. Jest to szczególnie istotne w kontekście języków o bogatej morfologii, jak język polski. Po drugie, FastText jest w stanie generować reprezentacje dla słów nieobecnych w słowniku~\cite{Lochter2020DeOutOfVocab}. Jeśli takie słowo składa się ze znanych modelowi n-gramów, jego wektor może zostać skonstruowany jako suma wektorów tych n-gramów, podczas gdy tradycyjne modele przypisują takim słowom wektor zerowy lub losowy~\cite{Dessi2021}.

\subsubsection{GloVe}
\label{secja:glove}
W odróżnieniu od predykcyjnego podejścia FastText, model GloVe (Global Vectors for Word Representation)~\cite{Pennington2014GLOVE} opiera swoje działanie na analizie globalnych statystyk współwystępowania wyrazów w całym korpusie.Łączy on zalety metod opartych na faktoryzacji globalnej macierzy współwystępowania z lokalnym modelowaniem kontekstu.

Podstawą działania modelu GloVe jest macierz współwystępowania słów $\mathbf{X}$ o wymiarach $|\mathbf{g}| \times |\mathbf{g}|$, dla słownika $\mathbf{g}$ to rozmiar słownika. Każdy element $x_{i, j}$ tej macierzy reprezentuje liczbę wystąpień słowa $w_j$ w zdefiniowanym, symetrycznym oknie kontekstowym słowa $w_i$. Macierz $\mathbf{X}$ stanowi zatem globalne i ilościowe ujęcie relacji między wszystkimi parami słów w korpusie. Celem modelu jest wyuczenie takich wektorów, aby ich iloczyn skalarny odzwierciedlał logarytm prawdopodobieństwa ich współwystępowania.

Model generuje reprezentacje wektorowe poprzez minimalizację ważonej funkcji straty, która opiera się na różnicy między iloczynem skalarnym wektorów a logarytmem ich empirycznej liczby współwystąpień. Funkcja straty jest zdefiniowana jako:
\begin{equation}
j = \sum_{i,j=1}^{|g|} f(x_{i, j}) (\mathbf{w}_i  \cdot \mathbf{\tilde{w}}_j + b_i + \tilde{b_j }- \log x_{i,j})^2 ,
\end{equation}
gdzie $\mathbf{w}_i$ oraz $\mathbf{\tilde{w}}_j$ to, odpowiednio, wektor docelowy słowa $w_i$ i wektor kontekstowy słowa $w_j$; $b_i$ i $\tilde{b}_j$ kompensują błędy systematyczne wynikające z różnic w częstotliwości występowania poszczególnych słów.

Funkcja skalująca $f(x_{i, j})$ kontroluje wagę par słów w procesie optymalizacji. Zapobiega ona nadmiernemu wpływowi bardzo częstych, lecz mało informatywnych współwystąpień, jednocześnie nie ignorując rzadkich, ale potencjalnie istotnych par. Funkcja ta dla pary słów jest zdefiniowana jako:
\begin{equation}
f(x_{i, j}) =
\begin{cases}
\left( \frac{x_{i, j}}{x_{\text{max}}} \right)^\alpha & \text{jeśli } x_{i, j} < x_{\text{max}} \\
1 & \text{w przeciwnym razie},
\end{cases}
\end{equation}
gdzie $x_{\text{max}}$ oraz $\alpha$ to hiperparametry o stałych wartościach odpowiednio 100 i $3/4$. Dzięki takiemu podejściu GloVe efektywnie wykorzystuje globalne statystyki korpusu do tworzenia wysokiej jakości, semantycznie bogatych osadzeń słów.

\subsection{Modelowanie sekwencji}
\label{sekcja:modelowanie-sekwencji}
Generowanie koherentnego opisu wymaga zdolności do modelowania zależności między elementami sekwencji wyrazów budujących zdanie. Ewolucja technik modelowania sekwencji postępowała od prostych modeli statystycznych do zaawansowanych architektur głębokich.
\subsubsection{Ujęcie statystyczne}
\label{rozdzial:modele_sttystyczne}
Zadaniem probabilistycznego modelowania języka jest estymacja rozkładu prawdopodobieństwa nad sekwencjami słów. Celem jest przypisanie wysokiego prawdopodobieństwa sekwencjom poprawnym gramatycznie i semantycznie, a niskiego tym niepoprawnym. Formalnie, dla danej sekwencji słów $\mathbf{c} = (y_1, y_2, ..., y_n)$, model językowy dąży do estymacji prawdopodobieństwa jej wystąpienia, $P(c)$. Podstawowym narzędziem do dekompozycji tego złożonego prawdopodobieństwa jest reguła łańcuchowa, która wyraża prawdopodobieństwo łączne jako iloczyn prawdopodobieństw warunkowych:
\begin{equation}
P(y_1, ..., y_n) = \prod_{i=1}^{n} P(y_i | y_1, ..., y_{i-1})  .
\end{equation}

Zgodnie z powyższym równaniem, problem modelowania prawdopodobieństwa całej sekwencji sprowadza się do zadania predykcji każdego kolejnego słowa $y_i$ na podstawie historii, czyli wszystkich poprzedzających je słów $(y_1, ..., y_{i-1})$.

Jednakże bezpośrednia estymacja prawdopodobieństw warunkowych $P(y_i | y_1, ..., y_{i-1})$ dla długich kontekstów jest w praktyce niewykonalna. Po pierwsze, statystycznie, długie, specyficzne sekwencje kontekstowe występują w danych treningowych niezwykle rzadko lub wcale. Po drugie, obliczeniowo, zarządzanie i przetwarzanie kontekstów o zmiennej i potencjalnie nieograniczonej długości jest nieefektywne. Złożoność ta jest porównywalna do pierwotnego problemu modelowania całej sekwencji~\cite{Hirst2017neural}. Rozwiązaniem tego wyzwania jest założenie Markowa~\cite{Almutiri2022Markov}. Upraszcza ono model poprzez ograniczenie kontekstu do $k$ ostatnich słów, gdzie $k$ jest stałą, niewielką liczbą:
\begin{equation}
    P(y_i | y_1, ..., y_{i-1}) \approx P(y_i | y_{i-k}, ..., y_{i-1}) .
\end{equation}
Innymi słowy, historia dłuższa niż $k$ słów jest uznawana za nieistotną dla predykcji słowa $y_i$. 

Praktyczną realizacją założenia Markowa są modele n-gramowe, gdzie $n = k+1$ i oznacza długość analizowanego kontekstu~\cite{Qi2025Markov}. W paradygmacie tym prawdopodobieństwa warunkowe obliczane są na podstawie znormalizowanych częstości występowania n-gramów (sekwencji $n$ słów) w korpusie treningowym, zazwyczaj za pomocą metody \gls{mle}. Mimo że podejście to znacząco redukuje złożoność obliczeniową, uwypukla jednocześnie problem rzadkości danych. Wiele poprawnych semantycznie i gramatycznie n-gramów może nie wystąpić w ograniczonym zbiorze treningowym, w wyniku czego estymator MLE przypisze im zerowe prawdopodobieństwo, co dyskwalifikuje każde zdanie zawierające choćby jeden taki n-gram. W celu rozwiązania tego problemu stosuje się techniki wygładzania (\gls{gls:smoothing}), które polegają na alokacji części masy prawdopodobieństwa z n-gramów zaobserwowanych w korpusie treningowym do n-gramów niezaobserwowanych. Najpopularniejsze to wygładzanie Laplace'a~\cite{Manning2008IntroductionToInformationRetrieval}, Knesera-Neya~\cite{Chen1998SmoothingTech}, 

Fundamentalną wadą modeli n-gramowych jest ich sztywne, krótkie okno kontekstowe. Motywuje to przejście w stronę architektur neuronowych. Modele te z definicji nie są w stanie modelować dalekosiężnych zależności w języku naturalnym, co jest warunkiem zrozumienia treści w języku naturalnym. W zdaniu: "Jan poszedł do kina z Marią, ponieważ dawno nie oglądał żadnego filmu; była bardzo zachwycona". Aby poprawnie przewidzieć ostatnie słowo – "zachwycona" – model musi wiedzieć, że podmiotem, którego dotyczy przymiotnik, jest "Maria", a nie "Jan". Jednak dla typowego modelu n-gramowego, jak trigramu lub 4-gramu, kontekst w momencie predykcji "...była bardzo" nie zawiera informacji o słowie "Maria", które wystąpiło znacznie wcześniej. Model statystyczny nie jest w stanie powiązać formy gramatycznej przymiotnika z odległym rzeczownikiem, co stanowi jego immanentne ograniczenie i uzasadnia konieczność zastosowania podejść zdolnych do kodowania i wykorzystywania znacznie dłuższego kontekstu, takich jak rekurencyjne sieci neuronowe.

\subsubsection{Podstawowa rekurencyjna sieć neuronowa}
\label{sekcja:sieci-rekurencyjne}
Rekurencyjne sieci neuronowe (RNN, Recurrent Neural Networks) to klasa architektur neuronowych zaprojektowanych do przetwarzania danych sekwencyjnych o zmiennej długości. Inherentną cechą architektur rekurencyjnych jest pętla zwrotna, która pozwala na przekazywanie informacji z poprzednich kroków czasowych do bieżącego. Koncepcja ta jest realizowana poprzez stan ukryty $\mathbf{h_t}$, który agreguje informacje z całej dotychczas przetworzonej sekwencji. Stan ten pełni rolę pamięci o zmiennej długości, co teoretycznie pozwala na modelowanie zależności na dowolną odległość.
\input{wykresy/sieci_rekurencyjne/komorka_RNN}


Podstawowa komórka RNN aktualizuje swój stan ukryty $\mathbf{h_t}$ w każdym kroku czasowym $t$ na podstawie poprzedniego stanu $\mathbf{h_{t-1}}$ oraz bieżącego wejścia $\mathbf{x_t}$, co przedstawiono na Rysunku~\ref{fig:komorka_RNN}. Proces ten formalnie zdefiniowano przez następujące równanie:
\begin{equation}
   \mathbf{h_t} = \tanh(\mathbf{W_{h}}\mathbf{h_{t-1} }+ \mathbf{W_{x}}\mathbf{x_t} + \mathbf{b_h}) ,
\end{equation}
gdzie $\mathbf{W_{\mathbf{h}}}$, $\mathbf{W_{\mathbf{x}}}$, $\mathbf{b_h}$ to trenowane parametry modelu, a tgh jest nieliniową funkcją aktywacji.
 
Pomimo teoretycznej zdolności do modelowania długich zależności, trenowanie standardowych architektur RNN napotyka na istotne trudności praktyczne związane z propagacją gradientu funkcji błędu w czasie, takich jak problem znikającego gradientu oraz problem eksplodującego gradientu~\cite{goodfellow2017deep}.

W przypadku znikającego gradientu, metody oparte na propagacji wstecznej i gradiencie obliczają częściowe pochodne dla funkcji błędu na podstawie wag w danym kroku. W pewnych przypadkach gradient jest tak niewielki, że obliczone wagi nie zmieniają się. Może prowadzić to nawet do całkowitego zatrzymania treningu~\cite{goodfellow2017deep}. 

Adekwatnie dla eksplodującego gradientu, może dojść do sytuacji, gdzie błędy skumulują się, a wagi w pojedynczej iteracji będą tak ogromne, że spowodują zjawisko przekroczenia dopuszczalnej wartości~\cite{goodfellow2017deep}. W efekcie model nie jest w stanie uczyć się na danych treningowych, zaś trening nie może zostać ukończony. Oba problemy są szczególnie dotkliwe w przypadku przetwarzania długich sekwencji danych, gdzie kluczowe jest zachowanie stabilnego przepływu informacji w czasie. W celu ich mitygacji stosuje się regularyzację wag oraz obcinanie gradientu (\gls{gls:gradient-clipping}). 

Odpowiedzią na te ograniczenia stały się bardziej złożone architektury, takie jak LSTM~\cite{Hochreiter1997LSTM} i GRU~\cite{Cho2014Properties}. Wprowadzają one mechanizmy bramek, które w sposób adaptacyjny kontrolują przepływ informacji przez komórkę. Bramki te decydują, które informacje należy zachować w stanie komórki, które usunąć, a które wykorzystać do wygenerowania wyjścia, co skutecznie łagodzi problem zanikającego gradientu.

W kontekście modelowania języka naturalnego, architektury rekurencyjne stanowią znaczący postęp w stosunku do klasycznych modeli statystycznych, takich jak n-gramy. Podstawową przewagą RNN jest zdolność do modelowania zależności o nieograniczonej długości, w przeciwieństwie do stałego, predefiniowanego okna kontekstowego w modelach n-gramowych. W tym ujęciu, wektor wejściowy $\mathbf{x_t}$ reprezentuje słowo lub znak w kroku $t$, a stan ukryty $\mathbf{h_t}$ staje się numeryczną reprezentacją całego dotychczasowego kontekstu. Dzięki temu sieć jest w stanie uchwycić semantyczne i syntaktyczne właściwości sekwencji, które są kluczowe dla zadań takich jak generowanie tekstu, tłumaczenie maszynowe czy analiza sentymentu.

\subsubsection{Sieć LSTM}
\label{rozdzial:siec_LSTM}
\input{wykresy/sieci_rekurencyjne/komorka_LSTM}
Sieć LSTM~\cite{Hochreiter1997LSTM} to wariant rekurencyjnej sieci neuronowej, gdzie udoskonalono zarządzanie pamięcią w każdym kroku czasowym generowania sekwencji wyjściowej. Odpowiada za to stan komórki $\mathbf{c_t}$, który przechowuje informacje w każdym kroku czasowym podczas generowania sekwencji wyjściowej. W odróżnieniu od stanu ukrytego w klasycznym RNN, podlega jedynie niewielkim modyfikacjom liniowym, zatem informacje oraz gradienty mogą być propagowane bez większych zmian w długich sekwencjach. 

Ponadto architektura LSTM wprowadza podział na pamięć długoterminową, przechowywaną w stanie komórki $\mathbf{c_t}$, oraz na pamięć krótkoterminową, reprezentowaną przez stan ukryty $\mathbf{h_t}$. Za kontrolę przepływu informacji w całej komórce LSTM odpowiada system trzech bramek: bramki zapominania, bramki wejściowej i bramki wyjściowej. Bramki te działają w oparciu o warstwę sigmoidalną, a na wyjściu generują wartości z przedziału $[0, 1]$. Wartości bliskie o powodują zablokowanie przepływu informacji, a wartości bliskie 1 implikują swobodny przepływ informacji.

Aktualizacji stanu komórki i generowania wyjścia w pojedynczym kroku czasowym $t$ przebiega sekwencyjnie, integrując działanie wszystkich trzech bramek, co przedstawiono na Rysunku~\ref{fig:komorka_LSTM}.

W pierwszym kroku bramka zapominania $\mathbf{f_t}$ decyduje, które informacje z poprzedniego stanu komórki $\mathbf{c_{t-1}}$ należy usunąć. Decyzja ta jest podejmowana na podstawie poprzedniego stanu ukrytego $\mathbf{h_{t-1}}$ oraz bieżących danych wejściowych $\mathbf{x_t}$ zgodnie z równaniem:
\begin{equation}
    \mathbf{f}_t = \sigma(\mathbf{W_f} \mathbf{x}_t + \mathbf{R}_{\mathbf{f}} \mathbf{h}_{t-1} + \mathbf{b_{\mathbf{f}}}),
\end{equation}
gdzie $\mathbf{W}_{\mathbf{f}}$ i $\mathbf{R}_{\mathbf{f}}$ to macierze wag, a $\mathbf{b_f}$ to wektor obciążenia (bias).

Następnie bramka wejściowa $\mathbf{i}_t$ określa, które nowe informacje powinny zostać zapisane w stanie komórki. Proces ten jest dwuetapowy. Najpierw warstwa sigmoidalna decyduje o tym, które wartości należy zaktualizować:
\begin{equation}
    \mathbf{i}_t = \sigma(\mathbf{W}_{\mathbf{i}} \mathbf{x}_t + \mathbf{R}_{\mathbf{i}} \mathbf{h}_{t-1} + \mathbf{b}_i) .
\end{equation}
Równocześnie warstwa z funkcją tgh tworzy wektor wartości $\tilde{c}_t$, kandydujących do dodania do stanu komórki:
\begin{equation}
    \mathbf{\tilde{c}}_t = \text{tgh}(\mathbf{W}_{\mathbf{c}} \mathbf{x}_t + \mathbf{R}_c \mathbf{h}_{t-1} + \mathbf{b}_c).
\end{equation}
Nowy stan komórki, $\mathbf{c}_t$, jest obliczany poprzez połączenie wyników działania bramki zapominania i wejściowej. Wektor bramki zapominania $\mathbf{f}_t$ jest mnożony poelementowo przez poprzedni stan komórki  $\mathbf{c}_{t-1}$. Następnie do wyniku dodawany jest iloczyn poelementowy wektora kandydującego $\tilde{\mathbf{c}}_t$ i wektora bramki wejściowej $\mathbf{i}_t$:
\begin{equation}
    \mathbf{c}_t = \mathbf{f}_t \odot \mathbf{c}_{t-1} + \mathbf{i}_t \odot \tilde{\mathbf{c}}_t   ,
\end{equation}
gdzie $\odot$ to mnożenie poelementowe (iloczyn Hadamarda)
W ostatnim kroku wyznaczany jest nowy stan ukryty $\mathbf{h}_t$ zależny od bramki wyjściowej $\mathbf{o}_t$. Bramka $\mathbf{o}_t$ filtruje zaktualizowany stan komórki $\mathbf{c}_t$, decydując, która jego część zostanie przekazana jako wyjście, według wzoru:
\begin{equation}
    \mathbf{o}_t = \sigma(\mathbf{W}_o \mathbf{x}_t + \mathbf{R}_o \mathbf{h}_{t-1} + \mathbf{b}_o)  .
\end{equation}
Następnie stan komórki $\mathbf{c}_t$ jest normalizowany przez funkcję tgh, a wynik jest mnożony przez wektor $\mathbf{o}_t$, co daje ostateczny stan ukryty:
\begin{equation}
    \mathbf{h}_t = \mathbf{o}_t \odot \text{tgh}(\mathbf{c}_t)      .
\end{equation}
Skuteczność sieci LSTM wynika z faktu, że operacje wykonywane przez bramki nie są predefiniowane, lecz wynikają z przebiegu treningu. Każda bramka optymalizuje własny zbiór parametrów $\mathbf{W},\mathbf{R},\mathbf{b}$ podczas treningu, dzięki czemu sieć autonomicznie uczy się optymalnej dla danego zadania strategii zarządzania informacją – zapominania, aktualizacji i selekcji danych wyjściowych. Dzięki rozdzieleniu funkcji stanu komórki $\mathbf{c}_t$ od stanu ukrytego  $\mathbf{h}_t$ możliwe jest modelowanie długich sekwencji.

\subsubsection{Sieć GRU}
\label{rozdzial:siec_gru}
Architektura GRU~\cite{Cho2014Learning} stanowi modyfikację klasycznej, rekurencyjnej sieci neuronowej, która, podobnie jak LSTM, została zaprojektowana w celu rozwiązania problemu zanikającego gradientu za pomocą mechanizmów bramkujących. W porównaniu do LSTM, model GRU charakteryzuje się mniejszą złożonością obliczeniową, ponieważ jego struktura obejmuje jedynie dwie bramki – resetującą i aktualizacji. Ponadto GRU rezygnuje z oddzielnej komórki pamięci $\mathbf{c}_t$ , integrując jej funkcjonalność bezpośrednio w stanie ukrytym $\mathbf{h}_t$.
\input{wykresy/sieci_rekurencyjne/komorka_GRU}

Proces obliczeniowy w komórce GRU, zilustrowany na Rysunku~\ref{fig:komorka_GRU}, przebiega sekwencyjnie. Finalny stan ukryty $\mathbf{h}_t$ jest wyznaczany na podstawie wektora wejściowego $\mathbf{x}_t$ oraz stanu ukrytego z poprzedniego kroku czasowego $\mathbf{h}_{t-1}$.

W pierwszym kroku obliczana jest bramka resetująca $\mathbf{r}_t$, która determinuje, które informacje z poprzedniego stanu ukrytego $\mathbf{h}_{t-1}$ są istotne dla obliczenia nowego kandydata na stan ukryty~\cite{Mienye2024GRU}. Wartość bramki obliczana jest za pomocą funkcji sigmoidalnej $\sigma$ i przyjmuje wartości w przedziale $[0, 1]$. Wartość bliska 0 oznacza ignorowanie informacji z $\mathbf{h}_{t-1}$, podczas gdy wartość bliska 1 wskazuje na jej pełne zachowanie:
\begin{equation}
    \mathbf{r}_t = \sigma(\mathbf{W}_{\mathbf{r}} \mathbf{x}_t + \mathbf{R}_{\mathbf{r}} \mathbf{h}_{t-1} + \mathbf{b}_{\mathbf{r}}),
\end{equation}
gdzie $\mathbf{W}_r$ i $\mathbf{R}_r$ to trenowane parametry modelu.

Następnie obliczana jest bramka aktualizacji $\mathbf{u}_t$. Bramka $\mathbf{u}_t$ odpowiada ona za kontrolę, w jakim stopniu finalny stan ukryty $\mathbf{h}_t$ będzie bazował na stanie z poprzedniego kroku $\mathbf{\mathbf{h}}_{t-1}$, a w jakim na nowo obliczonym kandydacie $\tilde{\mathbf{h}}_t$. Mechanizm ten odpowiada za modelowanie zależności długoterminowych, poprzez przenoszenie wybranych informacji przez wiele kroków czasowych. Podobnie jak bramka resetująca, wykorzystuje funkcję sigmoidalną:
\begin{equation}
    \mathbf{u}_t = \sigma(\mathbf{W}_u \mathbf{x}_t + \mathbf{R}_{\mathbf{u}} \mathbf{h}_{t-1} + \mathbf{b}_{\mathbf{u}}) ,
\end{equation}
gdzie $\mathbf{W}_{\mathbf{u}}$, $\mathbf{R}_{\mathbf{u}}$ i $b_{\mathbf{u}}$ to trenowane parametry modelu.

W kolejnym kroku wyznaczany jest kandydat na nowy stan ukryty $\tilde{\mathbf{h}}_t$. Jest to propozycja nowej wartości stanu ukrytego, formułowana na podstawie bieżącego wejścia $\mathbf{x}_t$ oraz wersji poprzedniego stanu ukrytego, przefiltrowanej przez bramkę resetującą $(\mathbf{r}_t \odot \mathbf{h}_{t-1})$. Poprzez iloczyn Hadamarda informacje nieistotne są filtrowane z $\mathbf{h}_{t-1}$, a następnie normalizowane za pomocą funkcji tgh do zakresu (-1, 1)
\begin{equation}
    \tilde{\mathbf{h}}_t = \text{tgh}(\mathbf{W}_{\tilde{\mathbf{h}}} \mathbf{x}_t + \mathbf{u}_{\tilde{\mathbf{h}}}(\mathbf{r}_t \odot \mathbf{h}_{t-1}) + \mathbf{b}_{\tilde{h}}) ,
\end{equation}
gdzie $\mathbf{W}_{\tilde{\mathbf{h}}}$, $\mathbf{u}_{\tilde{\mathbf{h}}}$ i $\mathbf{b_{\tilde{h}}}$ to uczone parametry modelu.

Ostatnim krokiem jest obliczenie wyjściowego stanu ukrytego $\mathbf{h}_t$ dla kroku czasowego $t$. Jest to wynik interpolacji liniowej pomiędzy poprzednim stanem ukrytym $\mathbf{h}_{t-1}$ a kandydatem $\tilde{\mathbf{h}}_t$. Bramka aktualizacji $\mathbf{u}_t$ pełni rolę współczynnika tej interpolacji, decydując o proporcjach, w jakich łączone są oba stany:
\begin{equation}
    \mathbf{h}_t = (1 - \mathbf{u}_t) \odot \mathbf{h}_{t-1} + \mathbf{u}_t \odot \tilde{\mathbf{h}}_t  ,
\end{equation}
Dzięki temu mechanizmowi komórka GRU elastycznie zarządza pamięcią. Gdy wartości $\mathbf{u}_t$ są bliskie 0, większość informacji z $\mathbf{h}_{t-1}$ jest zachowywana, co jest kluczowe dla przechwytywania długoterminowych zależności. Z kolei gdy $\mathbf{u}_t$ dąży do 1, stan ukryty jest zastępowany przez nowo wygenerowanego kandydata $\tilde{\mathbf{h}}_t$ celem adaptacji do nowych, istotnych informacji z bieżącego wejścia.





\section{Podstawowy model koder--dekoder -- synteza i ograniczenia}
Po przedstawieniu fundamentalnych komponentów architektury do generowania podpisów – kodera wizualnego opartego na splotowych sieciach neuronowych oraz dekodera językowego wykorzystującego rekurencyjne sieci neuronowe – naturalnym krokiem jest ich synteza w zintegrowany system.

W sekcji dokonano szczegółowej analizy tego podstawowego modelu. W pierwszej kolejności przedstawiono strategie integracji obu modułów. Następnie omówiono proces ich wspólnego uczenia (\gls{gls:end-to-end-learning}). W końcowej części zidentyfikowano i przeanalizowano kluczowe ograniczenia tej architektury, które stanowią motywację dla rozwoju bardziej zaawansowanych rozwiązań.

\subsection{Połączenie obrazu i tekstu}
\label{sekcja:jak_poloczyc_cechy_obrazu_tekstu}
\input{wykresy/scalanie_wstrzykiwanie/scalanie_wstrzykiwanie}
Istotnym aspektem w konstrukcji modelu do automatycznego generowania podpisów do obrazów jest metoda połączenia informacji pochodzących z dwóch różnych modalności – wizualnej i tekstowej. Zasadnicza decyzja architektoniczna dotyczy etapu oraz sposobu, w jaki cechy obrazu powinny zostać zintegrowane z dekoderem RNN. W literaturze przedmiotu wyróżnia się  architekturę wstrzykiwania oraz architekturę fuzji~\cite{TantiGattCamilleri2018Where, Tanti2017Role}.

Architektura wstrzykiwania polega na włączeniu informacji wizualnej bezpośrednio w proces rekurencyjnego przetwarzania danych w dekoderze, co wymusza na modelu trenowanie wspólnej, multimodalnej reprezentacji. W zależności od momentu integracji wektora cech wizualnych, wyróżnia się kilka wariantów tej architektury.

W metodzie wstrzykiwania inicjalnego (initial injection, Rysunek~\ref{fig:wstrzykiwanie_inicjalne}) wektor cech obrazu służy do zainicjowania początkowego stanu ukrytego sieci RNN. W wariancie wstrzykiwania wstępnego (pre-injection, Rysunek~\ref{fig:wstrzykiwanie_wstepne}) wektor ten jest podawany na wejście sieci w pierwszym kroku czasowym, poprzedzając osadzenie słowa inicjującego generowanie podpisu, przy czym metoda ta nie precyzuje sposobu inicjalizacji stanu ukrytego. Natomiast wstrzykiwanie równoległe (parallel injection, Rysunek~\ref{fig:wstrzykiwanie_rownolegle}) polega na dostarczaniu cech wizualnych do dekodera w każdym kroku czasowym, zazwyczaj poprzez konkatenację z wektorem osadzenia słowa. Zapewnia to stały dostęp do informacji o obrazie, jednak wiąże się ze znacznym kosztem obliczeniowym.

Odmienne podejście prezentuje architektura fuzji (Rysunek~\ref{fig:architektura_scalania}), w której modalności wizualna i tekstowa są przetwarzane oddzielnie. Sieć RNN operuje wyłącznie na sekwencji osadzeń słów, kodując kontekst językowy w stanie ukrytym. Informacja wizualna jest dołączana dopiero na etapie predykcji kolejnego słowa. W tym celu finalny stan ukryty RNN jest łączony z wektorem cech obrazu za pomocą konkatenacji, sumy wektorów bądź iloczynu Hadamarda. Wynik tej operacji stanowi wejście dla warstwy klasyfikacyjnej, obliczającej rozkład prawdopodobieństwa nad słownikiem.

Porównując obie strategie, architektura wstrzykiwania wymusza naukę złożonej, wspólnej przestrzeni cech, co jednak wiąże się z większą liczbą parametrów i ryzykiem zanikania wpływu informacji wizualnej w procesie generowania dłuższych sekwencji. Z kolei architektura fuzji charakteryzuje się niższą złożonością obliczeniową i wyraźnym rozdziałem przetwarzania obu modalności, co może jednak ograniczać zdolność modelu do ścisłego warunkowania generowanego tekstu na treści obrazu na wczesnych etapach dekodowania.

\subsection{Proces uczenia}
Połączony model koder-dekoder jest jednolicie trenowany. Oznacza to, że cała architektura, od wejścia obrazu do wyjścia w postaci sekwencji słów, jest traktowana jako jeden zintegrowany system. Podczas treningu sygnał błędu, obliczony na podstawie wygenerowanego podpisu, jest propagowany wstecznie  przez całą sieć – od dekodera RNN aż do kodera z siecią szkieletową. Pozwala to na wspólną optymalizację parametrów obu komponentów. W rezultacie model uczy się nie tylko generowania języka, ale także ekstrakcji cech wizualnych, które są najbardziej relewantne z perspektywy zadania generowania podpisów.

Standardową funkcją straty stosowaną w zadaniach generowania sekwencji, w tym opisu obrazów, jest entropia krzyżowa. Celem optymalizacji jest minimalizacja ujemnego logarytmu prawdopodobieństwa poprawnej sekwencji docelowej $\mathbf{c} = (y_1, ..., y_n)$ o długości $n$ dla danego obrazu $I$, przy danych parametrach modelu $\theta$. Całkowitą stratę dla pojedynczej pary (obraz, podpis) definiuje się jako sumę strat dla każdego słowa w sekwencji:
\begin{equation}
    L(I, \mathbf{c}) = - \sum_{t=1}^{n} \log p(y_t | I, y_1, \dots, y_{t-1}; \theta),
\end{equation}
gdzie $p(y_t | ...)$ jest prawdopodobieństwem wygenerowania poprawnego słowa $y_t$ w kroku czasowym $t$ na wyjściu dekodera. Minimalizacja tej funkcji straty odbywa się za pomocą algorytmów optymalizacji opartych na stochastycznym spadku gradientu, takich jak SGD, RMSprop czy Adam, które iteracyjnie aktualizują wagi modelu $\theta$ w celu poprawy jakości predykcji.

\subsection{Generowanie sekwencji wyjściowej}
\label{rozdzial:generowanie_sekwencji_wyjsciowej}
Po wytrenowaniu, model może być wykorzystany do generowania podpisów dla nowych obrazów. W tym celu stosuje się deterministyczne strategie dekodowania. W zadaniu automatycznego generowania podpisów obrazów, podczas generowania zdania wyjściowego, dekoder w każdym kroku czasowym $t$ generuje warunkowy rozkład prawdopodobieństwa $P(y_t | y_{1:t-1}, I)$, który określa prawdopodobieństwo wygenerowania słowa $y_t$ w podpisie, na podstawie historii wcześniej wygenerowanych słów $y_{1:t-1}$ oraz obrazu $I$. Wybór finalnej sekwencji słów wymaga zastosowania odpowiedniej strategii dekodowania. 

Najbardziej intuicyjnym podejściem do generowania sekwencji wyjściowej jest algorytm zachłanny. W każdym kroku czasowym $t$, algorytm ten wybiera słowo $y_t$ o najwyższym prawdopodobieństwie warunkowym, zgodnie z następującym wzorem~\cite{zhang2023dive}:
\begin{equation}
    y_t = \arg\max_{y \in G} P(y_t = y \mid  y_1, y_1, \ldots, y_{t-1}, I),
\end{equation}
gdzie $g$ oznacza słownik modelu językowego o długości $|g|$.

Pomimo swojej prostoty i niskiej złożoności obliczeniowej, algorytm zachłanny nie gwarantuje uzyskania globalnie optymalnego podpisu. Podejmowane są decyzje optymalne jedynie lokalnie. Wybór słowa o najwyższym prawdopodobieństwie w danym kroku może prowadzić do nieoptymalnych wyborów w kolejnych krokach.

\input{wykresy/ilustracja_przeszukiwania_wiazkowego}
Algorytm przeszukiwania wiązkowego ma na celu przezwyciężenie ograniczeń podejścia zachłannego. Zamiast jednej, najlepszej hipotezy, algorytm ten utrzymuje i rozwija $k$ najbardziej prawdopodobnych sekwencji w każdym kroku czasowym~\cite{Jurasky2023}. Szerokość wiązki $k$ jest hiperparametrem. Algorytm ten można interpretować jako przeszukiwanie przestrzeni możliwych podpisów, reprezentowanej jako drzewo przeszukiwania, jak przedstawiono na Rysunku~\ref{fig:ilustracja_przeszukiwania_wiazkowego}. Węzły drzewa odpowiadają sumarycznemu prawdopodobieństwu wygenerowania fragmentów zdania. Krawędzie reprezentują prawdopodobieństwa warunkowe wygenerowania słowa na podstawie poprzednich słów i obrazu $I$. Celem jest znalezienie ścieżki w drzewie, która odpowiada podpisowi o najwyższym prawdopodobieństwie.

W każdym kroku $t$, dla każdej z $k$ hipotez z kroku $t-1$, generowanych jest $|g|$ potencjalnych kontynuacji. Następnie obliczana jest skumulowana ocena dla każdej z $k \times |g|$ nowo powstałych sekwencji metodą logarytmu prawdopodobieństwa:
\begin{equation}
    \text{score}(y_{1:t}) = \sum_{i=1}^{t} \log P(y_i | y_{1:i-1}, I).
\end{equation}
Spośród wszystkich kandydatur, do dalszego przetwarzania w kroku $t+1$ wybieranych jest $k$ sekwencji o najwyższej ocenie. Proces jest kontynuowany do momentu, gdy wszystkie hipotezy w wiązce zakończą się słowem kończącym generowanie sekwencji $<$STOP$>$ lub osiągną maksymalną, predefiniowaną długość. Ostatecznie wybierana jest sekwencja o najwyższej ocenie końcowej. Przeszukiwanie wiązkowe stanowi kompromis między jakością generowanych sekwencji a kosztem obliczeniowym. Zazwyczaj prowadzi do uzyskania bardziej trafnych i spójnych językowo podpisów niż dekodowanie zachłanne.


\subsection{Ograniczenia modelu podstawowego}
Mimo swojej skuteczności i fundamentalnego znaczenia dla rozwoju dziedziny, podstawowa architektura koder-dekoder cechuje się istotnymi ograniczeniami, które zmotywowały dalsze badania nad jej udoskonaleniem.

Głównym ograniczeniem architektonicznym jest wąskie gardło informacyjne. Wynika ono z konieczności transformacji całej, potencjalnie bardzo złożonej informacji wizualnej zawartej w obrazie do pojedynczego wektora cech o stałym wymiarze. Niezależnie od bogactwa detali, relacji między obiektami i ogólnej kompozycji sceny, koder stosujący sieć szkieletową musi wyprodukować jeden, statyczny wektor reprezentacji. Proces ten nieuchronnie prowadzi do utraty informacji. W rezultacie, dekoder RNN, generując kolejne słowa opisu, ma ograniczony i niezmienny dostęp do danych wizualnych. Jest to szczególnie problematyczne przy opisywaniu złożonych scen z wieloma obiektami, gdzie odwołanie się do konkretnych regionów obrazu w różnych momentach generowania zdania byłoby pożądane.

Drugim istotnym problemem jest rozbieżność między celem procesu uczenia a metrykami stosowanymi do finalnej ewaluacji modelu. Model jest trenowany poprzez optymalizację lokalnej funkcji straty (entropii krzyżowej na poziomie pojedynczych słów), co jest formą uczenia z nauczycielem. Jego finalna jakość jest jednak oceniana za pomocą globalnych metryk sekwencyjnych, takich jak BLEU, METEOR, ROUGE czy CIDEr, które mierzą podobieństwo całych wygenerowanych zdań do referencyjnych opisów ludzkich pod kątem spójności, płynności i trafności. Optymalizacja sumy lokalnych prawdopodobieństw słów nie gwarantuje, że wygenerowana sekwencja będzie globalnie optymalna w świetle tych metryk~\cite{Shao2021Sequence, Cahyono2024automatedimagecaptioningcnns}.

Podsumowując, architektura koder-dekoder istotnie wpłynęła na skuteczność modeli do automatycznego podpisywania obrazów. Jednakże efektywność tego rozwiązania jest systemowo ograniczona, gdyż dekoder, generując kolejne słowo w sekwencji, ma mało informacji o treści obrazu. W każdym kroku czasowym przewiduje kolejne słowo na podstawie stałego wektora z ostatniej warstwy sieci szkieletowej. Wektor ten nie niesie całego zakresu i bogactwa informacyjnego z całej mapy cech obrazu. Wszystkie te dane są transformowane do pojedynczego wektora. Aby efektywnie wykorzystać informacje z wcześniejszych warstw, zaadaptowano mechanizm uwagi, którego warianty zostały dalej szczegółowo omówione.

\section{Mechanizm uwagi -- selektywne przetwarzanie złożonych cech obrazu}
\label{rozdzial:mechanizm_uwagi}
Mechanizm uwagi umożliwia dekoderowi dynamiczny dostęp do pełnego zbioru cech obrazu na każdym etapie generowania sekwencji wyjściowej. Dzięki temu model może selektywnie skupiać się na najbardziej relewantnych w danym momencie fragmentach obrazu, w zależności od aktualnie przetwarzanego słowa i ogólnego kontekstu zdania. Formalnie, w architekturze z mechanizmem uwagi, predykcja słowa w kroku czasowym $t$ jest warunkowana nie tylko stanem ukrytym dekodera $\mathbf{h_t}$, ale również wektorem kontekstu $\mathbf{z_t}$, zgodnie z formułą~\cite{Bahdanau2015NeuralMT}:

\begin{equation}
    p(y_t | y_1, ..., y_{t-1}, I) = f(\mathbf{h}_t, \mathbf{z}_t)
\end{equation}
Formuła jest identyczna dla klasycznego modelu koder-dekoder. Jednakże w wariancie klasycznym wektor kontekstu jest statyczny $\mathbf{z_t = v}$, gdzie $\mathbf{v}$ to pojedynczy, zagregowany wektor, całej mapy cech obrazu $\mathbf{V}$. W wariancie z uwagą jest on w każdym kroku czasowym obliczany na nowo. Dzięki temu zależności między obrazem a tekstem modelowane są na nowo w każdym kroku czasowym.

\subsection{Podstawowy mechanizm uwagi miękkiej}
Uwaga miękka (\gls{gls:soft-attention}) to jeden z pierwszych wariantów mechanizmu uwagi, który zastosowano w zadaniu automatycznego podpisywania obrazów. Metoda ta stała się bazą dla bardziej zaawansowanych architektur.

Model z uwagą miękką jako wejście przyjmuje mapę cech o odpowiednio wysokości, szerokości i liczbie kanałów $w \times s \times d$, wygenerowaną przez splotową sieć neuronową. Mapa ta jest następnie interpretowana jako zbiór $l = w \times s$ wektorów cech obrazu $\mathbf{V= \{v}_1, \dots, \mathbf{v}_l\}$, gdzie każdy d-wymiarowy wektor $\mathbf{v}_i$ stanowi reprezentację cech wizualnych dla $i$-tego fragmentu obrazu.

Proces generowania podpisu do obrazu rozpoczyna się od ustalenia początkowych wartości stanu ukrytego $\mathbf{h}_0$ oraz stanu komórki $\mathbf{c}_0$ komórki LSTM w dekoderze. Wartości te są wyznaczane na podstawie globalnego wektora kontekstu obrazu, obliczanego jako średnia arytmetyczna $l$ wektorów cech obrazu $\mathbf{V}$:
\begin{equation}
    \bar{\mathbf{v}} = \frac{1}{l}\sum_{i=1}^{l} \mathbf{v}_i.
\end{equation}
Następnie, wektor $\bar{\mathbf{v}}$ jest przetwarzany przez dwie oddzielne, jednowarstwowe sieci neuronowe $f_{\mathbf{h}_0}$ oraz $f_{c_0}$ w celu uzyskania odpowiednio początkowego stanu ukrytego $\mathbf{h}_0$ oraz stanu komórki $\mathbf{c}_0$.

Predykcji kolejnych słów dla $t>0$ ma charakter iteracyjny. Dla każdego kroku czasowego $t$ mechanizm uwagi dokonuje oceny istotności każdego wektora $\mathbf{v}_i$ w kontekście stanu ukrytego dekodera z poprzedniego kroku $\mathbf{h}_{t-1}$. W tym celu stosowana jest jednowarstwowa sieć neuronowa, która dla każdej z $l$ wektorów cech oblicza ocenę skalarną $e_{t,i}$ warunkowaną na poprzednim stanie ukrytym $\mathbf{h}_{t-1}$. Wartość ta określa stopień, w jakim dany fragment obrazu jest istotny dla predykcji aktualnego słowa $y_t$~\cite{Xu2015ShowAttendTell, Bahdanau2015NeuralMT}:
\begin{equation}
    \mathbf{e_{t,i} =r}^T \tanh(\mathbf{W}_v \mathbf{h}_{t-1} + \mathbf{U}_v \mathbf{v}_i + \mathbf{b}_v),
\end{equation}
gdzie $\mathbf{W}_v, \mathbf{U}_v$ to uczone macierze wag, a $\mathbf{r}$ to również uczony wektor wag, których model uczy się podczas treningu. Ich zadaniem jest przekształcenie danych wejściowych i stanu ukrytego w taki sposób, aby można było obliczyć ich wzajemne dopasowanie.
Uzyskane w ten sposób wyniki dopasowania dla wszystkich $l$ fragmentów są normalizowane funkcją softmax. W efekcie powstaje rozkład wag uwagi $\boldsymbol{\alpha}_t$, którego elementy sumują się do jedności. Można go interpretować jako dyskretny rozkład prawdopodobieństwa, określający skupienie uwagi modelu na poszczególnych fragmentach obrazu:
\begin{equation}
\boldsymbol{\alpha}_{t,i} = \frac{\exp(e_{t,i})}{\sum_{m=1}^{l} \exp(e_{t,m})}.
\end{equation}

Finalnie obliczany jest wektor kontekstu $\mathbf{z}_t$ jako ważona suma wszystkich wektorów cech $\mathbf{v}_i$, gdzie wagami są wyznaczone wcześniej wagi uwagi $\alpha_{t,i}$:
\begin{equation}
    \mathbf{z}_t = \sum_{i=1}^{l} \alpha_{t,i} \mathbf{v}_i.
    \label{eq:uwaga_miekka_wektor_kontekstu}
\end{equation}

Wektor kontekstu $\mathbf{z}_t$ stanowi syntetyczną reprezentację wizualną, w której regiony o wyższych wagach uwagi mają większy wpływ na proces generowania słowa $y_t$. Tak obliczony wektor kontekstu jest następnie konkatenowany z osadzeniem poprzednio wygenerowanego słowa $y_{t-1}$ i podawany jako wejście do sieci LSTM w bieżącym kroku czasowym: $\mathbf{x}_t=[\mathbf{e(y_{t-1})}, \mathbf{z}_t]$. Zaktualizowany stan ukryty $\mathbf{h}_t$ służy do predykcji rozkładu prawdopodobieństwa nad słownikiem dla słowa $y_t$. W ten sposób wygenerowane słowo wpływa na to, gdzie model skupi uwagę w kolejnym kroku, a cechy wizualne, na których skupiono uwagę, wpływają na dalsze generowanie sekwencji, tworząc pętlę zwrotną między modalnością wizualną a językową.

W odróżnieniu od opisanego deterministycznego mechanizmu, wprowadzono również jego stochastyczny wariant – uwagę twardą. Zamiast wykorzystywać ważoną sumę wszystkich wektorów cech, uwaga twarda w sposób probabilistyczny próbkuje jeden region obrazu $s_t$ w każdym kroku czasowym, a wektor kontekstu jest tożsamy z wektorem cech z tej lokalizacji: $\mathbf{z}_t = \mathbf{v}_{s_t}$. Mimo potencjalnie niższych kosztów obliczeniowych w fazie inferencji, trening modeli z uwagą twardą jest znacznie bardziej złożony i wymaga złożonych metod treningu.

Bazowy mechanizm uwagi miękkiej stał się punktem wyjścia dla szeregu wariantów mechanizmu uwagi, których celem było zwiększenie efektywności modelowania wizualno-językowego.

\subsection{Uwaga przestrzenna -- udoskonalenie przepływu informacji}
Chociaż mechanizm uwagi miękkiej stanowił przełom, badacze szybko zidentyfikowali potencjalne obszary do ulepszeń. Doprowadziło to do rozwoju wariantów mających na celu optymalizację przepływu informacji oraz efektywności wykorzystania kontekstu wizualnego.

Uwaga przestrzenna (\gls{gls:spatial-attention}) to modyfikacja opisanego wcześniej mechanizmu uwagi miękkiej. Różnica architektoniczna polega na uzależnieniu wektora kontekstu wizualnego $\mathbf{z}_t$ od bieżącego stanu ukrytego dekodera $\mathbf{h}_t$, a nie, jak poprzednio, od stanu z poprzedniego kroku czasowego $\mathbf{h}_{t-1}$. Taka zmiana implikuje, że model w danym kroku poszukuje informacji wizualnej, która jest zgodna z wiedzą już zakodowaną w jego aktualnym stanie.

W tym wariancie, proces obliczania wag uwagi jest inicjowany przez bieżący stan ukryty $\mathbf{h}_t$ sieci LSTM. Surowe wagi uwagi $\mathbf{e}_t$ nad $l$ fragmentami obrazu, reprezentowanymi przez mapę cech $\mathbf{V}$, są generowane za pomocą jednowarstwowej sieci neuronowej:
\begin{equation}
    \mathbf{e}_{t,i} = \mathbf{w_h}^T \tanh(\mathbf{W}_v \mathbf{V} + (\mathbf{W}_g \mathbf{h}_t)\mathbf{1}^T ),
\end{equation}

gdzie $\mathbf{W}_v$, $\mathbf{W}_g$ oraz $\mathbf{w}_h$ są uczonymi parametrami modelu. Uzyskane w ten sposób wyniki są następnie, analogicznie do uwagi miękkiej, normalizowane za pomocą funkcji softmax w celu wygenerowania rozkładu uwagi $\mathbf{\alpha_t}$ nad $l$ fragmentami obrazu. Na podstawie tego rozkładu obliczany jest wektor kontekstu $\mathbf{z}_t$ jako ważona suma wektorów cech poszczególnych regionów:
\begin{equation}
    \mathbf{z}_t = \sum_{i=1}^{l} \alpha_{ti} \mathbf{v}_{i}
        \label{eq:uwaga_przestrzenna_wektor_kontekstu}
\end{equation}

Finalnie, do predykcji kolejnego słowa $y_{t+1}$ wykorzystywana jest połączona informacja z wektora kontekstu $\mathbf{z}_t$ oraz bieżącego stanu ukrytego $\mathbf{h}_t$, na przykład poprzez ich zsumowanie i przetworzenie przez warstwę wyjściową.

\subsection{Uwaga adaptacyjna}
Standardowe mechanizmy uwagi, takie jak uwaga miękka oraz uwaga przestrzenna, narzucają konieczność wykorzystania przez sieć neuronową cech obrazu dla predykcji każdego kolejnego słowa w generowanej sekwencji. Takie podejście jest nieefektywne w przypadku predykcji słów o charakterze niewizualnym, takich jak spójniki czy przedimki, dla których dekoder wymaga jedynie ograniczonej ilości informacji wizualnej, bądź nie potrzebuje jej wcale. Ponadto, niektóre słowa, mimo swojego wizualnego charakteru, mogą być wiarygodnie przewidziane jedynie na podstawie wiedzy lingwistycznej zgromadzonej w dekoderze; przykładowo, słowo "sign" następujące po sekwencji "behind a red stop". W takich przypadkach obligatoryjne stosowanie mechanizmu uwagi może prowadzić do nieefektywnej alokacji zasobów obliczeniowych oraz potencjalnie degradować jakość generowanych opisów.

Rozwiązaniem tego problemu jest wprowadzenie mechanizmu uwagi adaptacyjnej, który reguluje stopień, w jakim model opiera się na cechach wizualnych podczas predykcji danego słowa. Mechanizm ten stanowi rozszerzenie koncepcji uwagi przestrzennej o dodatkowy komponent strażnika wizualnego $\mathbf{s}_t$, którego działanie jest regulowane przez bramkę.

Strażnik wizualny to alternatywne źródło informacji kontekstowej, gdy model decyduje o zmniejszeniu wpływu danych wizualnych. Wektor $\mathbf{s}_t$ reprezentuje wiedzę już zakodowaną w wewnętrznym stanie komórki LSTM, która obejmuje zarówno kontekst lingwistyczny, jak i przetworzone wcześniej cechy wizualne. Jest on uzyskiwany poprzez modyfikację standardowej architektury LSTM:

\begin{equation}
    \mathbf{s}_{t} = \boldsymbol{\beta}_{t} \odot \tanh(\mathbf{c}_{t}),
\end{equation}
\begin{equation}
    \boldsymbol{\beta}_{t} = \sigma(\mathbf{W}_{x}\mathbf{x}_{t} + \mathbf{W}_{h}\mathbf{h}_{t-1}),
\end{equation}
gdzie $\boldsymbol{\beta}_t$ jest wektorem bramki strażnika wizualnego, $\sigma$ to funkcja sigmoidalna, $\mathbf{c}_t$ jest wektorem stanu komórki LSTM, a $\odot$ oznacza iloczyn Hadamarda, $\mathbf{W}_x$ oraz $\mathbf{W}_h$ są macierzami wag podlegającymi uczeniu.

Finalny, adaptacyjny wektor kontekstu $\mathbf{z}_{t}$, wykorzystywany do predykcji słów, to ważona kombinacja przestrzennego wektora kontekstu $\mathbf{\hat{z}}_t$ z modelu uwagi przestrzennej, obliczonego według wzoru~\ref{eq:uwaga_przestrzenna_wektor_kontekstu} oraz wektora strażnika wizualnego $\mathbf{s}_t$:

\begin{equation}
    \mathbf{z}_{t} = \boldsymbol{\beta}_{t}\mathbf{s}_{t} + (1-\boldsymbol{\beta}_{t})\mathbf{\hat{z}}_{t}. \label{eq:uwaga_adaptacyjna_wektor_kontekstu}
\end{equation}

Proporcje obu składowych w kroku czasowym $t$ są determinowane przez bramkę strażnika $\boldsymbol{\beta}_t$, która kontroluje stopień, w jakim dekoder opiera swoje predykcje na przestrzennym kontekście wizualnym $\mathbf{\hat{z}}_t$ w stosunku do wewnętrznie wygenerowanego wektora strażnika wizualnego $\mathbf{s}_t$. Bramka jest obliczana na podstawie znormalizowanego rozkładu uwagi $\hat{\boldsymbol{\alpha}}_{t}$ nad przestrzennymi cechami obrazu oraz wektorem strażnika wizualnego:
\begin{equation}
    \mathbf{\hat{\alpha}_{t}} = \text{softmax}([\mathbf{e}_t; \mathbf{w_{h}}^{T}\tanh(\mathbf{W_s s_t} + \mathbf{W_{b}}\mathbf{h}_{t})]),
\end{equation}
gdzie $\mathbf{e_t}$ to oceny uwagi dla regionów obrazu, a operacja $[;]$ oznacza konkatenację wektorów. Wartość $\boldsymbol{\beta}_t$ jest ostatnim elementem wektora $\mathbf{\hat{\alpha}_{t}}$.

Dzięki temu, im wartość $\boldsymbol{\beta}_t$ jest bliższa 1, tym w większym stopniu predykcja opiera się na informacjach pochodzących ze strażnika wizualnego $\mathbf{s}_t$. Z drugiej strony, jeżeli $\boldsymbol{\beta}_t$ zbliża się do wartości 0, model przewiduje kolejne słowo, polegając na przestrzennym wektorze kontekstu $\mathbf{\hat{z}}_t$. Rozkład prawdopodobieństwa wygenerowania słów ze słownika jest obliczany na podstawie zsumowanego adaptacyjnego wektora kontekstu oraz wyjściowego stanu ukrytego $\mathbf{h}_t$ z sieci LSTM.




\subsection{Zmiana paradygmatu -- uwaga własna i mechanizmy hybrydowe}
\label{rozdzial:uwaga_wlasna}
W odróżnieniu od mechanizmów uwagi, które obliczają korelacje między zapytaniem z dekodera a cechami obrazu, mechanizm uwagi własnej (\gls{gls:self-attention}) operuje wyłącznie w obrębie jednego zbioru wektorów wejściowych. Jego celem jest modelowanie wzajemnych zależności pomiędzy tymi wektorami. W kontekście kodera obrazu, wejście jest reprezentowane jako zbiór  $l$ wektorów cech $\mathbf{V} = \{\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_l\}$, z których każdy odpowiada za określony region obrazu. Mechanizm uwagi własnej umożliwia każdemu regionowi uwzględnienie informacji z innych regionów. W rezultacie model jest w stanie lepiej zrozumieć relacje przestrzenne i semantyczne między elementami sceny, zanim informacja wizualna zostanie przekazana do dekodera.

Mechanizm uwagi własnej opiera działanie na macierzach $\mathbf{Q}$, $\mathbf{K}$ i $\hat{\mathbf{V}}$, które są odrębnymi reprezentacjami wejściowych wektorów cech obrazu $\mathbf{V}$. Projekcje te są realizowane poprzez mnożenie wejściowej macierzy $\mathbf{V}$ przez trenowane macierze wag $\mathbf{W}_Q$, $\mathbf{W}_K$, $\mathbf{W}_V$, zgodnie z formułami:
\begin{equation}
    \mathbf{Q = V \space W}_Q, \quad \mathbf{K = V \space W}_K, \quad \mathbf{\hat{V} = V \space W}_{\hat{V}}.
\end{equation}

Wynikowa macierz uwagi to ważona suma wektorów wartości $\hat{\mathbf{V}}$, gdzie wagi określają zgodność zapytań $\mathbf{Q}$ z kluczami $\mathbf{K}$. Zgodność obliczana jest poprzez skalowaną uwagę skalarną:
\begin{equation}
    \text{Uwaga}(\mathbf{Q, K, \hat{V}}) = \text{softmax}\left(\frac{\mathbf{QK}^T}{\sqrt{d_k}}\right)\mathbf{V}.
    \label{eq:self_attention}
\end{equation}
Czynnik skalujący $\frac{1}{\sqrt{d_k}}$ stabilizuje gradienty podczas treningu, zapobiegając sytuacji, w której duże wartości iloczynu skalarnego prowadzą do nasycenia funkcji softmax.

Mechanizm uwagi własnej wielogłowicowej stanowi rozszerzenie koncepcji uwagi własnej. Zamiast pojedynczej operacji uwagi, model równolegle przetwarza informacje w $n$ podprzestrzeniach reprezentacji.
Dla każdej z $n$ głowic, wejściowe macierze zapytań $\mathbf{Q}$, kluczy $\mathbf{Q}$ i wartości $\hat{\mathbf{V}}$ są najpierw poddawane odrębnym transformacjom liniowym, tworząc $\mathbf{Q}_i$, $\mathbf{K}_i$ oraz $\hat{\mathbf{V}}_i$. Następnie, dla każdej głowicy $i \in \{1, ..., n\}$, funkcja uwagi jest obliczana niezależnie:
\begin{equation}
    head_i = \text{Uwaga}(\mathbf{Q_i, K_i, \hat{V}_i}).
\end{equation}
Wyniki uzyskane dla poszczególnych głowic są następnie konkatenowane, a powstała w ten sposób macierz jest przekształcana za pomocą kolejnej projekcji liniowej. Celem tej operacji jest integracja informacji pochodzących z różnych podprzestrzeni:
\begin{equation}
    f_{mh-att}(\mathbf{Q, K, \hat{V}}) = [head_1, ..., head_n] \label{wzor:uwaga_wieloglowicowa}.
\end{equation}
Dzięki temu każda głowica może wyspecjalizować się w wykrywaniu innego rodzaju relacji, co znacząco zwiększa zdolność modelu.

Architektura AoANet stanowi przykład zaawansowanego modelu hybrydowego, który wykorzystuje zarówno uwagę własną, jak i nowatorski moduł do oceny adekwatności wyniku uwagi.

Standardowy mechanizm uwagi generuje wektor wyjściowy niezależnie od tego, czy znaleziono faktycznie istotne informacje. Aby rozwiązać ten problem, autorzy AoANet wprowadzili moduł AoA, który ocenia i filtruje wynik mechanizmu uwagi. 

Moduł ten, dla danego tensora zapytania $Q$ i rezultatu uwagi własnej $f_{att}(Q,K,\hat{V})$ generuje tensor informacji $I$ oraz tensor bramki uwagi $B$:
\begin{equation}
I= \mathbf{W_{QI}} Q + \mathbf{W_{VI}} f_{mh-att}(Q,K,\hat{V})) + b_I,
\end{equation}
\begin{equation}
B= \sigma(\mathbf{W}_{QB}Q + \mathbf{W}_{VB} f_{mh-att}(Q,K,\hat{V}) + b_{B}),
\end{equation}
gdzie $f_{mh-att}(Q,K,\hat{V})$ obliczane jest według wzoru na uwagę wielogłowicową~\ref{wzor:uwaga_wieloglowicowa} opisaną w rozdziale~\ref{rozdzial:uwaga_wlasna}. 
Finalnie rezultat przetwarzania przez moduł $AoA$ to iloczyn Hadamarda tensora informacji $I$ oraz tensora bramki uwagi $B$:
\begin{equation}
    AoA(f_{mh-att},Q,K,\hat{V})= B \odot I.
\end{equation}
Dzięki elastyczności rozwiązania, jakim jest moduł $AoA$, rezultatem iloczynu w koderze z modułem $AoA$ jest macierz, a w przypadku dekodera z modułem $AoA$ wektor. Bramka $B$ selektywnie wzmacnia lub osłabia składowe tensora informacji $I$. Jest to swoisty filtr, który podczas treningu uczy się oczekiwanej wiedzy. Co istotne, parametry tensora $I$ oraz bramki uwagi $B$ są niezależnie trenowane.

Architektura AoANet rozszerza standardową architekturę koder-dekoder o moduły AoA w koderze i dekoderze nazwane odpowiednio $AoA_e \quad AoA_d$, które udoskonalają wyjściowe cechy wizualne w obu modułach.

Koder działa dwuetapowo, w pierwszym kroku obliczana jest uwaga wielogłowicowa $f_{mh-att}$, aby zamodelować relacje między regionami obrazu, zgodnie z procedurą opisaną w rozdziale~\ref{rozdzial:uwaga_wlasna}. Uzyskany rezultat jest przetwarzany przez moduł $AoA_e$, który ocenia istotność tych relacji dla globalnej reprezentacji obrazu. Proces ten jest powtarzany kilkukrotnie, a rezultat jest sumowany z oryginalną macierzą cech obrazu $\mathbf{V}$ i normalizowany. Finalna macierz udoskonalonych cech obrazu $\mathbf{V'}$ jest przekazywana do dekodera:
\begin{equation}
\mathbf{V'} = \text{LayerNorm}(\mathbf{V} + AoA_e(f_{mh-att}, \mathbf{W_{Qe} V, W_{Ke} V, W_{\hat{V}e} V)}).
\end{equation}

Dekoder z modułem AoA jest oparty na LSTM i generuje podpis słowo po słowie. W każdym kroku $t$, sieć LSTM najpierw integruje informacje o dotychczas wygenerowanym fragmencie zdania z ogólnym kontekstem wizualnym obrazu. Na tej podstawie aktualizuje swój wewnętrzny stan ukryty $\mathbf{h}_t$. Zaktualizowany stan ukryty $\mathbf{h}_t$ pełni rolę zapytania $Q$ dla modułu AoA w dekoderze $AoA^d$. Moduł ten, wykorzystując udoskonalone cechy obrazu $\mathbf{v'}$ jako klucze $K$ i wartości $\hat{V}$, oblicza nowy wektor kontekstu wizualnego:
\begin{equation}
    \mathbf{z_t}= AoA_d(f_{mh-att}, \mathbf{W_{Qd} [h_t], W_{Kd} V', W_{Vd} V'}),
    \label{eq:uwaga_własna_wektor_kontekstu}
\end{equation}
gdzie $f_{mh-att}$ to standardowy mechanizm uwagi wielogłowicowej omówiony w poprzedniej sekcji.

Tak obliczony wektor kontekstu $\mathbf{z}_t$ służy do obliczenia rozkładu prawdopodobieństwa nad całym słownictwem:
\begin{equation}
    p(y_t | y_{1:t-1}, I) = \text{softmax}(\mathbf{W}_p(\mathbf{h}_t + \mathbf{z}_t)).
\end{equation}
Dzięki temu dwuetapowemu procesowi uwagi, AoANet jest w stanie generować bardziej precyzyjne i trafne opisy.

\subsection{Podsumowanie i wpływ mechanizmu uwagi}

Wprowadzenie mechanizmu uwagi stanowiło kluczowy krok w ewolucji architektur do generowania podpisów do obrazów, poprzez umożliwienie dekoderowi dynamicznego dostępu do pełnej, niezmienionej reprezentacji cech obrazu na każdym etapie generowania sekwencji wyjściowej. W efekcie powstawały bardziej kontekstowo adekwatne podpisy.

Mechanizm uwagi umożliwia monitorowanie działania modelu, a dzięki temu zrozumienie jego działania. Wagi uwagi $\alpha_{ti}$ można wizualizować w postaci map ciepła nałożonych na obrazy wejściowe, co pozwala śledzić, które fragmenty obrazu model uważa za istotne w trakcie predykcji poszczególnych słów. Dzięki temu można zrozumieć globalnie kroki postępowania modelu~\cite{Xu2015ShowAttendTell}..

Sukces mechanizmu uwagi w efektywnym modelowaniu zależności między wejściem a wyjściem stał się bezpośrednią inspiracją dla powstania architektur, takich jak transformator~\cite{Vaswani2017AttentionIA}.Obecnie architektura transformatorowa zyskuje coraz większą popularność w zadaniach automatycznego generowania podpisów do obrazów~\cite{Cahyono2024automatedimagecaptioningcnns}. Rozwój metod z uwagą, od modeli CNN-RNN aż po architektury oparte wyłącznie na tym mechanizmie, podkreśla fundamentalne znaczenie tego rozwiązania dla postępu w modelowaniu sekwencyjnym i multimodalnym~\cite{Sutskever2014Seq2Seq, Cho2014Learning}.

\chapter{Zbiory danych i ewaluacja rezultatów}
\label{rozdzial:metryki}
Zbiory danych w zadaniu automatycznego generowania podpisów do obrazów składają się z par obraz–podpisy. Ich zróżnicowanie, poprawność leksykalna, gramatyczna i syntaktyczna warunkują efektywność modeli, a jednocześnie sprawiają, że ocena jakości generowanych podpisów jest zadaniem złożonym i wieloaspektowym, zarówno na poziomie technicznym, jak i językowym~\cite{Reiter2009Investigation}.  

W niniejszym rozdziale dokonano przeglądu dostępnych zbiorów danych oraz metod ewaluacji rezultatów modeli do automatycznego podpisywania obrazów. Omówiono zbiory danych, takie jak Microsoft COCO, czy Google Conceptual Captions, a następnie przeprowadzono analizę metryk ewaluacyjnych, rozpoczynając od klasycznych opartych na n-gramach, jak BLEU, czy ROUGE, METEOR, CIDEr przez metryki uwzględniające aspekty semantyczne, jak  SPICE, czy WMD. Rozdział zamyka omówienie roli i metodologii oceny ludzkiej jako ostatecznego weryfikatora jakości generowanych podpisów.


\section{Zbiory danych}
\input{tabele/zbiory_danych_zestawienie}
\input{zdjecia/przykladowe_zdjecia_zbiory/przykladowe_zdjecia_zbiory}
Zbiory danych w zadaniu automatycznego generowania podpisów do obrazów pełnią dwie funkcje. Po pierwsze, są fundamentem, na którym model uczy się zależności między domeną wizualną a językową, z drugiej zaś, służą jako punkt odniesienia do obiektywnej ewaluacji i porównywania postępów w tej dziedzinie. Jakość i przydatność zbioru danych są determinowane przez następujące atrybuty.

Po pierwsze zbiór danych powinien odzwierciedlać szerokie spektrum scen, obiektów, atrybutów oraz interakcji spotykanych w rzeczywistym świecie. Obejmuje to zarówno zróżnicowanie tematyczne (np. sceny przyrodnicze, miejskie, portrety), jak i formalne (np. fotografie, grafiki, obrazy o różnym oświetleniu i kompozycji). Wysoka wariancja wizualna w danych treningowych warunkuje zdolność modelu do generalizacji, szczególnie w przypadku nieobserwowanych dotąd danych.

Równie istotnym aspektem jest charakterystyka lingwistyczna i stylistyczna podpisów tekstowych, która bezpośrednio wpływa na zdolność modelu do generowania językowo naturalnych i adekwatnych opisów. W tym kontekście wyróżnia się podpisy denotacyjne i konotacyjne. Podpisy denotacyjne koncentrują się na obiektywnym przedstawieniu treści wizualnej. Wymieniają obecne obiekty, ich cechy oraz relacje przestrzenne między nimi. Ten typ podpisu dominuje w standardowych zbiorach, takich jak MS COCO.

Podpisy konotacyjne prócz faktów mogą zawierać dodatkowe informacje, takie jak interpretacje kulturowe, emocjonalne, czy wnioski na temat przedstawionej sytuacji. Generowanie tego typu podpisów wymaga od modelu nie tylko rozpoznawania, ale i rozumienia sceny wizualnej.

Specyfikę podpisów warunkuje również  źródło ich akwizycji. Dane pozyskiwane w sposób kontrolowany, jak w przypadku platformy Amazon Mechanical Turk cechują się wysoką jakością i spójnością, co jest pożądane podczas treningu i ewaluacji. Z kolei zbiory pozyskiwane automatycznie (np. z mediów społecznościowych) oferują znacznie większą skalę i różnorodność językową, jednak ich wadą jest wysoki poziom szumu informacyjnego, co stawia dodatkowe wyzwania na etapie przetwarzania wstępnego.

Podsumowując, świadomość powyższych cech jest podstawą do adekwatnego doboru zbioru danych do problemu badawczego oraz dla prawidłowej interpretacji wyników ewaluacji. Dostosowanie charakterystyki danych treningowych do domeny docelowej, np. medycyny, sztuki czy prawa, stanowi krytyczny czynnik warunkujący skuteczność finalnego modelu.

W dalszej części zostaną omówione najważniejsze zbiory danych, począwszy od podstawowego Flickr. Zestawienie ich najważniejszych atrybutów przedstawiono w Tabeli~\ref{tab:zbiory_danych_zestawienie}, a przykłady obrazów z odpowiadającymi im podpisami na Rysunku~\ref{fig:przykladowe_zdjecia_zbiory}.

Szerszy przegląd zbiorów danych stosowanych w wizji komputerowej i przetwarzaniu języka naturalnego, wykraczający poza samo zadanie generowania podpisów, można znaleźć w opracowaniu~\cite{Ferraro2015Survey}. Praca ta obejmuje dodatkowe analizy statystyczne dotyczące złożoności syntaktycznej czy semantyki podpisów.

\subsection{Flickr}
Jednymi z pierwszych zbiorów danych, które ukształtowały wczesne badania nad generowaniem automatycznych podpisów do obrazów, są kolekcje Flickr8k~\cite{Hadosh2013Framing} oraz jego późniejsze rozszerzenie, Flickr30k~\cite{Youngetal2014Image}. Obrazy do obu zbiorów pozyskano z serwisu Flickr, selekcjonując fotografie przedstawiające ludzi lub zwierzęta w trakcie dających się opisać czynności. Istotnym elementem obu zasobów jest ujednolicona metoda akwizycji podpisów, gdzie dla każdego obrazu zebrano pięć niezależnych, denotatywnych podpisów, wygenerowanych w ramach kontrolowanego procesu przez pracowników platformy Amazon Mechanical Turk.

Zbiór Flickr8k, wprowadzony w 2013 roku, liczy 8092 obrazy, dla których utrwalono standardowy podział na zbiór treningowy 6000, walidacyjny 1000 i testowy 1000. Wprowadzony rok później Flickr30k stanowi jego rozszerzenie do 31 783 fotografii, stworzony w odpowiedzi na rosnące zapotrzebowanie na większe zasoby niezbędne do trenowania bardziej złożonych modeli neuronowych. Standardowy podział liczy 28783 obrazy treningowe i 1000 obrazów w zbiorze testowym oraz walidacyjnym. 

\subsection{Microsoft COCO}
Bazując na doświadczeniach zdobytych przy tworzeniu wcześniejszych zasobów w 2014 roku, wprowadzono zbiór Microsoft COCO (Common Objects in Context)~\cite{Lin2014Microsoft, Chen2015microsoftCOCO}. Jest to jeden z najbardziej wpływowych zbiorów danych w badaniach nad automatycznym podpisywaniem obrazów. Jego opracowanie motywowane było potrzebą stymulowania postępów w analizie i rozpoznawaniu obiektów w ich naturalnym otoczeniu, z możliwie wiernym odzwierciedleniem złożoności i różnorodności rzeczywistych scen wizualnych. 

Realizację tego celu oparto na trzech założeniach. Po pierwsze, zbiór koncentruje się na obiektach w ich typowym kontekście, uwzględniając interakcje i wzajemne przesłanianie, co stanowiło odejście od analizy izolowanych instancji. Po drugie, w celu precyzyjnego prognozowania lokalizacji, zamiast tradycyjnych ramek ograniczających (\gls{gls:bounding-box}), wprowadzono adnotacje na poziomie masek segmentacyjnych. Po trzecie, w kontekście generowania podpisów, istotne było stworzenie podstaw do badań nad holistycznym rozumieniem sceny. Ten cel osiągnięto poprzez zebranie pięciu unikalnych ludzkich podpisów dla każdego obrazu.

Cechą wyróżniającą Microsoft COCO jest jego wielozadaniowy charakter. W przeciwieństwie do zasobów wyspecjalizowanych, integruje on na tych samych obrazach adnotacje umożliwiające prowadzenie badań w wielu komplementarnych dziedzinach widzenia komputerowego. Jest to detekcja obiektów z wykorzystaniem ramek ograniczających, segmentacja instancji przez maski, analiza postawy człowieka oraz generowanie podpisów.

Procedura budowy zasobu była wieloetapowa i realizowana z wykorzystaniem platformy Amazon Mechanical Turk. Proces rozpoczęto od zdefiniowania 91 kategorii powszechnie występujących obiektów. Następnie, przy użyciu zapytań ukierunkowanych na sceny o dużej gęstości obiektów, pozyskano obrazy z serwisu Flickr. W kolejnym kroku pracownicy dokonywali wstępnej klasyfikacji, oznaczając obecność obiektów z predefiniowanych kategorii. Po tej weryfikacji inna grupa pracowników, posługując się dedykowanym narzędziem, dokonywała segmentacji poprzez wyznaczanie dokładnych konturów każdej instancji obiektu. Zgromadzony w ten sposób zbiór przefiltrowano, aby wyeliminować obrazy o nieodpowiednich wymiarach lub te, które nie spełniały założonych kryteriów kompozycyjnych. 

Finalnym etapem było pozyskiwanie podpisów. Każdy obraz przedstawiono pięciu niezależnym pracownikom, których zadaniem było sformułowanie zwięzłego zdania opisującego scenę, ze szczególnym uwzględnieniem obiektów i relacji między nimi. Rozdzielenie zadań i zaangażowanie wielu niezależnych osób gwarantowało obiektywizm oraz różnorodność językową tworzonych podpisów. Proces ten był wspierany przez mechanizmy walidacji i kontroli jakości, które obejmowały zarówno ocenę automatyczną, jak i weryfikację przez kolejną grupę niezależnych recenzentów.

W rezultacie powstał zbiór zawierający łącznie 164062 obrazów, na których oznaczono 2,5 miliona instancji obiektów należących do 91 kategorii, przy średniej gęstości 7,7 obiektu na obraz. Zbiór testowy zawiera 40775 obrazów, gdzie podpisy nie są dostępne publicznie. Co istotne, MS COCO dostarcza pięć niezależnych, unikalnych podpisów w języku naturalnym, gdzie każdy został stworzony przez innego człowieka. Dzięki temu podpisy odzwierciedlają różnorodność ludzkiej percepcji i języka. Dostarczają nie tylko bogatego materiału do trenowania modeli, ale również umożliwiają stosowanie zaawansowanych metryk ewaluacyjnych, takich jak CIDEr.

Obok oficjalnej dystrybucji danych, w badaniach nad generowaniem podpisów standardowo stosuje się podział zaproponowany przez Andreja Karpathy’ego~\cite{Karpathy2015Deep}, gdzie dokonano reorganizacji oryginalnego zbioru treningowego i walidacyjnego. Zdefiniowano zbiór testowy liczący 5000 obrazów oraz zbiór walidacyjny o tej samej wielkości. Pozostałe 113287 obrazów z oryginalnych zasobów treningowych i walidacyjnych przeznaczono na zbiór treningowy.

Dzięki swojej skali, złożoności oraz jakości adnotacji, Microsoft COCO stał się standardem w trenowaniu i ocenie modeli do automatycznego generowania podpisów do obrazów. Wprowadzona w 2017 roku aktualizacja zbioru zoptymalizowała podział danych. Większość obrazów z zestawu walidacyjnego z 2014 roku została włączona do zbioru treningowego, natomiast sam zbiór walidacyjny został istotnie zredukowany. Zmiana ta miała na celu przyspieszenie iteracyjnych cykli trenowania i ewaluacji modeli. Do dnia dzisiejszego MS COCO jest jednym z najważniejszych i najpowszechniej stosowanych zasobów badawczych w tej domenie.


\subsection{Google’s Conceptual Captions}
W odróżnieniu od precyzyjnie adnotowanych, lecz kosztownych w akwizycji zbiorów danych, zbiór GCC (Google’s Conceptual Captions)~\cite{Piyush2018Conceptual} opublikowany w 2018, odchodzi od ręcznego podpisywania obrazów, prezentując w pełni zautomatyzowane podejście do akwizycji danych na masową skalę. GCC powstał w wyniku ekstrakcji i wieloetapowej filtracji par obraz–tekst z miliardów stron internetowych. W efekcie zgromadzono 3346732 par obrazów z podpisami w języku angielskim.

Podstawowym źródłem danych tekstowych dla GCC były atrybuty "alt-text" (tekst alternatywny) powiązane z obrazami w kodzie HTML. Atrybuty te, pierwotnie zaprojektowane w celu poprawy dostępności cyfrowej, dostarczyły ogromnej liczby podpisów do obrazów. Dane te charakteryzowały się jednak znaczną niejednorodnością i zawierały liczne treści nierelewantne, takie jak komunikaty nawigacyjne czy słowa kluczowe.

W celu oczyszczania danych wprowadzono wieloetapowy potok przetwarzania. W pierwszym kroku usuwano podpisy zbyt krótkie lub zbyt długie, zawierające znaki specjalne, a także te, które z dużym prawdopodobieństwem nie stanowiły podpisu w języku naturalnym. Następnie zastosowano szereg filtrów opartych na modelach przetwarzania języka naturalnego oraz wizji komputerowej, aby usunąć nazwy własne, informacje nieopisowe oraz przypadki, w których tekst nie był semantycznie spójny z zawartością obrazu. Celem tego procesu było wyodrębnienie podpisów, które w sposób abstrakcyjny odnoszą się do sceny, a nie tylko dosłownie wyliczają widoczne obiekty.

Finalny zbiór danych podzielono na część treningową 3 318 333 pary, walidacyjną 15 840 par oraz testową 12 559 par. Fundamentalną zaletą GCC jest jego skala i różnorodność, które znacząco przewyższają zbiory adnotowane manualnie.

\subsection{Zbiór SBU}
Koncepcję wykorzystania zasobów internetowych do budowy wielkoskalowych zbiorów danych, rozwinięto również w przypadku zbioru SBU (Stony Brook University) Captioned Photo Dataset~\cite{Ordonez2011Im2Text}. W odróżnieniu od GCC, źródłem danych nie były atrybuty alt-text, lecz podpisy organicznie tworzone przez użytkowników serwisu Flickr. Zbiór ten obejmuje milion par obraz–podpis i został zaprojektowany z myślą o pozyskaniu podpisów charakteryzujących się większą naturalnością i różnorodnością językową niż te pochodzące z kontrolowanych procesów generowania podpisów.

Akwizycję danych oparto na zapytaniach do wyszukiwarki platformy. Zapytania te wykorzystywały  kombinacje wizualnie nacechowanych rzeczowników, czasowników, przymiotników i przyimków, aby pozyskać pełne, deskryptywne zdania. Zebrane w ten sposób dane poddano filtracji, gdzie odrzucono  zdania składające się z pojedynczego słowa, daty czy nazwy generowane przez aparaty fotograficzne. Istotnym kryterium selekcji był wymóg składniowy – każdy podpis musiał zawierać co najmniej jeden rzeczownik oraz jeden czasownik, co promowało zachowanie poprawnych gramatycznie, opisowych zdań.

Pomimo zastosowanych mechanizmów filtracji, istotnym ograniczeniem zbioru SBU jest wysoki poziom szumu informacyjnego w podpisach, będący nieodłączną konsekwencją automatycznej akwizycji. Ponadto, zarówno treść wizualna, jak i stylistyka językowa odzwierciedlają specyfikę serwisu Flickr z okresu, w którym dane były zbierane, co może wprowadzać stronniczość w modelach.

Przegląd zamykają zbiory danych o charakterze wyspecjalizowanym, zaprojektowane w celu adresowania konkretnych ograniczeń zbiorów ogólnego przeznaczenia lub eksploracji nowych aspektów zadania automatycznego generowania podpisów do obrazów.

\subsection{Visual Genome}
Zbiór danych Visual Genome~\cite{Krishna2016Visualgenome} opublikowany w 2016 roku, wprowadza fundamentalną zmianę w podejściu do podpisywania obrazów w porównaniu do klasycznych zbiorów koncentrujących się na globalnych podpisach sceny wizualnej, jak MS COCO czy Flickr30k. Całkowicie porzucono generowanie pojedynczego podpisu dla całego obrazu na rzecz gęstej adnotacji jego poszczególnych regionów, obiektów oraz relacji między nimi. Celem było stworzenie uporządkowanej, grafowej reprezentacji wiedzy o treści obrazu, celem jej głębokiego zrozumienia. 

Struktura adnotacji dla każdego z 108077 obrazów obejmuje siedem komponentów, takich jak obiekty i ich atrybuty, relacje między obiektami, opisy regionów, grafy regionów, grafy scen oraz pary pytanie–odpowiedź. Każdy obraz w zbiorze średnio zawiera adnotacje dla 35 obiektów, 26 atrybutów oraz 21 relacji, które są agregowane w postaci grafów scen.

Dzięki swojej bogatej i ustrukturyzowanej formie, Visual Genome stał się kluczowym zasobem nie tylko dla zadania generowania podpisów, ale również dla zadań wymagających złożonej interpretacji wizualnej, takich jak rozpoznawanie relacji między obiektami czy generowanie scen na podstawie opisu grafowego. Zbiór ten stanowi pomost między percepcją wizualną a obliczeniową reprezentacją wiedzy, stymulując rozwój modeli zdolnych do bardziej zaawansowanej analizy scen.

\subsection{TextCaps}
Standardowe modele automatycznego generowania podpisów często ignorują informację semantyczną zawartą w tekście obecnym na obrazach, traktując go jako nieistotny szum lub element tekstury. Wprowadzony w 2020 roku zbiór danych TextCaps~\cite{sidorov2019textcaps} został zaprojektowany w celu przezwyciężenia tego ograniczenia. Składa się z 28408 obrazów, do których zebrano średnio po pięć podpisów. Warunkiem poprawnego wygenerowania podpisu było odwołanie się do informacji tekstowej widocznej na obrazie. Zadanie to wymaga od modelu wykonania złożonej operacji, nie tylko zlokalizowania i rozpoznania tekstu za pomocą mechanizmów (\gls{ocr}), ale również jego integracji z globalnym kontekstem wizualnym w ramach spójnego gramatycznie i semantycznie zdania.

\section{Ewaluacja rezultatów}
Ewaluacja jakości automatycznie generowanych podpisów do obrazów, stanowi jedno z najbardziej złożonych wyzwań w dziedzinie przetwarzania języka naturalnego. W odróżnieniu od zadań o jednoznacznie zdefiniowanej odpowiedzi, takich jak klasyfikacja, dla pojedynczego obrazu może istnieć wiele semantycznie poprawnych i stylistycznie adekwatnych podpisów. Ta inherentna wieloznaczność sprawia, że ocena wygenerowanego podpisu wymaga zastosowania metod, które oceniają podpisy pod wieloma względami. W literaturze przedmiotu wykształciły się dwa paradygmaty ewaluacji: ilościowy, oparty na metrykach automatycznych, oraz jakościowy, bazujący na ocenie ludzkiej.

Metryki automatyczne stanowią zbiór algorytmów, które w sposób obiektywny i powtarzalny kwantyfikują podobieństwo pomiędzy podpisem wygenerowanym przez model (kandydującym) a zbiorem podpisów referencyjnych, stworzonych przez ludzi. Główną zaletą tego rodzaju metryk jest skalowalność, szybkość i niski koszt, co czyni je narzędziem w iteracyjnym procesie rozwoju i optymalizacji modeli. Ich wadą jest jednak to, że opierają się na analizie zgodności leksykalnej, więc stanowią jedynie aproksymację rzeczywistej jakości językowej i nie są w stanie uchwycić pełnego zakresu niuansów, poprawności gramatycznej, płynności czy adekwatności kontekstowej.

Alternatywą jest  ocena ludzka. Człowiek, w odróżnieniu od algorytmu, jest w stanie dokonać holistycznej oceny, uwzględniając wszystkie aspekty jakościowe podpisu – od wierności semantycznej względem obrazu, przez poprawność gramatyczną i stylistyczną, aż po jego naturalność i kreatywność. Metodologia ta jest jednak  procesem czasochłonnym, kosztownym i z natury subiektywnym, co może prowadzić do niskiej zgodności ocen między ewaluatorami.

W konsekwencji, rzetelna i wiarygodna ewaluacja systemów do automatycznego podpisywania obrazów wymaga kombinacji obu podejść. Metryki automatyczne służą jako podstawowe narzędzie do szybkiego budowania prototypu i porównywania architektur na dużą skalę, podczas gdy ocena ludzka stosowana jest do ostatecznej weryfikacji rzeczywistej jakości i użyteczności generowanych podpisów.


\subsection{Metryki oparte na n-gramach -- analiza zgodności leksykalnej}
Najszerzej stosowaną klasą metryk automatycznych są miary oparte na analizie zgodności n-gramów, czyli sekwencji $n$ sąsiadujących jednostek tekstowych, takich jak litery, sylaby lub słowa. Ich założenie polega na kwantyfikacji jakości podpisu kandydującego poprzez stopień, w jakim jego n-gramy pokrywają się z n-gramami obecnymi w zestawie podpisów referencyjnych. Przykładowo, unigramy (1-gramy) to pojedyncze słowa, bigramy (2-gramy) to pary sąsiadujących słów. Atutem tego podejścia jest prostota koncepcyjna, niska złożoność obliczeniowa oraz niezależność od specyfiki języka. Do tego rodzaju metryk zalicza się BLEU i ROUGE oraz bardziej zaawansowane lingwistycznie METEOR i zorientowany na konsensus CIDEr.

\subsubsection{BLEU}
\label{sekcja:bleu}
Metryka BLEU (Bilingual Evaluation Understudy)~\cite{Papineni2002Bleu} opiera się na kwantyfikacji zgodności n-gramów pomiędzy podpisem wygenerowanym (kandydujacym) a zbiorem podpisów referencyjnych. Wynik BLEU jest kompozycją dwóch komponentów, zmodyfikowanej precyzji n-gramów oraz kary za zwięzłość.

Istotnym elementem zmodyfikowanej precyzji n-gramów jest mechanizm przycinania, który zapobiega zawyżaniu wyniku poprzez nadmierne powtarzanie tych samych słów lub fraz. Mechanizm ten polega na ograniczeniu liczby wystąpień danego n-gramu w tekście kandydującym do maksymalnej liczby wystąpień tego n-gramu w dowolnym z zdań referencyjnych. Dzięki temu zmodyfikowana precyzja n-gramów uwzględnia nie tylko zgodność leksykalną podpisów, ale także ich naturalność językową i zgodność stylistyczną. Zmodyfikowaną precyzję $p_n$ dla n-gramów rzędu $n$ definiuje się formalnie jako:
\begin{equation}
    p_n = \frac{\sum_{g \in G_{\text{corpus}}} \text{count}_{\text{clip}}(g)}{\sum_{g \in G_{\text{corpus}}} \text{count}(g)},
\end{equation}
gdzie $\text{count}_{\text{clip}}(g)$ to minimum z dwóch wartości: całkowitej liczby wystąpień n-gramu $g$ w danym podpisie kandydującym oraz maksymalnej liczby jego wystąpień w dowolnym z podpisów referencyjnych. Z kolei mianownik, $\text{count}(g)$, to suma wszystkich wystąpień każdego n-gramu $g$ w podpisach kandydujących, co odpowiada ich łącznej liczbie w całym korpusie.

Drugim komponentem jest kara za zwięzłość (Brevity Penalty, BP), która przeciwdziała generowaniu zdań nadmiernie krótkich. Kara za zwięzłość skutecznie przeciwdziała strategii generowania krótkich, lecz ubogich w treść podpisów, co sprzyja tworzeniu bardziej informacyjnych i adekwatnych opisów. Definiuje ją wzór:
\begin{equation}
\text{BP} =
\begin{cases}
1 & \text{jeśli } \hat{c} > r ,\\
e^{1 - r/c} & \text{jeśli } \hat{c} \leq r,
\end{cases}
\end{equation}
gdzie $\hat{c}$ to łączna długość wszystkich zdań kandydujących, a $r$ to długość najbliższego (pod względem liczby słów) zdania referencyjnego dla każdego ze zdań kandydujących.

Ostateczna wartość metryki BLEU nie opiera się na precyzji n-gramów tylko jednego rzędu. Zamiast tego, oblicza się BLEU skumulowane, które uwzględnia precyzję dla n-gramów o różnej długości. Wynik BLEU-N jest średnią geometryczną zmodyfikowanych precyzji dla wszystkich rzędów n-gramów od 1 do n, z nałożoną karą za zwięzłość. Użycie średniej geometrycznej sprawia, że niska precyzja dla dowolnego rzędu n-gramów, jak $p_3$ lub $p_4$ istotnie obniża wynik końcowy, więc każda długość n-gramu jest równie ważna. Formalnie, skumulowany wynik $BLEU-N$ wyraża się wzorem:
\begin{equation}
    \text{BLEU-N} = \text{BP} \cdot \exp\left(\sum_{n=1}^{n} w_n \log p_n\right),
\end{equation}
gdzie $w_n$ to wagi przypisane poszczególnym rzędom n-gramów.

Zidentyfikowane ograniczenia metryki BLEU, w szczególności jej niezdolność do uwzględniania relacji semantycznych, stały się przesłanką do opracowania bardziej zaawansowanych miar, takich jak METEOR.


\subsubsection{ROUGE}
\label{sekcja:rouge}
Jako komplementarne podejście do BLEU, opracowano metrykę ROUGE (Recall-Oriented Understudy for Gisting Evaluation)~\cite{Lin2004Rouge}, która służy do kwantyfikacji zgodności semantycznej i strukturalnej pomiędzy zdaniem kandydującym a zbiorem zdań referencyjnych, stworzonych przez ludzi.

Podstawą działania ROUGE jest pomiar stopnia pokrycia słów między zdaniem kandydującym a zdaniami referencyjnymi. ROUGE sprawdza, jaka część informacji zawartej w podpisach referencyjnych została uwzględniona w podpisie kandydującym. W zadaniu automatycznego podpisywania obrazów najszersze zastosowanie znalazły warianty ROUGE-L, ROUGE-N oraz ROUGE-S.

ROUGE-L opiera się na najdłuższej wspólnej sekwencji słów (Longest Common Subsequence, LCS) pomiędzy podpisem kandydującym a podpisami referencyjnymi. LCS identyfikuje najdłuższą sekwencję słów, która występuje w tej samej kolejności zarówno w podpisie kandydującym, jak i referencyjnym, przy czym słowa te nie muszą tworzyć ciągłego fragmentu zdania. Zaletą tej metryki jest zdolność do oceny globalnej spójności strukturalnej zdań bez konieczności definiowania długości n-gramu.

Wynik ROUGE-L to średnią harmoniczną precyzji $p_l$ i czułości $r_l$:
\begin{equation}
  r_l = \frac{l(\mathbf{c}, \mathbf{s_i})}{|\mathbf{s_i}|},
\end{equation}
\begin{equation}
  p_l = \frac{l(\mathbf{c}, \mathbf{s_i})}{|\mathbf{c}|},
\end{equation}
gdzie $l(\mathbf{c}, \mathbf{s})$ to długość najdłuższego wspólnego podciągu między zdaniem kandydującym $\mathbf{c}$ a zdaniem referencyjnym $\mathbf{s_i}$, a $|\mathbf{c}|$ i $|\mathbf{s_i}|$ oznaczają ich długości w słowach. Obliczenia przeprowadza się osobno dla każdego z zdań referencyjnych $\mathbf{s_i}$, a następnie agreguje wyniki. 

Ostateczny wynik ROUGE-L wyraża się wzorem:
\begin{equation}
    \text{ROUGE-L} = \frac{(1 + \beta^2) r_{l} p_{l}}{r_{l} + \beta^2 p_{l}},
\end{equation}
gdzie $\beta=1,2$.

ROUGE-S wykorzystuje skip-bigramy, czyli pary słów występujące w tekście w tej samej kolejności, ale niekoniecznie obok siebie. Maksymalna odległość między słowami w parze jest parametrem metryki. W odróżnieniu od LCS, który identyfikuje tylko jedną, najdłuższą sekwencję, ROUGE-S zlicza wszystkie pasujące pary, co pozwala na uchwycenie zależności między słowami na dłuższych dystansach.

Przykładowo, w zdaniu: "policja schwytała złoczyńcę o poranku" można wyróżnić następujące skip-bigramy (przy braku limitu odległości): "policja schwytała", "policja złoczyńcę", "policja o", "policja poranku", "schwytała złoczyńcę", "schwytała o", "schwytała poranku", "złoczyńcę o", "złoczyńcę poranku", "o poranku".

Formuły na czułość $r_{skip}$ i precyzję $p_{skip}$ mają analogiczną postać do poprzednich wariantów:
\begin{equation}
    r_{s} = \frac{\text{SKIP}(\mathbf{c}, \mathbf{s_i})}{|\text{SKIP}(\mathbf{s_i})|},
\end{equation}
\begin{equation}
    p_{s} = \frac{\text{SKIP}(\mathbf{c, s_i})}{|\text{SKIP}(\mathbf{c})|},
\end{equation}
gdzie $\text{SKIP}(\mathbf{c}, \mathbf{s_i})$ oznacza liczbę wspólnych skip-bigramów, a $|\text{SKIP}(\mathbf{c})|$ i $|\text{SKIP}(\mathbf{s_i})|$ to całkowita liczba skip-bigramów odpowiednio w podpisie kandydującym oraz podpisem referencyjnym $\mathbf{s_i}$. Obliczenia przeprowadza się osobno dla każdego z zdań referencyjnych $\mathbf{s_i}$, a następnie agreguje wyniki. Wynik końcowy jest również miarą f.

ROUGE-W to rozwinięcie ROUGE-L, które przypisuje wyższą wagę dłuższym, nieprzerwanym sekwencjom wspólnych słów. W przeciwieństwie do standardowego LCS, które traktuje wszystkie dopasowane słowa jednakowo, ROUGE-W premiuje ciągłość dopasowań. Do identyfikacji i ważenia takich sekwencji wykorzystywane są techniki programowania dynamicznego. Dzięki temu ROUGE-W lepiej ocenia spójność i płynność gramatyczną generowanego tekstu.

Podsumowując, metryki z rodziny ROUGE dostarczają kompleksowego aparatu do ewaluacji jakości generowanych podpisów. ROUGE-L ocenia globalną zgodność strukturalną, ROUGE-S mierzy zależności między słowami na dłuższych dystansach, a ROUGE-W premiuje ciągłość dopasowań. Łączne stosowanie tych wariantów pozwala na wieloaspektową ocenę generowanych treści.

\subsubsection{METEOR}
\label{sekcja:meteor}
\input{tabele/meteor_wartosci_stalych}
Metryka METEOR (Metric for Evaluation of Translation with Explicit Ordering)~\cite{Banerjee2005METEOR, Meteor2008Agarwal} została opracowana jako odpowiedź na zidentyfikowane ograniczenia metryk BLEU i ROUGE, jak niezdolność do uwzględniania znaczeń słów. Celem metryki METEOR jest zapewnienie oceny, która koreLuje z ludzkim osądem jakościowym, poprzez integrację podstawowej wiedzy lingwistycznej. W przeciwieństwie do metryk opartych jedynie na dopasowaniu n-gramów, METEOR uwzględnia również synonimy oraz formy podstawowe słów. Dzięki temu jest w stanie pozytywnie ocenić zdania, które są semantycznie poprawne, lecz leksykalnie odmienne od zdań referencyjnych.

Ewaluacja w metryce METEOR składa się z trzech kroków. W pierwszym kroku znajdowane są jednoznaczne dopasowania n-gramów między zdaniem kandydującym a referencyjnym. Proces ten polega na utworzeniu maksymalnej możliwej liczby par słów, gdzie każde słowo z zdania kandydującego może być połączone z co najwyżej jednym słowem z zdania referencyjnego. Aby zapewnić najwyższą jakość dopasowania, METEOR stosuje ściśle określoną, trójetapową hierarchię. Najpierw dopasowywane są n-gramy identyczne, następnie słowa o tym samym rdzeniu (zgodnie z algorytmem Portera~\cite{Porter1980Stemmer}), a na końcu słowa będące synonimami w bazie WordNet~\cite{Miller1995Wordnet}. Taka hierarchiczna struktura zapewnia pierwszeństwo dopasowaniom dokładnym. Jeżeli istnieje wiele możliwych dopasowań o tej samej maksymalnej liczbie par, METEOR wybiera to, w którym kolejność słów w zdaniach jest najbardziej zbliżona, co minimalizuje liczbę przecięć linii łączących dopasowane n-gramy.

Następnie na podstawie liczby dopasowanych słów $m$, obliczane są miary precyzji $p_m$ i czułości $r_m$ dla unigramów:
\begin{equation}
    p_m = \frac{m}{w_t},
\end{equation}
\begin{equation}
    r_m = \frac{m}{w_r},
\end{equation}
gdzie $w_t$ to łączna liczba n-gramów w zdaniu kandydującym, a $w_r$ to łączna liczba n-gramów w pojedynczym zdaniu referencyjnym. Wskaźniki te są następnie łączone w średnią harmoniczną $f_{mean}$:
\begin{equation}
    f_{mean} = \frac{p_m \cdot r_m}{\alpha p_m + (1 - \alpha)r_m}.
\end{equation}
Parametry $\gamma \alpha \theta$ są optymalizowane w celu maksymalizacji korelacji metryki z ocenami ludzkimi, przy czym ich wartości są specyficzne dla danego języka~\cite{Meteor2008Agarwal}. Wartości parametrów zastosowane w oryginalnej publikacji przedstawiono w Tabeli~\ref{tab:meteor_wartosci_stalych}.
Aby ocenić płynność i poprawność gramatyczną, METEOR wprowadza karę za fragmentację, obliczaną na podstawie liczby zbitek – ciągłych i uporządkowanych sekwencji dopasowanych słów. Im więcej zbitek, tym bardziej fragmentaryczna jest struktura zdania. Karę $pen$ definiuje wzór:
\begin{equation}
    pen = \gamma \left(\frac{z}{m}\right)^{\theta},
\end{equation}
gdzie $z$ to liczba zbitek. Ostateczny wynik METEOR jest iloczynem miary $f_{mean}$ i współczynnika kary: 
\begin{equation}
    METEOR = (1 - pen) f_{mean}.
\end{equation} 
Finalnie dla każdego ze zdań referencyjnych obliczana jest metryka METEOR, a jako końcową ocenę przyjmuje się najwyższą uzyskaną wartość.

Główną zaletą metryki METEOR jest jej wyższa korelacja z oceną ludzką w porównaniu do BLEU i ROUGE, dzięki elastycznemu mechanizmowi dopasowania słów. Ograniczeniem pozostaje jednak fakt, że wszystkie dopasowane słowa – niezależnie od ich wartości informacyjnej – wnoszą jednakowy wkład do wyniku końcowego. Metryka nie rozróżnia słów z informacjami o obrazie, jak rzeczowniki, czasowniki od słów funkcyjnych. Tę lukę adresuje metryka CIDEr (por. Sekcja~\ref{sekcja:cider}), która wprowadza ważenie oparte na częstotliwości występowania n-gramów w całym korpusie referencyjnym.


\subsubsection{CIDEr}
\label{sekcja:cider}
Metryka CIDEr (Consensus-based Image Description Evaluation)~\cite{Vedantam2015Cider} jest standardem w ilościowej ocenie jakości podpisów do obrazów generowanych automatycznie. U jej podstaw leży założenie, że trafność predykcji maszynowej powinna być mierzona stopniem jej zgodności z konsensusem, zdefiniowanym jako zbiór referencyjnych podpisów stworzonych przez ludzi. Metryka CIDEr kwantyfikuje konsensus poprzez analizę statystyczną n-gramów, odzwierciedlając semantyczną spójność i powtarzalność wzorców lingwistycznych obecnych w ludzkich podpisach.

W metodologii CIDEr zarówno podpis kandydujący, jak i podpisy referencyjne są transformowane do postaci wektorowej w przestrzeni, której wymiary odpowiadają wszystkim unikalnym n-gramom występującym w korpusie. Każdy podpis jest zatem reprezentowany jako wektor, którego składowe stanowią wagi przypisane poszczególnym n-gramom. Wagi nadawane są metodą TF-IDF (Term Frequency-Inverse Document Frequency), która ma na celu uwypuklenie znaczenia n-gramów informacyjnie istotnych. W konsekwencji, n-gramy częste w danym opisie, a jednocześnie rzadkie w całym zbiorze danych, otrzymują wysoką wagę. Z kolei waga n-gramów powszechnych, o niskiej wartości semantycznej, jest marginalizowana.

Proces obliczeniowy dla pojedynczego podpisu kandydującego $c$ i zbioru $m$ referencji $S=\{\mathbf{s_{1}, s_{2}}, ..., \mathbf{s_{m}}\}$ jest następujący. W pierwszym etapie wszystkie podpisy poddawane są tokenizacji i ekstrakcji n-gramów (typowo dla $n \in \{1, 2, 3, 4\}$). Dla każdego n-gramu $\omega_k$ z globalnego słownika $\Omega$ obliczana jest waga TF-IDF. 

Składowa Term Frequency (TF) określa znormalizowaną częstotliwość występowania $\omega_k$ w danym podpisie $s_{j}$:
\begin{equation}
\mathrm{TF}(\omega_k, s_{j}) = \frac{h_k(s_{j})}{\sum_{\omega_l \in \Omega} h_l(s_{j})},
\end{equation}
gdzie $h_k(s_{j})$ oznacza liczbę wystąpień n-gramu $\omega_k$ w podpisie $s_{j}$. 

Składowa Inverse Document Frequency (IDF) mierzy informacyjną unikalność n-gramu w skali całego zbioru danych:
\begin{equation}
\mathrm{IDF}(\omega_k) = \log\left(\frac{|I|}{\sum_{I_p \in I} \min\left(1, \sum_q h_k(s_{p,q})\right)}\right),
\end{equation}
gdzie $|I|$ jest całkowitą liczbą obrazów w zbiorze, a mianownik w argumencie logarytmu zlicza liczbę obrazów, dla których w zbiorze podpisów referencyjnych n-gram $\omega_k$ wystąpił co najmniej raz. Waga TF-IDF dla n-gramu $\omega_k$ w podpisie $s_{j}$ jest iloczynem obu wartości: 
\begin{equation}
    \mathbf{g_k(s_{j})}= \mathrm{TF}(\omega_k, s_{j}) \times \mathrm{IDF}(\omega_k).
\end{equation}
W analogiczny sposób obliczane są wagi $\mathbf{g_k(c)}$ dla podpisu kandydującego, tworząc wektory cech $\mathbf{g^n(c)}$ i $\mathbf{g^n(s_{j})}$ dla każdej długości n-gramu $n$.

Podobieństwo między podpisem kandydującym a referencyjnym jest mierzone za pomocą podobieństwa kosinusowego ich wektorowych reprezentacji. Miara ta jest niewrażliwa na długość porównywanych podpisów i przyjmuje wartości z przedziału $[0, 1]$, gdzie 1 oznacza identyczność wektorów ważonych n-gramów, a 0 ich ortogonalność, czyli brak wspólnych n-gramów. Ocena $\mathrm{CIDEr}_n$ dla n-gramów o długości $n$ jest średnią z podobieństw kosinusowych między wektorem podpisu kandydującego a wektorami wszystkich $m$ podpisów referencyjnych:
\begin{equation}
\mathrm{CIDEr}_n(c, S) = \frac{1}{m} \sum_{j=1}^{m} \frac{\mathbf{g^n(c) \cdot g^n(s_{j})}}{\mathbf{\|g^n(c)\| \cdot \|g^n(s_{j})\|}},
\end{equation}
gdzie $\cdot$ oznacza iloczyn skalarny, a $\| \cdot \|$ normę euklidesową wektora. 

Finalna ocena CIDEr jest równomierną średnią arytmetyczną wyników $\mathrm{CIDEr}_n$ uzyskanych dla różnych długości n-gramów (standardowo $n=4$):
\begin{equation}
\mathrm{CIDEr}(\mathbf{c}, S) = \sum_{n=1}^4 w_n \mathrm{CIDEr}_n(c, S), \quad \text{gdzie} \quad w_n = \frac{1}{4}.
\end{equation}

Metryka CIDEr wykazuje wysoką korelację z ocenami ludzkimi, przewyższając pod tym względem klasyczne metryki, takie jak BLEU czy METEOR. Jej główną zaletą jest zdolność do premiowania n-gramów o wysokiej wartości informacyjnej, co stanowi efektywne przybliżenie oceny trafności semantycznej. Mimo to, CIDEr posiada istotne ograniczenia. Po pierwsze, jest wrażliwa na rzadkie słowa kluczowe, co może prowadzić do zawyżania oceny podpisów zawierających unikalne, lecz potencjalnie nieistotne detale, lub do zaniżania oceny w przypadku literówek. Po drugie, jako metryka oparta na leksykalnej zgodności, nie uwzględnia synonimów ani parafraz, co skutkuje karaniem poprawnych semantycznie podpisów, które używają odmiennego słownictwa niż zbiór referencyjny. Wreszcie, CIDEr nie ocenia poprawności gramatycznej ani spójności logicznej generowanego zdania. Mimo tych niedoskonałości, pozostaje jednym z kluczowych i najszerzej stosowanych narzędzi ewaluacyjnych w zadaniach automatycznego podpisywania obrazów.

\subsection{Metryki oparte na reprezentacji semantycznej}
Metryki oparte na n-gramach nie są w stanie w pełni ocenić, czy model poprawnie interpretuje znaczenie sceny, a jedynie czy używa podobnego słownictwa co autor podpisu, co zawęża ich użycie. W odpowiedzi na te niedoskonałości opracowano klasę metryk, które porównują znaczenie podpisu, a nie jedynie ciągi znaków. Podejście to ma na celu weryfikację, czy semantyczna treść wygenerowanego podpisu jest spójna z treścią podpisów referencyjnych, niezależnie od użytych sformułowań syntaktycznych. Paradygmat ten realizują SPICE oraz WMD.
\subsubsection{SPICE}
\label{sekcja:spice}
 \input{wykresy/spice/spice_graf_sceny}
 \input{wykresy/spice/spice_drzewo_zaleznosci}
Metryka SPICE (Semantic Propositional Image Captioning Evaluation)~\cite{Anderson2016Spice} odchodzi od analizy podpisów na podstawie zgodności leksykalnej i koncentruje się wyłącznie na ocenie poprawności semantycznej. W odróżnieniu od metryk opartych na analizie n-gramów, SPICE dekomponuje zdania na reprezentacje w postaci grafów scen, które modelują obiekty, ich atrybuty oraz wzajemne relacje. Dzięki temu oceniana jest merytoryczna zawartość podpisu, celowo abstrahując od jego płynności, stylu czy poprawności gramatycznej. Ocena dotyczy zatem zgodności logicznej treści, a nie statystycznego współwystępowania słów.


Transformacja zdania w graf sceny rozpoczyna się od analizy składniowej za pomocą wstępnie wytrenowanego analizatora składniowego~\cite{Klein2003Accurate}, który identyfikuje zależności gramatyczne między słowami w podpisie. Wynikiem tego etapu jest drzewo zależności (patrz~\ref{fig:spice_drzewo}), w którym węzły reprezentują poszczególne słowa, a skierowane krawędzie wskazują na ich wzajemne powiązania gramatyczne, zidentyfikowane zgodnie ze standardem Universal Dependencies~\cite{Arneffe2014Universal}.

Następnie, wygenerowane drzewo zależności jest konwertowane na graf scen za pomocą zbioru ręcznie zdefiniowanych reguł lingwistycznych~\cite{Schuster2015Generating}. Przykładowo dla drzewa zależności przedstawionego na Rysunku~\ref{fig:spice_drzewo}, zbudowanego dla obrazu~\ref{fig:spice_obraz_zrodlowy} reguła mapująca parę przymiotnik-rzeczownik transformuje zależność składniową $young\xleftarrow{amod}girl$ na obiekt (węzeł) $girl$ z atrybutem $young$ (patrz Rysunek~\ref{fig:spice_graf_z_drzewa}).

Formalnie, graf sceny dla podpisu kandydującego $c$ jest definiowany jako trójka $\mathbf{g(c) = \langle o(c), e(c), k(c) \rangle}$, gdzie $\mathbf{o(c)}$ to zbiór klas obiektów w podpisie $c$, $\mathbf{e(c)}$ to zbiór relacji (krawędzi) między obiektami, a $\mathbf{k(c)}$ to zbiór atrybutów przypisanych do obiektów.  W celu dokonania porównania, graf jest konwertowany na zbiór krotek semantycznych: $\mathbf{t(g(c)) = o(c) \cup e(c) \cup k(c)}$

Zgodność między zbiorem krotek podpisu kandydującego $\mathbf{t(g(c))}$ a zbiorem krotek pochodzących ze wszystkich podpisów referencyjnych $\mathbf{t(g(s))}$ jest kwantyfikowana za pomocą miar precyzji $p(c, s)$ i czułości (pokrycia) $r(c, s)$:
\begin{equation}
 p(c, s) = \frac{|\mathbf{t(g(c))} \cap_{\text{sem}} \mathbf{t(g(s))|}}{\mathbf{|t(g(c))|}},
\end{equation}
\begin{equation}
 r(c, S) = \frac{\mathbf{|t(g(c)) }\cap_{\text{sem}}\mathbf{ t(g(s))|}}{\mathbf{|t(g(s))|}},
\end{equation}
gdzie operator $|\dots \cap_{\text{sem}} \dots|$ to funkcja, która zlicza wspólne krotki semantyczne. Krotki są uznawane za zgodne, jeżeli ich składowe lematy są identyczne lub stanowią synonimy w tezaurusie WordNet, analogicznie do podejścia zastosowanego w metryce METEOR.

Ostateczny wynik metryki SPICE jest miarą $f1$, czyli średnią harmoniczną precyzji i czułości:
\begin{equation}
 \text{SPICE}(c, s) = f_1(c, s) = \frac{2 \cdot p(c, s) r(c, s)}{p(c, s) + r(c, s)}.
\end{equation}

Główną zaletą metryki SPICE jest jej zdolność do szczegółowej oceny poprawności semantycznej, w tym zliczania obiektów i rozpoznawania ich atrybutów,  czy weryfikacji relacji przestrzennych. Jednakże, zgodnie z założeniami projektowymi, SPICE całkowicie pomija lingwistyczną jakość generowanego tekstu, w tym płynność, styl czy poprawność gramatyczną, co istotnie ogranicza jej potencjał w pomiarze jakości podpisów maszynowych.


\subsubsection{WMD}
\label{sekcja:wmd}
Odmienne podejście do kwantyfikacji podobieństwa tekstów wprowadza metryka WMD (Word Mover's Distance)~\cite{Kusner2015FromWE}, opierając się na koncepcji problemu transportowego (transportation problem) w przestrzeni osadzeń słów. Umożliwia ona pomiar semantycznej odległości między podpisami, nawet w przypadku braku wspólnych słów kluczowych. WMD modeluje podpis jako ważoną dystrybucję osadzeń słów i oblicza minimalny koszt transformacji podpisów referencyjnych w podpis kandydujący.

Formalnie, każdy podpis jest reprezentowany jako znormalizowany wektor w modelu \gls{bow}. Dla ustalonego słownika o rozmiarze $|g|$, podpis kandydujący $c$ jest wektorem $\mathbf{c}$, którego $i$-ta składowa, $c_i$, oznacza znormalizowaną częstotliwość $i$-tego słowa w dokumencie. Zbiór podpisów referencyjnych $S$ jest agregowany do uśrednionej reprezentacji BoW, tworząc w ten sposób syntetyczny wektor $\mathbf{s}$, którego składowa $s_j$ oznacza znormalizowaną, uśrednioną częstość występowania słowa w zestawie podpisów referencyjnych.

Koszt jednostkowy transformacji słowa $i$ w słowo $j$, oznaczony jako $p(i, j)$, jest zdefiniowany jako odległość euklidesowa między ich wektorami osadzeń $\mathbf{c}_i, \mathbf{s}_j$:
\begin{equation}
 p(i, j) = \|\mathbf{c}_i - \mathbf{s}_j\|_2.
\end{equation}

Celem WMD jest znalezienie optymalnej macierzy przepływu $\mathbf{T}$, gdzie element $T_{i,j} \geq 0$ określa, jaka część "masy" słowa $i$ z podpisu źródłowego $\mathbf{c}$ musi zostać przetransportowana, aby stać się słowem $j$ w podpisach referencyjnych $\mathbf{s}$. Macierz $\mathbf{T}$ musi spełniać warunki brzegowe, zapewniające, że cała masa ze źródła zostanie rozdysponowana, a całe zapotrzebowanie w miejscu docelowym zostanie zaspokojone:
\begin{gather}
 \sum_{j=1}^{|g|} T_{i,j} = c_{i} \quad \forall i \in \{1, \dots , |g|\} ,\\
 \sum_{i=1}^{|g|} T_{i,j} = s_{j} \quad \forall j \in \{1, \dots, |g|\}.
\end{gather}

Odległość WMD między podpisem kandydującym $\mathbf{c}$ i zbiorem podpisów referencyjnych $\mathbf{s}$ jest zdefiniowana jako minimalny całkowity koszt transportu, uzyskany poprzez rozwiązanie następującego problemu programowania liniowego:
\begin{equation}
 \text{WMD}(\mathbf{c,s}) = \min_{\mathbf{T} \geq 0} \sum_{i,j=1}^{|g|} T_{i,j}p(i,j).
\end{equation}

Dokładne rozwiązanie tego problemu charakteryzuje się wysoką złożonością obliczeniową, rzędu $O(n^3 \log n)$, gdzie $n$ jest liczbą unikalnych słów w analizowanych podpisach. Stanowi to istotną barierę w zastosowaniach na dużą skalę, co doprowadziło do opracowania metod aproksymacyjnych.

Pierwszą z nich jest \gls{gls:wcd}, która upraszcza problem, obliczając odległość euklidesową między średnimi wektorami osadzeń między wektorem podpisu kandydującego $s$ a podpisami kandydującymi $\mathbf{s}$.

Drugą, bardziej zaawansowaną aproksymacją jest \gls{gls:rwmd}, która polega na relaksacji jednego z warunków brzegowych problemu transportowego, co znacząco upraszcza optymalizację. Metoda ta cechuje się złożonością $O(n^2)$ i stanowi kompromis między dokładnością pełnej metryki WMD a szybkością WCD.

Zaletą WMD jest jej zdolność do oceny podobieństwa semantycznego w sposób niezależny od porządku słów i zgodności leksykalnej. Wadą pozostaje jednak wysoki koszt obliczeniowy oraz wrażliwość na jakość użytych osadzeń słów.

\subsection{Ocena ludzka}
W badaniach nad automatycznym podpisywaniem elementem procesu ewaluacji jest ocena ludzka, która polega na zaangażowaniu ludzi do subiektywnej oceny automatycznie wygenerowanych podpisów. Wartość oceny ludzkiej wynika z faktu, że człowiek jest w stanie dostrzec niuanse semantyczne, kontekst kulturowy oraz poprawność językową, co często pozostaje poza zasięgiem algorytmów opartych na metodach statystycznych czy uczeniu maszynowym. W praktyce ocena ludzka polega na przypisaniu podpisowi wartości na określonej skali lub na udzieleniu odpowiedzi na konkretne pytania dotyczące jakości podpisu.  

Jedną z najczęściej stosowanych metod oceny ludzkiej w kontekście automatycznego podpisywania obrazów jest skala Likerta. Skala Likerta~\cite{Robinson2014} to metoda psychometryczna służąca do pomiaru postaw i opinii, opracowana przez Rensisa Likerta w latach trzydziestych XX wieku. W kontekście oceny automatycznych podpisów do obrazów respondenci proszeni są o wyrażenie swojego stopnia zgody lub niezgody z serią stwierdzeń dotyczących jakości podpisu, zaznaczając odpowiednią pozycję na skali od "zdecydowanie się nie zgadzam" do "zdecydowanie się zgadzam".  

Przykładowe pytania w ankiecie wykorzystującej skalę Likerta do oceny podpisów do obrazów (skala od "zdecydowanie nie" do "zdecydowanie tak"), to:  
\begin{itemize}
    \item Podpis dokładnie i wiernie oddaje sens obrazu.  
    \item Podpis jest płynny i naturalny.  
    \item Podpis jest poprawny językowo.  
    \item Podpis jest podobny do opisu ludzkiego.  
\end{itemize}  

Istotnym kryterium oceny podpisu jest jego poprawność językowa, która odnosi się do zgodności podpisu z zasadami gramatyki, składni i leksyki danego języka. W kontekście języka polskiego poprawność językową można dokładnie zdefiniować na podstawie topologii błędów językowych Markowskiego~\cite{Andrzej2005kultura}. Topologia ta obejmuje następujące rodzaje błędów:  

\begin{tabular}{llll}
\textbullet{} gramatyczne & \textbullet{} leksykalne & \textbullet{} słowotwórcze & \textbullet{} ortograficzne \\
\textbullet{} fleksyjne & \textbullet{} słownikowe (wyrazowe) & \textbullet{} fonetyczne & \textbullet{} interpunkcyjne \\
\textbullet{} składniowe & \textbullet{} frazeologiczne & \textbullet{} stylistyczne & \\
\end{tabular}

Poprawność gramatyczna odnosi się do zgodności z zasadami morfologii i składni języka, natomiast poprawność leksykalna dotyczy właściwego doboru słów i wyrażeń. Błędy słownikowe i frazeologiczne wynikają z użycia niewłaściwych form wyrazowych lub niepoprawnych związków frazeologicznych. Poprawność stylistyczna odnosi się natomiast do zgodności z normami stylistycznymi charakterystycznymi dla danego kontekstu komunikacyjnego.  

Oprócz skali Likerta w ocenie ludzkiej stosuje się również bardziej precyzyjne metody określenia jakości podpisu. Jedną z nich jest porównywanie parami. W tej metodzie respondenci otrzymują dwa podpisy do tego samego obrazu (jeden wygenerowany przez model sztucznej inteligencji, drugi wykonany przez człowieka) i proszeni są o wskazanie, który z nich jest lepszy. Metoda ta pozwala na bezpośrednie porównanie jakości generowanego podpisu z podpisem referencyjnym, co zwiększa trafność oceny.  

Inną metodą oceny ludzkiej jest edycja tekstu. W tej metodzie respondenci proszeni są o edycję podpisu wygenerowanego przez model automatycznie generujący podpis do obrazu, tak aby poprawić jego jakość. Ilość wprowadzonych zmian to miara jakości podpisu — im mniej zmian jest koniecznych, tym lepsza jest jakość pierwotnego podpisu.  

Kolejną metodą jest ocena holistyczna, w której respondenci przyznają podpisowi automatycznemu ogólną ocenę w skali punktowej od 1 do 5, gdzie 1 oznacza bardzo słaby podpis, a 5 — bardzo dobry. Ocena holistyczna pozwala na syntetyczne ujęcie jakości podpisu w ramach jednej miary liczbowej, jednak jej wadą jest wysoka subiektywność i brak precyzyjnych kryteriów oceny.  

Ocena ludzka, mimo swojej powszechności i intuicyjności, posiada pewne ograniczenia. Jednym z kluczowych problemów jest subiektywność osądów. Każdy ewaluator może inaczej postrzegać jakość podpisu w zależności od własnych doświadczeń językowych, kulturowych i percepcyjnych. Zmienność między ewaluatorami prowadzi do trudności w uzyskaniu spójnych wyników. Kolejnym ograniczeniem jest czasochłonność i wysoki koszt przeprowadzania oceny ludzkiej, zwłaszcza gdy konieczne jest zaangażowanie dużej liczby respondentów w celu uzyskania statystycznie istotnych wyników.  

Mimo opisanych ograniczeń, ocena ludzka pozostaje niezastąpionym złotym standardem w ewaluacji podpisów. Żadna metryka automatyczna nie jest w stanie w pełni uchwycić niuansów, które dostrzega człowiek. Dlatego wysoką korelację z oceną ludzką uznaje się za potwierdzenie wiarygodności metryk automatycznych, a same wyniki oceny ludzkiej stanowią ostateczny punkt odniesienia dla jakości generowanych modeli.


\subsection{Porównanie metryk}
\input{tabele/metryki_rezultaty_na_zdaniu}
W niniejszym rozdziale dokonano systematycznego przeglądu dwóch filarów, na których opierają się współczesne badania w dziedzinie automatycznego generowania podpisów do obrazów: zbiorów danych stanowiących empiryczną podstawę dla modeli oraz metryk ewaluacyjnych służących do pomiaru ich skuteczności. Przedstawiona analiza ukazuje wyraźną ewolucję w obu tych obszarach – od relatywnie niewielkich, manualnie adnotowanych korpusów do wielkoskalowych zasobów pozyskiwanych automatycznie, oraz od prostych miar leksykalnych do zaawansowanych metod oceny semantycznej.

Analiza porównawcza omówionych metryk automatycznych ujawnia fundamentalne kompromisy i specyfikę każdej z nich. Metryki takie jak BLEU (por. Sekcja~\ref{sekcja:bleu}) i ROUGE (por. Sekcja~\ref{sekcja:rouge}), oparte na zgodności n-gramów, pozostają standardem ze względu na prostotę implementacji i wydajność obliczeniową, lecz ich zdolność do oceny rzeczywistej jakości jest ograniczona. Stanowią one miarę zgodności na poziomie powierzchniowym, ignorując bogactwo relacji semantycznych, takich jak synonimia czy parafraza. METEOR (por. Sekcja~\ref{sekcja:meteor}) stanowi krok naprzód, integrując podstawową wiedzę lingwistyczną, co skutkuje wyższą korelacją z osądem ludzkim, jednak jego skuteczność jest uzależniona od zewnętrznych zasobów językowych.

Prawdziwą zmianę paradygmatu przyniosły metryki opracowane z myślą o specyfice zadania. CIDEr (por. Sekcja~\ref{sekcja:cider}), poprzez mechanizm ważenia TF-IDF, z powodzeniem modeluje pojęcie konsensusu i istotności informacyjnej, nagradzając podpisy, które są zarówno trafne, jak i deskryptywne. Z kolei SPICE (por. Sekcja~\ref{sekcja:spice}) i WMD (por. Sekcja~\ref{sekcja:wmd}) przenoszą ewaluację na płaszczyznę semantyczną. SPICE, oceniając zgodność na poziomie grafów sceny, oferuje bezprecedensową zdolność do weryfikacji poprawności merytorycznej opisu – rozpoznanych obiektów, atrybutów i relacji. Czyni to jednak kosztem całkowitego pominięcia jakości lingwistycznej. WMD natomiast, mierząc odległość w przestrzeni osadzeń słów, w elastyczny sposób kwantyfikuje podobieństwo znaczeniowe, lecz jest obarczone wysokim kosztem obliczeniowym i brakiem wrażliwości na składnię.


W Tabeli~\ref{tab:metryki_rezultaty_na_zdaniu} przedstawiono analizę wrażliwości wybranych metryk na celowe modyfikacje zdania kandydującego. Zestawiono oryginalne zdanie zmodyfikowane o synonimy, wyrazy redundantne, a także ze zmienioną kolejnością słów. W celach porównawczych w Tabeli~\ref{tab:metryki_rezultaty_na_zdaniu} znajduje się także oryginalne zdanie, wraz z pięcioma podpisami referencyjnymi.

Ewidentnie zastąpienie słów ich synonimami skutkuje obniżeniem wartości wszystkich analizowanych metryk, przy czym spadek ten jest szczególnie znaczący w przypadku SPICE oraz CIDEr. W rozpatrywanym przykładzie ograniczenie metryki SPICE wynika z nieprawidłowego mapowania synonimów, natomiast niższa ocena metryki CIDEr jest konsekwencją zastosowanego mechanizmu ważenia TF-IDF.

Ponadto wprowadzenie do zdania wyrazów redundantnych prowadzi do spadku wartości metryk BLEU-1, BLEU-2, ROUGE-L oraz CIDEr w stosunku do zdania oryginalnego. Należy jednak zaznaczyć, że metryka WMD pozostaje niewrażliwa na zmianę szyku wyrazów.

Z powyższej analizy wynika, że nie istnieje pojedyncza, uniwersalna metryka automatyczna, która byłaby w stanie w pełni uchwycić wielowymiarowość jakości generowanego tekstu. Każda z miar posiada swoje unikalne zalety i systematyczne słabości. W konsekwencji rzetelna ewaluacja ilościowa wymaga stosowania zestawu komplementarnych metryk, które łącznie pozwalają na wieloaspektową ocenę modelu, obejmującą zarówno zgodność leksykalną, semantyczną, oraz płynność językową.

Należy jednak podkreślić, że nawet najbardziej zaawansowane miary automatyczne pozostają jedynie aproksymacją ostatecznego kryterium, jakim jest ocena ludzka. To ona stanowi niezastąpiony, złoty standard weryfikacji, jako jedyna zdolna do holistycznej oceny spójności, poprawności gramatycznej, adekwatności stylistycznej i ogólnej jakości komunikacyjnej wygenerowanego podpisu.

\subsection{Wyzwania w generowaniu i ewaluacji podpisów w języku polskim}
Rozwój architektur neuronowych, zwłaszcza modeli opartych na mechanizmie uwagi, umożliwił osiągnięcie znaczących postępów w badaniach nad automatycznym podpisywaniem obrazów. Jednakże, w przypadku języków o złożonej morfologii i swobodnym szyku zdania, do których należy język polski, proces generowania i ewaluacji podpisów napotyka na fundamentalne trudności. Złożoność fleksyjna języka polskiego, obejmująca deklinację rzeczowników, przymiotników i zaimków oraz koniugację czasowników, stawia przed modelami językowymi znacznie wyższe wymagania niż w przypadku języka angielskiego. Konieczność zapewnienia zgodności gramatycznej (np. podmiotu z orzeczeniem pod względem osoby, liczby i rodzaju) w obrębie całego zdania wymaga nie tylko modelowania zależności statystycznych, ale również głębokiego zrozumienia reguł gramatycznych.

Jak wskazuje analiza jakości tekstów generowanych maszynowo w języku polskim, przeprowadzona w~\cite{Mazur2024Poprawnosc} głównym problemem pozostaje poprawność składniowa i fleksyjna. Generowane konstrukcje są często niekompletne, a ich struktura odbiega od naturalnych wzorców językowych. Modele wykazują trudności w przestrzeganiu podstawowych zasad gramatycznych, co prowadzi do powstawania błędów w odmianie wyrazów oraz niepoprawnych konstrukcji składniowych. Te niedoskonałości wynikają w dużej mierze z charakteru danych treningowych, w których nacisk kładzie się na ilość, a nie na bezwzględną poprawność językową, co prowadzi do utrwalania błędnych wzorców.

Wymienione wyzwania w generowaniu tekstu implikują również istotne ograniczenia w procesie jego ewaluacji. Standardowe metryki automatyczne, takie jak BLEU czy ROUGE, oparte na analizie n-gramów, mogą okazać się niewystarczające. Ich wrażliwość na zgodność leksykalną sprawia, że mogą one nisko oceniać zdania semantycznie poprawne, lecz używające synonimów lub odmiennych form fleksyjnych niż w podpisach referencyjnych. Z drugiej strony, mogą one przypisywać wysokie wyniki zdaniom zawierającym rażące błędy gramatyczne, o ile współdzielą one odpowiednią liczbę n-gramów z referencją. W konsekwencji, rzetelna ocena jakości podpisów w języku polskim wymaga zastosowania metryk zdolnych do uwzględnienia bogactwa morfologicznego i elastyczności składniowej lub polegania na kosztownej i subiektywnej ocenie ludzkiej.


\chapter{Badania podstawowej architektury koder-dekoder}
\label{rozdzial:badania_podstawowej_architektury_koder_dekoder}
Rozdział przedstawia badania nad optymalizacją architektury typu koder-dekoder w zadaniu automatycznego generowania podpisów do obrazów. Analizie poddano wpływ poszczególnych komponentów modelu na jego ostateczną wydajność w ramach dwóch wariantów integracji cech wizualnych i tekstowych, poprzez fuzję oraz wstrzykiwanie wstępne, które opisano w Sekcji~\ref{sekcja:jak_poloczyc_cechy_obrazu_tekstu}. Celem badań było udoskonalenie ugruntowanej w literaturze architektury poprzez systematyczną modyfikację jej komponentów oraz hiperparametrów. W ramach metodyki badawczej oceniono wpływ zastosowania różnych, wstępnie trenowanych sieci szkieletowych (m.in. VGG, Resnet, Inception, Densenet) na jakość ekstrakcji cech wizualnych oraz zintegrowano modele osadzeń słów, takie jak GloVe i FastText, w celu poprawy spójności semantycznej i jakości lingwistycznej generowanych podpisów. 

Wprowadzone modyfikacje przyczyniły się do wzrostu wydajności modelu bez wprowadzania fundamentalnych zmian w jego topologii, co mówi o potencjale zastosowanej metody. W sekcji weryfikowana będzie hipoteza (H1) dotycząca znaczenia sieci szkieletowej, hipoteza (H2) dotycząca metod fuzji i (H3) dotycząca struktury dekodera. Wyniki przeprowadzonych badań zostały opublikowane w artykułach~\cite{Bartosiewicz2024Optimal, Bartosiewicz2024Improving}.

\section{Architektura modelu}
Podstawę dla prowadzonych analiz stanowiła architektura koder-dekoder. Model składa się z wizualnej ścieżki przetwarzania, realizowanej przez koder, oraz tekstowej, obsługiwanej przez dekoder. \textit{Komponent ekstrakcji cech obrazu} w koderze zamienia obraz wejściowy w semantycznie bogatą reprezentację wektorową za pomocą sieci szkieletowej, co omówiono w Sekcji~\ref{rozdzial:reprezentacja_obrazu}). 
Na jego wyjściu powstaje wektor cech obrazu, który jest spłaszczeniem warstw w pełni połączonych (\gls{gls:fully-connected-layer}) wielowymiarowej mapy cech obrazu $\mathbf{V=\{\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\}}$, gdzie $\mathbf{v}_i$ jest wektorem cech odpowiadającym $i$-temu regionowi przestrzennemu. 
Tak wygenerowany wektor cech obrazu jest następnie przetwarzany przez \textit{komponent adaptacyjny}, gdzie następuje liniowa transformacja wektora cech obrazu do przestrzeni o wymiarowości zgodnej z przestrzenią dekodera. Dopiero na tym etapie wagi są dostrajane (\gls{gls:fine-tuning}) do specyfiki zadania. 

Ścieżka dekodera rozpoczyna się od \textit{komponentu osadzania słów}, który przetwarza słowa zakodowane gorącojedynkowo na wektory osadzeń, co omówiono w Sekcji~\ref{rozdzial:reprezentacja_slow}. Tak zakodowane słowa są wejściem do rekurencyjnej sieci neuronowej w \textit{komponencie RNN}, która modeluje zależności sekwencyjne i generuje stan ukryty, agregujący informacje o dotychczas wytworzonej części podpisu (zagadnienie modelowania sekwencji oraz stosowanych do tego sieci rekurencyjnych omówiono w Sekcji~\ref{sekcja:modelowanie-sekwencji}). Obie ścieżki mogą być syntetyzowane z udziałem \textit{komponentu fuzji} w każdym kroku czasowym dla architektury fuzji lub jednorazowo w \textit{komponencie RNN} w przypadku architektury wstrzykiwania wstępnego. Mechanizm integracji informacji wizualnej z kodera i tekstowej w dekoderze różnicuje badane modele. W pracy zbadano architekturę fuzji (merge architecture), gdzie integracja następuje w każdym kroku czasowym z udziałem \textit{komponentu fuzji}, oraz architekturę wstrzykiwania wstępnego (pre-injection architecture), gdzie informacja wizualna jest wykorzystywana jednorazowo do inicjalizacji stanu początkowego \textit{komponentu RNN}.



\input{wykresy/architektury/warstwy/architektura_modelu_badan_nad_warstwami}
W architekturze fuzji której schemat przedstawiono na Rysunku~\ref{fig:architektura_modelu_badan_nad_warstwami} synteza informacji wizualnej i tekstowej zachodzi w \textit{komponencie fuzji} w każdym kroku czasowym generowania zdania wyjściowego, jak przedstawiono w Sekcji~\ref{sekcja:jak_poloczyc_cechy_obrazu_tekstu}). Komponent ten integruje wektor cech obrazu z \textit{komponentu adaptacyjnego} z wyjściem rekurencyjnej sieci neuronowej, tworząc podstawę do predykcji kolejnego słowa. Analizie poddano fuzję przez dodawanie i konkatenację. W metodzie dodawania wektory cech obu modalności, o identycznej wymiarowości, są dodawane do siebie element po elemencie (\gls{gls:element-wise}). W metodzie konkatenacji wektory te są łączone wzdłuż wymiaru cech, tworząc pojedynczy, dłuższy wektor reprezentacji. Połączona reprezentacja jest następnie przekazywana do \textit{komponentu predykcji słów}, zaimplementowanego jako sekwencja warstw w pełni połączonych z funkcją aktywacji softmax, która generuje rozkład prawdopodobieństwa słów nad całym słownikiem. Słowo o najwyższym prawdopodobieństwie jest wybierane jako kolejne w sekwencji. W badaniach architektury fuzji wykorzystano wstępnie wytrenowane modele osadzeń GloVe oraz FastText i porównano architektury LSTM oraz GRU. Warianty eksperymentalne \textit{komponentu adaptacyjnego} obejmowały różne rozmiary warstwy wyjściowej oraz możliwość jego całkowitej eliminacji z architektury.

\input{wykresy/architektury/warstwy/model_bazowy}
Drugi badany wariant, architektura wstrzykiwania wstępnego przedstawiony na Rysunku~\ref{fig:model_bazowy}, modyfikuje sposób nadawania wartości początkowej dekodera. W tym podejściu zaadaptowany wektor cech obrazu jest wprowadzany do modelu jednorazowo, służąc do nadania wartości początkowej dekodera rekurencyjnego. W badaniach architektury wstrzykiwania wstępnego użyto sieć LSTM, więc zaadaptowany wektor cech obrazu posłużył do zainicjowania zarówno stanu ukrytego ($h_{t=0}$) oraz stanu komórki ($c_{t=0}$). W ten sposób pełna informacja wizualna jest jednorazowo "wstrzykiwana" do komórki LSTM przed rozpoczęciem generowania pierwszego słowa. W kolejnych krokach czasowych dekoder operuje wyłącznie na swoim stanie wewnętrznym oraz osadzeniach poprzednio wygenerowanego słowa. W ramach eksperymentów dla tej architektury badano wpływ zastosowania różnych sieci szkieletowych, takich jak Resnet152, Densenet201, Regnet32, InceptionV3 oraz analizowano, jak rozmiar stanu ukrytego sieci LSTM wpływa na wydajność modelu w zależności od zastosowanej sieci szkieletowej w koderze. 

W procesie generowania sekwencji wyjściowej dla obu architektur zastosowano algorytm przeszukiwania wiązkowego (beam search, opisany w Sekcji~\ref{rozdzial:generowanie_sekwencji_wyjsciowej}). Dekodowanie rozpoczyna się od słowa sygnalizującego początek zdania $<$START$>$. W każdym kroku, dla każdej z $k$ hipotez (fragmentu zdania) o najwyższym dotychczasowym prawdopodobieństwie logarytmicznym, model generuje predykcje kolejnych słów. Z powstałego zbioru nowych, rozszerzonych sekwencji kandydujących, do dalszego przetwarzania zachowywane jest jedynie $k$ najbardziej prawdopodobnych, gdzie $k$ jest predefiniowanym parametrem szerokości wiązki. Proces ten jest kontynuowany aż do osiągnięcia kryterium terminacji -- wygenerowania tokenu końca sekwencji $<$STOP$>$ lub osiągnięcia maksymalnej długości podpisu. Ostatecznie wybierana jest hipoteza o najwyższym skumulowanym prawdopodobieństwie. W ramach badań architektury wstrzykiwania wstępnego analizowano również wpływ parametru $k$ na jakość generowanych podpisów. W przypadku architektury fuzji stosowano algorytm przeszukiwania wiązkowego z $k=1$, czyli wybierano token o najwyższym prawdopodobieństwie wystąpienia. Jest to adekwatne do stosowania przeszukiwania zachłannego.
\section{Scenariusz badawczy}
\subsection{Badania architektury fuzji}
Scenariusz badawczy obejmował systematyczną analizę i optymalizację modelu typu koder-dekoder w architekturze fuzji. Głównym celem była ocena wpływu zastąpienia poszczególnych komponentów architektury ich nowszymi odpowiednikami na wydajność modelu. Priorytetem była również redukcja złożoności obliczeniowej przy zachowaniu wysokiej jakości generowanych podpisów, z myślą o implementacji modelu w środowiskach o ograniczonych zasobach sprzętowych.

Proces badawczy podzielono na trzy fazy. Faza pierwsza koncentrowała się na identyfikacji optymalnej kombinacji sieci szkieletowej oraz modelu osadzeń słów. Zgodnie z literaturą~\cite{Yang2017ImageCW, Xu2015ShowAttendTell, Anderson2018BottomUpAT, Herdade2019Image, Lebret2015Phrase, Karpathy2015Deep, Sugano2016SeeingW}, analizowano sieci szkieletowe VGG16/19, Resnet50/152V2, InceptionV3, Xception, Densenet121/201 oraz Mobilenet/MobilenetV2. Dla kodowania tekstu porównano modele osadzeń GloVe oraz FastText. W celu wyizolowania wpływu sieci szkieletowej oraz osadzeń słów, parametry pozostałych komponentów, w tym sieci rekurencyjnej i warstw predykcyjnych, utrzymano na stałym poziomie 256 neuronów.

W fazie drugiej, bazując na optymalnej parze sieci szkieletowej oraz modelu osadzeń słów wyłonionej w poprzednim etapie (model Xception dla cech wizualnych i osadzenia GloVe dla cech tekstowych), przeprowadzono analizę komponentów odpowiedzialnych za przetwarzanie i integrację wektorów multimodalnych. Oceniono wpływ \textit{komponentu adaptacyjnego}, testując warianty z warstwą redukującą wymiarowość cech obrazu do 128, 256 i 512 neuronów oraz wariant bez tej warstwy. Porównano strategie integracji modalności, poprzez dodawanie wektorów oraz ich konkatenację. W \textit{komponencie predykcji słów} badano różne konfiguracje warstw w pełni połączonych. Jako dekoder zaimplementowano sieć LSTM, analizując wpływ liczby jej jednostek ukrytych.

Trzecia faza poświęcona była weryfikacji wpływu typu sieci rekurencyjnej na skuteczność modelu. W tym celu powtórzono najbardziej obiecujące eksperymenty z fazy drugiej, zastępując architekturę LSTM siecią GRU. Celem było ustalenie, czy model GRU, o mniejszej złożoności, jest w stanie uzyskać porównywalną lub wyższą wydajność.

Jakość generowanych podpisów ewaluowano za pomocą metryk BLEU (1-4), CIDEr oraz SPICE. Zgodnie z aktualnym stanem wiedzy, za kluczowe wskaźniki, wykazujące najwyższą korelację z oceną ludzką, przyjęto metryki CIDEr i SPICE.

Ostatnim etapem była walidacja zdolności do generalizacji najlepszych modeli. Ocenę przeprowadzono na obrazach spoza dystrybucji danych treningowych, włączając fotografie ze świata rzeczywistego oraz obrazy wygenerowane syntetycznie przez model DALL-E 3~\cite{Dalle2023dalle3}. Analiza ta pozwoliła ocenić odporność i skuteczność modeli w konfrontacji z nowymi obiektami i scenami.

\subsection{Badania architektury wstrzykiwania wstępnego}
Badania architektury wstrzykiwania wstępnego podzielono na dwa etapy w celu zbadania parametrów treningowych modelu oraz przebiegu generowania zdań przez wytrenowany model. W pierwszym etapie przeprowadzono eksperymenty z wykorzystaniem sieci szkieletowych oraz różnych rozmiarów stanu ukrytego sieci LSTM. Na tym etapie zgodnie z literaturą~\cite{Vinyals2015Show, Vinyals2017ShowTellLessonsLearned}, w eksperymentach standardowo stosowano $k=3$.


W drugim etapie analizowano wpływ szerokości wiązki $k$ w algorytmie przeszukiwania wiązkowego podczas inferencji. Modele wytrenowane w pierwszym etapie poddano ponownej ewaluacji z różnymi wartościami parametru $k$, co pozwoliło na wyznaczenie jego optymalnej wartości dla procesu inferencji.

Na każdym etapie wyniki oceniano przy użyciu metryk BLEU-1 do BLEU-4, ROUGE-L, SPICE oraz CIDEr.

\section{Przebieg treningu}
Trening obu architektur poprzedzono zunifikowanym wstępnym przetwarzaniem danych. Obrazy wejściowe zostały przeskalowane i znormalizowane do wymiarów wymaganych przez poszczególne sieci szkieletowe: $256 \times 256 \times 3$ dla modeli VGG16/19, Resnet50/152V2, Densenet121/201 oraz Mobilenet/MobilenetV2; $342 \times 342 \times 3$ dla InceptionV3 i Xception; oraz $384 \times 384 \times 3$ dla Regnet32. Wartości pikseli znormalizowano do zakresu $[0, 1]$. Równolegle, podpisy referencyjne poddano tokenizacji zgodnie z procedurą opisaną w Sekcji~\ref{rozdzial:wstepne_przetwarzanie}, tworząc słownik dla całego korpusu. Każdą sekwencję uzupełniono o tokeny specjalne $<$START$>$ i $<$STOP$>$.

W ramach pojedynczej iteracji treningowej, partia obrazów była przetwarzana przez \textit{komponent ekstrakcji cech obrazu}, gdzie wybrana sieć szkieletowa generowała wektor cech wizualnych. Wymiarowość tego wektora była zależna od użytego modelu i wynosiła od 1000 w Mobilenet do 4096 w VGG16. Równocześnie podpisy w formie tokenów przechodziły przez \textit{komponent osadzania słów}, gdzie każde słowo było odwzorowywane na 200-wymiarowy wektor osadzeń przy użyciu osadzeń GloVe lub FastText.

Podczas treningu zastosowano uczenie z nauczycielem (\gls{gls:teacher-forcing}). W każdym kroku czasowym na wejście sieci RNN podawano osadzenie prawidłowego słowa z sekwencji referencyjnej z kroku $t-1$, a nie słowa wygenerowanego przez model. Na podstawie stanu ukrytego z poprzedniego kroku $\mathbf{h}_{t-1}$ oraz bieżącego słowa wejściowego, sieć RNN obliczała nowy stan ukryty $\mathbf{h}_t$.

Różnica między architekturami manifestowała się w sposobie wykorzystania wektora cech obrazu. W architekturze fuzji, zaadaptowany wektor cech obrazu był w każdym kroku $t$ łączony w \textit{komponencie fuzji} ze stanem ukrytym $h_t$. Połączony wektor stanowił podstawę do predykcji następnego słowa $y_t$. W architekturze wstrzykiwania wstępnego, wektor cech obrazu był wykorzystywany jednorazowo do inicjalizacji $ h_{t=0}$ oraz $c_{t=0}$ 
w sieci LSTM.

Optymalizację parametrów modelu oparto na minimalizacji funkcji straty w postaci entropii krzyżowej (\gls{gls:cross-entrophy-loss}). Gradienty funkcji straty obliczano za pomocą metody wstecznej propagacji błędów. Do aktualizacji wag modelu posłużył optymalizator Adam, skonfigurowany z parametrami $\beta_1 = 0,9$, $\beta_2 = 0,999$ oraz $\epsilon = 1 \times 10^{-8}$. Nie stosowano mechanizmu zaniku wag (\gls{gls:weight-decay}). W celu zapobiegania problemowi eksplodujących gradientów zaimplementowano technikę ich obcinania (\gls{gls:gradient-clipping}) z progiem 5. Bazowy współczynnik uczenia dla dekodera wynosił $4 \times 10^{-4}$, a dla kodera w przypadku jego douczania $1 \times 10^{-4}$. Uczenie prowadzono w partiach o rozmiarze 10. Wartości dobrano w oparciu o powszechną praktykę w zadaniach automatycznego generowania podpisów do obrazów oraz eksperymenty wstępne, dążąc do zapewnienia stabilności treningu.

Zaimplementowano mechanizmy kontroli przebiegu uczenia. Zastosowano adaptacyjną zmianę współczynnika uczenia (\gls{gls:learning-rate}), redukując jego wartość o 20\% (mnożnik 0,8), jeżeli metryka BLEU-4 na zbiorze walidacyjnym nie uległa poprawie przez osiem kolejnych epok. Trening zaplanowano na 100 epok, z mechanizmem wczesnego zatrzymania (\gls{gls:early-stopping}), przerywającym uczenie, jeżeli wartość funkcji straty na zbiorze walidacyjnym nie zmniejszyła się przez pięć kolejnych epok. Punkty kontrolne modelu zapisywano w przypadku poprawy funkcji straty na zbiorze walidacyjnym.


\section{Przebieg testowania}
Ewaluację wytrenowanych modeli przeprowadzono na zbiorze testowym, stosując ocenę ilościową oraz jakościową. Ewaluację dla każdego modelu rozpoczynano od wczytania punktu kontrolnego, który uzyskał najlepsze wyniki na zbiorze walidacyjnym, wraz z odpowiadającym mu słownikiem. Obrazy testowe poddawano tym samym transformacjom co w procesie uczenia, obejmującym skalowanie i normalizację. Następnie, z wykorzystaniem sieci szkieletowej, dla każdego obrazu ekstrahowano wektor cech.

Proces generowania opisu realizowano z wykorzystaniem dwóch strategii dekodowania, uzależnionych od architektury modelu. W modelu opartym na fuzji zastosowano deterministyczną strategię przeszukiwania zachłannego (\gls{gls:greedy-search}), opisaną w Sekcji~\ref{rozdzial:generowanie_sekwencji_wyjsciowej}. Strategia ta polegała na wyborze w każdym kroku czasowym słowa o najwyższym prawdopodobieństwie, na bazie wektora cech obrazu oraz słowa wygenerowanego w poprzednim kroku.

Dla modelu z wstrzykiwaniem wstępnym wykorzystano algorytm przeszukiwania wiązkowego (beam search, \gls{gls:beam-search}) z predefiniowaną szerokością wiązki $k$ (szczegółowo przedstawiony w Rozdziale~\ref{rozdzial:generowanie_sekwencji_wyjsciowej}). Metoda ta polega na utrzymywaniu i rozwijaniu k najbardziej prawdopodobnych sekwencji kandydujących w każdym kroku generowania słów w zdaniu.


Niezależnie od zastosowanej strategii, proces dekodowania sekwencji wyjściowej inicjowano tokenem $<$START$>$ i kontynuowano aż do osiągnięcia kryterium terminacji, czyli wygenerowania tokenu końca sekwencji $<$STOP$>$ lub osiągnięcia maksymalnej, predefiniowanej długości podpisu. Finalny podpis konstruowano poprzez konkatenację wygenerowanych słów, z pominięciem tokenów specjalnych. Tak uzyskane zdanie było następnie porównywane z pięcioma podpisami referencyjnymi przy użyciu metryk ilościowych BLEU-1 do BLEU-4, CIDEr oraz SPICE.

Ewaluację ilościową uzupełniono o analizę jakościową. Analiza ta miała dwojaki charakter. Z jednej strony, badano przykłady trafnie wygenerowanych podpisów w celu identyfikacji mocnych stron modeli. Z drugiej strony, przeprowadzono systematyczną analizę i kategoryzację popełnianych błędów, aby zdiagnozować ich słabości i potencjalne kierunki dalszych badań.

\section{Rezultaty}
\subsection{Wyniki dla architektury fuzji}
\subsubsection{Ewaluacja komponentów kodowania danych wejściowych}

Pierwszy etap badań obejmował ewaluację wpływu sieci szkieletowych oraz modeli osadzeń słów na skuteczność generowania podpisów, celem weryfikacji hipotezy szczegółowej (H1). W pierwszej kolejności porównano dziesięć architektur sieci szkieletowych opisanych w Sekcji~\ref{rozdzial:reprezentacja_obrazu}. Każdą z sieci testowano w połączeniu z osadzeniami GloVe oraz FastText. Ocenę ilościową przeprowadzono z wykorzystaniem metryk BLEU (1-4) oraz CIDEr, która stanowiła główny wskaźnik skuteczności. Przeanalizowano również efektywność obliczeniową modeli, uwzględniając całkowitą liczbę parametrów oraz czas inferencji.

 W tej fazie badań zastosowano osadzenia GloVe i FastText w \textit{komponent osadzania słów}. \textit{Komponent adaptacyjny} składa się z pojedynczej warstwy w pełni połączonej (\gls{gls:fully-connected-layer}), gdzie rozmiar wejściowy jest równy długości wektora cech obrazu, a rozmiar wyjściowy odpowiada rozmiarowi wejściowemu sieci RNN, którą w tym eksperymencie jest sieć LSTM. \textit{Komponent predykcji słów} składa się z dwóch warstw FC. W pierwszej warstwie rozmiar wektora wejściowego i wyjściowego wynosi 256. Druga warstwa generuje na wyjściu prawdopodobieństwa słów. Rozmiar wejściowy drugiej warstwy wynosi 256, podczas gdy rozmiar wyjściowy jest równy rozmiarowi słownika.

\input{rezultaty/warstwy/rezultaty_srednio}
Analiza wyników (Tabela~\ref{tab:rezultaty_srednio}) wskazuje, że najwyższą skuteczność, osiągnął model wykorzystujący architekturę Xception. W konfiguracji z osadzeniami GloVe uzyskano wynik CIDEr równy 78,13. Marginalnie niższy rezultat (77,64) odnotowano dla tej samej architektury z wektorami FastText. Wysoką skuteczność wykazała również sieć Densenet201 (CIDEr 76,74 z FastText oraz 76,54 z GloVe). Najniższe wyniki uzyskano dla starszych architektur VGG16 i VGG19.

Wykazano, że wybór metody osadzania słów wpływa na końcową jakość modelu, jednak efekt ten jest zależny od architektury sieci szkieletowej. Dla większości sieci (m.in. Densenet121, Densenet201, InceptionV3, Mobilenet) wektory FastText skutkowały wyższymi wartościami CIDEr. Odwrotną zależność zaobserwowano dla Resnet152V2 oraz najskuteczniejszej architektury Xception, gdzie wektory GloVe pozwoliły osiągnąć najwyższy wynik.

\input{rezultaty/warstwy/parametry/zaleznosc_metryki_cider_od_ilosci_parametrow_modelu}
Analiza zależności pomiędzy metryką CIDEr a liczbą parametrów (Rysunek~\ref{fig:zaleznosc_metryki_cider_od_ilosci_parametrow_modelu}) wskazuje na brak monotonicznej zależności między wzrostem złożoności modelu a poprawą jakości generowanych podpisów. Modele o największej liczbie parametrów, VGG16 (143,26 mln) i VGG19 (144,47 mln), charakteryzowały się najniższymi wynikami CIDEr. Optymalne rezultaty osiągnęły modele o umiarkowanej złożoności (22-28 mln parametrów), w tym Xception (25,24 mln) i Densenet201 (22,67 mln). Sugeruje to istnienie progu złożoności, po przekroczeniu którego dalsze zwiększanie pojemności modelu nie implikuje poprawy skuteczności w badanym zadaniu.

Stwierdzono również, że wymiarowość wektora cech obrazu nie jest bezpośrednio skorelowana ze skutecznością modelu. Najdłuższe wektory (VGG, 4096 elementów) nie zapewniały najwyższych wartości metryk. Najskuteczniejsze modele wykorzystywały wektory 2048-elementowe (Xception) oraz 1920-elementowe (Densenet201). Decydującym czynnikiem okazała się jakość wyuczonej reprezentacji wizualnej, a nie sama wymiarowość wektora cech.

\input{rezultaty/warstwy/naj_epoka/zaleznosc_metryki_cider_od_czasu_generowania_sekwencji_wyjsciowej}
Relacja między czasem inferencji a wartością metryki CIDEr na Rysunku~\ref{fig:zaleznosc_metryki_cider_od_czasu_generowania_sekwencji_wyjsciowej} jest niejednoznaczna. Model Densenet201 z FastText charakteryzował się wysoką efektywnością obliczeniową (1748 ms) przy jednoczesnej wysokiej skuteczności (CIDEr 76,74). Model Xception z GloVe uzyskał najwyższy wynik CIDEr (78,13) przy dłuższym czasie inferencji (2414 ms). Modele o najdłuższych czasach inferencji (np. Mobilenet z GloVe, 3860 ms) nie osiągały czołowych wyników jakościowych.

Podsumowując pierwszy etap badań, jako optymalną konfigurację wytypowano model oparty na sieci Xception w połączeniu z osadzeniami GloVe (CIDEr: 78,13; SPICE: 15,16). Konfiguracja ta została wybrana do dalszych badań.

\input{rezultaty/warstwy/przewidziane_podpisy_obrazy/porownanie_przewidzianych_podpisow}
\input{rezultaty/warstwy/przewidziane_podpisy_obrazy/przewidziane_obrazy}
W Tabeli~\ref{tab:porownanie_przewidzianych_podpisow} zaprezentowano przykładowe podpisy dla obrazów z Rysunku~\ref{fig:przewidziane_obrazy}. Wygenerowane podpisy są generalnie poprawne gramatycznie i spójne semantycznie z zawartością obrazu. Zaobserwowano jednak przypadki halucynacji obiektów. Na Rysunku~\ref{fig:przewidziane_obrazy_b} model wygenerował obiekt "kuchenka", wnioskując o jego prawdopodobnej obecności na podstawie kontekstu (kuchnia, kuchenka mikrofalowa), mimo jego faktycznej nieobecności na obrazie, co wskazuje na wpływ korelacji występujących w danych treningowych.

\input{rezultaty/warstwy/przewidziane_podpisy_obrazy/porownanie_przewidzianych_podpisow_para}
W Tabeli~\ref{tab:porownanie_przewidzianych_podpisow_para} porównano podpisy dla Rysunku~\ref{fig:przewidziane_obrazy_d} wygenerowane przez najskuteczniejszy model (Xception + GloVe) oraz przez model Densenet201. Model oparty na Densenet201 nie rozpoznał poprawnie obiektów definiujących scenę na obrazie para młoda" ani relacji (krojenie tortu weselnego). Znajduje to odzwierciedlenie w niskiej wartości CIDEr (11,12), pomimo poprawności gramatycznej zdania. Model z Xception wygenerował podpis adekwatny semantycznie, osiągając CIDEr wyższy o 146,85 punktu.

\subsubsection{Analiza zdolności do generalizacji}
Istotnym kryterium oceny modeli uczenia maszynowego jest ich zdolność do generalizacji na danych spoza dystrybucji zbioru treningowego (\gls{gls:ood}). Testy na obrazach zewnętrznych wykazały, że skuteczność generalizacji jest silnie uzależniona od zgodności zawartości obrazu z kategoriami reprezentowanymi w zbiorze MS COCO. Sceny zawierające znane obiekty i konteksty były opisywane precyzyjnie, natomiast obiekty spoza dystrybucji prowadziły do generowania podpisów niespójnych semantycznie.

\input{rezultaty/warstwy/obrazy_zew/obrazy_zew}
Analiza błędów potwierdziła, że wynikają one z ograniczeń leksykalnych i semantycznych zbioru treningowego. Na Rysunku~\ref{fig:obrazy_zew_e} obiekt "lama" (nieobecny w słowniku MS COCO) został błędnie sklasyfikowany jako wizualnie i semantycznie zbliżony obiekt "owca" (\gls{gls:substytucja-semantyczna}). W przypadku braku powiązanych kategorii (np. "delfiny", Rysunek~\ref{fig:obrazy_zew_e}), model generował podpisy oderwane od treści obrazu (\gls{gls:halucynacja-kategoryczna}).

Eksperyment kontrolowany z wykorzystaniem obrazów syntetycznych wygenerowanych przez narzędzie DALL-E 3~\cite{openai2023dalle3} potwierdził te obserwacje. Model poprawnie identyfikował obiekty z kategorii MS COCO (Rysunek~\ref{fig:obrazy_zew_a}), a generował błędne podpisy dla obiektów spoza tego zbioru (Rysunki~\ref{fig:obrazy_zew_c} i \ref{fig:obrazy_zew_d}).

Wykazano, że obecność kategorii w zbiorze treningowym nie gwarantuje poprawnego rozpoznania w nietypowym kontekście. Na Rysunku~\ref{fig:obrazy_zew_b} "pies" został błędnie zidentyfikowany jako "mężczyzna", mimo poprawnego rozpoznania akcji ("jazda na rowerze"). Dowodzi to ograniczonej zdolności modelu do kompozycyjnego rozumienia sceny w przypadku atypowych konfiguracji wizualnych.

\subsubsection{Optymalizacja mechanizmu fuzji i predykcji słów}
\label{sec:adaptmergepredict}
W drugim etapie badań dokonano optymalizacji \textit{komponentu RNN, adaptacyjnego, fuzji i predykcji słów} odpowiedzialnych za integrację cech multimodalnych i generowanie sekwencji wyjściowej. Jako konfigurację bazową wykorzystano koder Xception oraz osadzenia GloVe, zgodnie z rezultatami drugiego etapu.

\input{rezultaty/warstwy/merging_add}
\input{rezultaty/warstwy/merging_concatenate}
W pierwszej kolejności porównano metody fuzji cech wizualnych i tekstowych przez dodawanie oraz konkatenację. Zestawiono modele o zbliżonej architekturze, ustalając wymiarowość komponentów na 256. Wyniki dla dodawania przedstawiono w Tabeli~\ref{tab:mergingADD}, a dla konkatenacji w Tabeli~\ref{tab:mergingCONCATENATE}.

Wyniki wykazały wyższość metody konkatenacji. W porównywalnych konfiguracjach, model wykorzystujący konkatenację osiągnął wynik CIDEr na poziomie 81,85 (25,32 mln parametrów), przewyższając model bazujący na dodawaniu o 3,72 punktu (CIDEr 78,13; 25,2 mln parametrów). Metoda konkatenacji okazała się również znacznie efektywniejsza obliczeniowo, redukując czas inferencji niemal trzykrotnie (2247 ms vs 6336 ms). Konkatenacja zachowuje odrębność informacji z obu modalności, co zapewnia późniejszym warstwom większą elastyczność w modelowaniu interakcji multimodalnych, w przeciwieństwie do dodawania, które wymusza natychmiastową fuzję w tej samej przestrzeni wektorowej.

Następnie przeprowadzono optymalizację hiperparametrów dekodera opartego na LSTM. Analizowano wpływ wymiarowości \textit{komponenty RNN, adaptacyjnego oraz predykcji słów}. Zaobserwowano, że zwiększanie wymiarowości \textit{komponentu predykcji słów}, prowadziło do poprawy wyników. Najlepsze rezultaty uzyskano dla konfiguracji, w której rozmiar \textit{komponentu RNN oraz adaptacyjnego} ustalono na 256, a rozmiar \textit{komponentu predykcji słów} na 512.

Architektura o konfiguracji 256/256/512 osiągnęła najwyższy wynik CIDEr (82,49) oraz SPICE (16,08) (wiersz 4, Tabela~\ref{tab:mergingCONCATENATE}), przy 27,31 mln parametrów i czasie inferencji 2812 ms. Zestawienie modelu bez dodatkowej warstwy FC po \textit{komponencie fuzji} (wiersz 9) z modelem posiadającym tę warstwę (wiersz 4) ujawnia jej istotność (różnica 3,19 CIDEr). Wprowadzenie nieliniowości w tej warstwie wspomaga naukę złożonego mapowania i efektywną integrację informacji multimodalnych przed finalną predykcją. Uzyskany rezultat przewyższa wyniki modeli referencyjnych w Tabeli~\ref{tab:rezultaty_srednio}, co potwierdza skuteczność przeprowadzonej optymalizacji komponentów.

Jednocześnie potwierdzono, że dalsze zwiększanie pojemności modelu jest nieefektywne. Konfiguracja 512/512/1024 (33,35 mln parametrów) skutkowała spadkiem CIDEr do 79,05 oraz ponad dwukrotnym wydłużeniem czasu inferencji (6024 ms), co wskazuje na zjawisko przeuczenia (\gls{gls:overfitting}) i utratę zdolności generalizacji.

\subsubsection{Ewaluacja architektur RNN: LSTM vs. GRU}
\label{rozzdzial:eksperymenty_dotyczace_sieci_rnn}
Trzeci etap badań poświęcono ewaluacji sieci GRU jako alternatywy dla LSTM. Celem było zbadanie, czy zastosowanie architektury o mniejszej złożoności obliczeniowej pozwoli na zwiększenie efektywności przy zachowaniu porównywalnej jakości. Eksperymenty bazowały na optymalnej konfiguracji zidentyfikowanej w poprzednich eksperymentach, gdzie użyto sieci szkieletowej Xception, osadzeń GloVe oraz konkatenacji do fuzji multimodalnej.

Przeprowadzono optymalizację dekodera GRU, przy stałym rozmiarze 256 neuronów \textit{komponentu RNN i adaptacyjnego}. Najwyższą jakość (CIDEr: 82,19; SPICE: 15,76) uzyskano dla konfiguracji 256/256/256. W odróżnieniu od rezultatów dla LSTM, dalsze zwiększanie rozmiaru \textit{komponentu predykcji słów} do 512 skutkowało pogorszeniem wyniku (CIDEr: 81,41), co sugeruje niższą optymalną złożoność dekodera GRU w badanej architekturze.

\input{rezultaty/warstwy/results_gru}
Bezpośrednie porównanie optymalnych modeli GRU i LSTM wskazuje na kompromis pomiędzy skutecznością a efektywnością obliczeniową. Model LSTM uzyskał marginalnie wyższe wyniki jakościowe (przewaga o 0,3 CIDEr i 0,32 SPICE). Jednakże model GRU okazał się znacznie bardziej efektywny, posiadał o 2,12 mln mniej parametrów i generował podpisy w czasie krótszym o 989 ms. Ta przewaga jest bezpośrednią konsekwencją prostszej struktury wewnętrznej komórki GRU.

Wyniki te można tłumaczyć specyfiką zadania generowania podpisów, gdzie przetwarzane sekwencje są relatywnie krótkie, mają typowo mniej niż 50 tokenów. W takich warunkach złożone mechanizmy bramkowania LSTM, zaprojektowane do modelowania zależności długoterminowych, nie oferują istotnej przewagi nad uproszczoną architekturą GRU, która zapewnia wyższą efektywność obliczeniową.

Wybór architektury zależy zatem od priorytetów aplikacyjnych. W scenariuszach wymagających maksymalizacji metryk ilościowych, LSTM pozostaje rozwiązaniem referencyjnym. Jeżeli kluczowe są szybkość inferencji i redukcja zapotrzebowania na zasoby, jak w systemach czasu rzeczywistego, GRU stanowi konkurencyjną alternatywę.

\subsubsection{Analiza jakościowa i lingwistyczna}
W Tabeli~\ref{tab:poprawne_podpisy} przedstawiono przykłady poprawnych podpisów uzyskanych przez optymalny model z siecią Xception oraz osadzeniami GloVe dla obrazów z Rysunku~\ref{fig:poprawne_podpisy_fig}. Charakteryzują się one poprawnością gramatyczną i wysoką zgodnością semantyczną z zawartością obrazu.
\input{rezultaty/warstwy/poprawne_podpisy/poprawne_podpisy}
\input{rezultaty/warstwy/poprawne_podpisy/poprawne_podpisy_fig}

\input{rezultaty/warstwy/blednie_przewidziane_podpisy/bledne_podpisy}
\input{rezultaty/warstwy/blednie_przewidziane_podpisy/bledne_podpisy_fig}
W Tabeli~\ref{tab:bledne_podpisy} zaprezentowano przykłady błędnie wygenerowanych podpisów. Analiza wykazała, że błędne fragmenty często korelują z wysoką frekwencją występowania danych sformułowań w zbiorze treningowym, co wskazuje na tendencyjność modelu wynikającą z dystrybucji danych treningowych. Przykładowo, dla Rysunku~\ref{fig:bledne_podpisy_d}, błędny fragment "with people standing" zawiera często występujące bigramy ("with people": 1328 wystąpień; "people standing": 2740 wystąpień). Podobne zjawisko zaobserwowano dla pozostałych przykładów.

W celu analizy przyczyn błędów zbadano zasób leksykalny. Rozmiar słownika treningowego wynosił 26335 unikalnych słów. W zbiorze testowym zidentyfikowano 7197 unikalnych słów, z czego 503 występowały wyłącznie w zbiorze testowym. Ponieważ model operuje wyłącznie na słowniku treningowym, obiekty lub akcje opisane za pomocą tych 503 słów nie mogły zostać poprawnie zidentyfikowane i wystąpił problem słów spoza słownika (\gls{gls:oov}).

Analiza częstości bigramów przedstawiona w Tabeli~\ref{tab:bledne_podpisy} potwierdza, że model wykazuje tendencję do wykorzystywania struktur językowych dominujących w danych uczących. Może to prowadzić do sytuacji, w której wyuczony model językowy dominuje nad sygnałem wizualnym, skutkując generowaniem poprawnych gramatycznie, lecz nieadekwatnych semantycznie podpisów.

\subsection{Wyniki dla architektury wstrzykiwania wstępnego}
W tej części przedstawiono wyniki dla architektury wstrzykiwania wstępnego, w której wektor cech obrazu nadaje wartość początkową stanu ukrytego oraz stanu komórki sieci LSTM. Zbadano wpływ sieci szkieletowej, rozmiaru stanu ukrytego oraz szerokości wiązki w algorytmie dekodowania.

\subsubsection{Wpływ sieci szkieletowej i rozmiaru stanu ukrytego LSTM}
\input{rezultaty/warstwy/beam_search/lstm_warstwa_ukryta_siec_szkieletowa_wstrzykiwanie_wstepne}
W Tabeli~\ref{tab:lstm_warstwa_ukryta_siec_szkieletowa_wstrzykiwanie_wstepne} przedstawiono uśrednione wyniki CIDEr dla różnych architektur i rozmiarów stanu ukrytego LSTM (256, 512, 1024). Analiza danych wskazuje, że rozmiar 512 jest optymalny dla większości badanych sieci. Architektury Densenet161, Densenet121 generalnie uzyskiwały lepsze wyniki przy większych rozmiarach 512 lub 1024. Model Resnet152 wykazał wysoką wrażliwość na ten hiperparametr, osiągając optimum przy 512 i notując spadki dla 256 i 1024. Densenet161 i Densenet201 konsekwentnie poprawiały wyniki wraz ze wzrostem rozmiaru warstwy ukrytej.

\input{rezultaty/warstwy/beam_search/rezultaty_wstrzykiwanie_wstepne}
Szczegółowe wyniki badań w Tabeli~\ref{tab:rezultaty_wstrzykiwanie_wstepne}) wskazują, że najwyższą skuteczność według CIDEr osiągnął model Resnet152 z rozmiarem stanu ukrytego 512. Model Densenet201 z rozmiarem LSTM równym 1024 wykazał konkurencyjną skuteczność przy mniejszej liczbie parametrów w porównaniu do Resnet152.

Porównując rodziny architektur, modele Resnet, mimo większej liczby parametrów, konsekwentnie osiągały lepsze wyniki niż Densenet. Resnet152 przewyższa Densenet201, stosując mniejszy stan ukryty LSTM. Może to wskazywać, że głębsza architektura i połączenia rezydualne w Resnet są korzystniejsze w modelowaniu złożonych cech wizualnych dla tej architektury niż połączenia gęste w Densenet.

\subsubsection{Wpływ szerokości wiązki}
\input{rezultaty/warstwy/beam_search/szerokosc_wiazki_siec_szkieletowa_wstrzykiwanie_wstepne}
W Tabeli~\ref{tab:szerokosc_wiazki_siec_szkieletowa_wstrzykiwanie_wstepne} przedstawiono uśrednione wyniki CIDEr dla szerokości wiązki $k\in \{1, 2, 3, 5\}$ w algorytmie przeszukiwania wiązkowego. Wpływ tego parametru jest zależny od architektury modelu. Model Densenet201 uzyskał najwyższy wynik (50,02) dla $k=2$. Dla większości architektur szerokość $k=2$ okazała się optymalna lub bliska optymalnej, co sugeruje, że zwiększanie przestrzeni przeszukiwania powyżej tej wartości nie przynosi znaczącej poprawy jakości, a zwiększa koszt obliczeniowy. 


\subsubsection{Analiza jakościowa i ograniczenia metryk ewaluacyjnych}
\input{rezultaty/warstwy/beam_search/porownanie_bledne_poprawne_wstrzykiwanie_wstepne}
W Tabeli~\ref{tab:porownanie_bledne_poprawne_wstrzykiwanie_wstepne} porównano podpisy wygenerowane przez modele Densenet201 i Resnet152 do obrazów na Rysunku~\ref{fig:porownanie_bledne_poprawne_wstrzykiwanie_wstepne}). Analiza jakościowa ujawniła istotną rozbieżność pomiędzy percepcyjną jakością podpisów a wartościami metryk ewaluacji automatycznej.

\input{rezultaty/warstwy/beam_search/niski_cider_poprawny_podpis_wstrzykiwanie_wstepne}
Tabela~\ref{tab:niski_cider_poprawny_podpis_wstrzykiwanie_wstepne} ilustruje przypadki, gdzie podpisy trafnie oddają semantykę obrazu, mimo niskich wyników CIDEr. Wskazuje to na ograniczenia metryk ilościowych, faworyzujących leksykalne podobieństwo do podpisów referencyjnych, co nie zawsze koreluje z ludzką percepcją trafności. Podkreśla to konieczność stosowania holistycznego podejścia do ewaluacji, łączącego metryki ilościowe z oceną jakościową.

Manualna analiza wykazała również problemy z poprawnością gramatyczną, w szczególności błędy w stosowaniu przedimków (np. "the", "a") w języku angielskim, co wskazuje na ograniczenia modeli w zakresie precyzyjnego modelowania złożonych reguł gramatycznych.

\chapter{Badania mechanizmu uwagi}
\label{rozdzial:badania_mechanizmu_uwagi}
Rozdział prezentuje wyniki badań nad optymalizacją modeli automatycznego generowania podpisów do obrazów, rozszerzonych o mechanizm uwagi. Celem badań jest empiryczna weryfikacja synergii pomiędzy architekturą kodera wizualnego a implementacją mechanizmu uwagi oraz identyfikacja konfiguracji optymalnych pod względem efektywności predykcyjnej i obliczeniowej.

Przyjęta metodologia koncentruje się na doskonaleniu reprezentacji danych wejściowych poprzez dobór sieci szkieletowej i strategii treningowej oraz optymalizacji procesu inferencji poprzez dostrojenie algorytmu przeszukiwania wiązkowego. Analizie poddano mechanizm uwagi miękkiej, przestrzennej, adaptacyjnej oraz własnej, szerzej opisanych w Rozdziale~\ref{rozdzial:mechanizm_uwagi}.

\section{Architektura badań}
Zaproponowana architektura badawcza opiera się na paradygmacie koder-dekoder, w którym mechanizm uwagi w każdym kroku czasowym $t$ odpowiada za dynamiczne dostarczanie dekoderowi najbardziej relewantnych informacji wizualnych. Analizie poddano uwagę miękką~\cite{Xu2015ShowAttendTell} (Rysunek~\ref{fig:uwaga_miekka}), uwagę przestrzenną~\cite{Lu2017KnowingWT} (Rysunek~\ref{fig:uwaga_przestrzenna}), uwagę adaptacyjną~\cite{Lu2017KnowingWT} (Rysunek~\ref{fig:uwaga_adaptacyjna}) oraz uwagę własną~\cite{Huang2019attention} (Rysunek~\ref{fig:uwaga_wlasna}).

\input{wykresy/architektury/rodzaje_badanej_uwagi/rodzaje_uwagi}
Model składa się z kodera, odpowiedzialnego za przetwarzanie obrazu wejściowego $I$ i ekstrakcję wysokopoziomowych cech wizualnych. Koder zawiera \textit{komponent ekstrakcji cech obrazu}, realizowany za pomocą sieci szkieletowej. Na jego wyjściu powstaje mapa cech siatkowych $\mathbf{V=\{\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\}}$, gdzie $\mathbf{v}_i$ jest wektorem cech odpowiadającym $i$-temu regionowi przestrzennemu. Sieć przetwarza całą mapę cech obrazu, a Pmechanizm uwagi wybiera istotne w danym momencie fragmenty obrazu. Mapa ta jest następnie przetwarzana przez \textit{komponent adaptacyjny} w celu dopasowania jej wymiarowości do wymagań dekodera.

Dekoder odpowiada za generowanie sekwencji wyjściowej słowo po słowie i został zaimplementowany za pomocą sieci rekurencyjnej. W jego skład wchodzi \textit{komponent osadzania słów, fuzji, RNN, uwagi i predykcji słów}. \textit{Komponent osadzania słów} transformuje słowo z poprzedniego kroku $y_{t-1}$ na jego osadzenie $\mathbf{e}(y_{t-1})$. 
\textit{Komponent fuzji} przygotowuje wektor wejścia $\mathbf{x_t}$ dla sieci LSTM w \textit{komponencie RNN} poprzez agregację cech obrazu $\mathbf{V}$ oraz osadzenia $\mathbf{e}(y_{t-1})$. \textit{Komponent RNN} agreguje informacje o dotychczas wygenerowanej sekwencji. W kroku czasowym $t$ komórka LSTM aktualizuje swój stan ukryty $\mathbf{h_t}$ oraz stan komórki $\mathbf{c_t}$ na podstawie wejścia $\mathbf{x_t}$ i stanu poprzedniego $\mathbf{h_{t-1}}$, 
zgodnie z formalizmem opisanym w Sekcji~\ref{rozdzial:siec_LSTM}.

Centralnym komponentem architektury jest \textit{komponent uwagi}, obliczający wektor kontekstu wizualnego $\mathbf{z_t}$, będący ważoną reprezentację cech $\mathbf{V}$. Ostatnim elementem ścieżki dekodera jest jest \textit{komponent predykcji słów}, czyli warstwa w pełni połączona z funkcją aktywacji softmax, obliczająca rozkład prawdopodobieństwa $p(y_t)$ nad słownikiem.

Zasadniczym elementem różnicującym badane modele jest sposób obliczania oraz integracji wektora kontekstu wizualnego $\mathbf{z_t}$ podczas dekodowania. W przypadku uwagi miękkiej wektor kontekstu jest włączany bezpośrednio w pętlę rekurencyjną. Wektor kontekstu $\mathbf{z_t}$ jest obliczany na podstawie poprzedniego stanu ukrytego dekodera $\mathbf{h_{t-1}}$ oraz mapy cech $\mathbf{V}$ zgodnie z równaniem~\ref{eq:uwaga_miekka_wektor_kontekstu}. Następnie jest on konkatenowany w \textit{komponencie fuzji} z osadzeniem poprzednio wygenerowanego słowa $\mathbf{e(y_{t-1})}$ tworząc wejściowy wektor $x_t$ do komórki LSTM w \textit{komponencie RNN}, co formalizuje równanie: $\mathbf{h_t} = \text{LSTM}([\mathbf{\text{e}(y_{t-1}); z_t], h_{t-1}})$. Nowy stan ukryty $\mathbf{h_t}$, wzbogacony o kontekst wizualny $\mathbf{z_t}$, jest wykorzystywany przez \textit{komponent predykcji słów} do wygenerowania słowa $y_t$.

W odróżnieniu od powyższego, wariant uwagi przestrzennej warunkuje wektor kontekstu wizualnego nie na poprzednim stanie ukrytym $h_{t-1}$, lecz na aktualnym stanie ukrytym dekodera $h_t$. W pierwszej kolejności sieć LSTM oblicza nowy stan ukryty $\mathbf{h_t}$ na podstawie poprzedniego stanu ukrytego $\mathbf{h_{t-1}}$ oraz wektora wejściowego $x_t$, który w tym przypadku jest uśrednionym wektorem cech obrazu $avg(\mathbf{V})$ połączonym z osadzeniem słowa wygenerowanego w poprzednim kroku czasowym $\mathbf{e(y_{t-1})}$ poprzez operację konkatenacji. Dopiero nowy stan $\mathbf{h_t}$ jest wykorzystywany w \textit{komponencie uwagi} do obliczenia wektora kontekstu $\mathbf{z_t}$ zgodnie z równaniem~\ref{eq:uwaga_przestrzenna_wektor_kontekstu}. Finalna predykcja odbywa się na połączonej reprezentacji $[\mathbf{h_t};z_t]$ w \textit{komponencie predykcji słów}.

Uwaga adaptacyjna rozszerza mechanizm uwagi przestrzennej, aby sterować przepływem informacji wizualnej. W tym celu oryginalny wektor kontekstu przestrzennego $\mathbf{\hat{z_t}}$ zależny od aktualnego stanu ukrytego $\mathbf{h_t}$ w dekoderze jest modyfikowany o wektor strażnika wizualnego $\mathbf{s_t}$ oraz wektor bramki uwagi $\boldsymbol{\beta}_t$. Na podstawie wektora poprzedniego stanu ukrytego $\mathbf{h_{t-1}}$, wektora stanu komórki LSTM $\mathbf{c_t}$ oraz wektora $\mathbf{x_t}$,  bramka uwagi $\boldsymbol{\beta}_t$ decyduje, czy w danym kroku czasowym model powinien skupić się na informacjach z obrazu, czy na wiedzy już zgromadzonej. Finalny, adaptacyjny wektor kontekstu $\mathbf{z_t}$ jest kombinacją wektora kontekstu z uwagi przestrzennej $\mathbf{\hat{z_t}}$ oraz wektora strażnika wizualnego $\mathbf{s_t}$, ważoną przez bramkę strażnika wizualnego $\boldsymbol{\beta}_t$ zgodnie z wzorem~\ref{eq:uwaga_adaptacyjna_wektor_kontekstu}. Tak uzyskany wektor kontekstu $\mathbf{z_t}$ jest łączony z wektorem stanu ukrytego $\mathbf{h_t}$ stając się wejściem do \textit{komponentu predykcji słów}.

Czwarty badany wariant, uwaga własna modyfikuje sposób obliczania kontekstu wizualnego. W każdym kroku czasowym, standardowy wielogłowicowy mechanizm uwagi własnej oblicza wektor kontekstu $\hat{\mathbf{z_t}}$ na podstawie wektora stanu ukrytego dekodera $\mathbf{h_{t}}$. Następnie, w celu rafinacji uzyskanego wektora kontekstu $\hat{\mathbf{z_t}}$, równolegle obliczany jest wektor informacji $\mathbf{i}$ oraz wektor bramki $\mathbf{g}$. Wektor informacji $\mathbf{i}$ identyfikuje istotne cechy w wektorze kontekstu $\hat{\mathbf{z_t}}$, czyli połączonej reprezentacji obrazu i tekstu, z kolei wektor bramki $\mathbf{g}$ moduluje przepływ informacji poprzez ocenę ogólnej trafności wektora kontekstu $\hat{\mathbf{z_t}}$ względem aktualnego stanu ukrytego dekodera $\mathbf{h_{t}}$. Ostateczny wektor kontekstu $\mathbf{z_t}$ powstaje w wyniku mnożenia element po elemencie wektora informacji $\mathbf{i}$ oraz wektora bramki $\mathbf{g}$ zgodnie z równaniem\ref{eq:uwaga_własna_wektor_kontekstu}, aby stać się wejściem do \textit{komponentu predykcji słów}.

Po zakończeniu treningu, generowanie sekwencji wyjściowej na etapie inferencji realizowane jest w \textit{komponencie przeszukiwania} z wykorzystaniem algorytmu przeszukiwania wiązkowego. W ramach eksperymentów analizowano wpływ szerokości wiązki $k\in\{1, 2, 3, 5, 8\}$ na jakość generowanych podpisów.

W celu weryfikacji wydajności architektury w różnych konfiguracjach przetestowano zróżnicowane implementacje komponentów. Jako sieci szkieletowe w koderze wykorzystano architektury z rodziny Densenet (Densenet121, Densenet161, Densenet201), Resnet (Resnet101, Resnet152), InceptionV3 oraz Regnet. W dekoderze zastosowano wstępnie trenowane osadzenia GloVe oraz osadzenia inicjalizowane losowo, trenowane wraz z modelem.

\section{Scenariusz badawczy}
Przedstawiony scenariusz badawczy został zaprojektowany w celu weryfikacji hipotezy o istnieniu synergii pomiędzy komponentem ekstrakcji cech o a językowym. Jego realizacja ma na celu identyfikację optymalnych kombinacji między siecią szkieletową, a mechanizmem uwagi.

Pierwszy etap badań poświęcono identyfikacji i walidacji optymalnej strategii treningowej, która ukierunkowała dalsze badania. W tym celu wykonano analizę porównawczą czterech odrębnych scenariuszy treningowych, aby hierarchicznie określić wpływ poszczególnych komponentów modelu — sieci szkieletowej w \textit{komponencie ekstrakcji cech obrazu} oraz osadzeń słów  w \textit{komponencie osadzania słów} na jakość generowanych predykcji. Analiza miała na celu izolację wpływu wag sieci szkieletowej oraz wag osadzeń słów. Analizie poddano warianty modelu wykorzystujące różne strategie inicjalizacji i treningu wag. W przypadku warstwy osadzeń rozważano wektory GloVe – zamrożone lub dostrajane w trakcie uczenia – oraz wagi inicjowane losowo i trenowane od początku. Każde z tych rozwiązań testowano w połączeniu z zamrożonymi lub w pełni trenowanymi wagami sieci szkieletowej dla jednego wariantu mechanizmu uwagi.

Na podstawie wyników uzyskanych w pierwszym etapie badawczym, w fazie drugiej przeprowadzono systematyczną analizę porównawczą interakcji pomiędzy różnymi sieciami szkieletowymi a mechanizmami uwagi. Weryfikacji poddano siedem architektur: Regnet, InceptionV3, trzy warianty Densenet (201, 161, 121) oraz dwa warianty Resnet (101, 152). Ich współdziałanie oceniano z uwagą adaptacyjną, przestrzenną oraz włąsną.

W badaniach zastosowano dwie odmienne strategie uczenia, dobrane adekwatnie do charakteru analizowanych mechanizmów uwagi. Dla modeli z uwagą adaptacyjną, przestrzenną i miękką wdrożono zweryfikowaną procedurę dwuetapową, wykorzystującą wstępnie trenowane osadzenia słów GloVe. W pierwszym etapie (do 30 epok), przy zamrożonych wagach sieci szkieletowej oraz osadzeń, optymalizowano wyłącznie parametry warstw uwagi. W etapie drugim (do 50 epok) cały model był dostrajany w trybie end-to-end.

Odmienne, holistyczne podejście przyjęto dla uwagi własnej, zgodnie z pracą referencyjną~\cite{Huang2019attention}. Model trenowano od podstaw zgodnie z strategią end-to-end, z początkowo losowymi wagami osadzeń słów. Wybór tej strategii był motywowany dążeniem do wytworzenia spójnej, multimodalnej przestrzeni reprezentacji, w której cechy wizualne i językowe są wzajemnie skalibrowane. Uczenie osadzeń od podstaw pozwala na ich precyzyjne dopasowanie do ograniczonego słownictwa w zbiorze danych, eliminując potencjalny szum informacyjny z generycznych wektorów GloVe. Jednocześnie, dostrajanie sieci szkieletowej od początku treningu pozwala na ekstrakcję cech wizualnych, które są bezpośrednio relewantne dla generowania złożonych podpisów, a nie tylko dla rozpoznawania obiektów.

Ocenę skuteczności poszczególnych kombinacji architektur przeprowadzono, analizując kompromis między wydajnością predykcji, a złożonością obliczeniową. Wydajność mierzono za pomocą metryki CIDEr oraz wartości funkcji straty, natomiast złożoność wyrażono liczbą parametrów modelu. Uzupełniająco raportowano również metryki BLEU (1-4) oraz ROUGE-L. Uzyskane wyniki odniesiono do modeli referencyjnych, zdefiniowanych na podstawie literatury wprowadzającej dany mechanizm uwagi: Resnet-152 dla uwagi adaptacyjnej i przestrzennej oraz Resnet-101 dla uwagi miękkiej i własnej.

Trzeci etap badań koncentrował się na analizie dynamiki procesu treningowego, w szczególności na wpływie wyboru sieci szkieletowej i mechanizmu uwagi na szybkość konwergencji modelu. Jako miarę szybkości przyjęto liczbę epok niezbędną do osiągnięcia optymalnej wartości metryki CIDEr na zbiorze walidacyjnym. W pierwszej kolejności dokonano oceny uśrednionej, porównując średnią liczbę epok wymaganą do konwergencji dla każdego z czterech mechanizmów uwagi, uśredniając wyniki ze wszystkich testowanych rodzajów sieci szkieletowej. Następnie przeprowadzono analizę szczegółową, badając interakcje dla każdej pary mechanizm uwagi - sieć szkieletowa.

Ostatnia faza badawcza poświęcona została optymalizacji inferencji poprzez analizę metody przeszukiwania wiązkowego. Analizowano wpływ szerokości wiązki $k$ na jakość generowanych podpisów. Badanie przeprowadzono dla dyskretnego zbioru wartości $k \in \{1,2,3,5,8\}$, testując każdą wartość dla wszystkich wcześniej zweryfikowanych kombinacji mechanizmów uwagi i sieci szkieletowych. Celem badawczym było zidentyfikowanie optymalnej wartości parametru $k$, która stanowi najkorzystniejszy kompromis między jakością predykcji, mierzoną metryką CIDEr, a złożonością obliczeniową inferencji.

\section{Przebieg treningu}
Procedurę treningową rozpoczęto od przygotowania danych wejściowych. Każdy obraz ze zbioru treningowego poddano sekwencji transformacji w celu ujednolicenia formatu wejściowego zgodnie z wymaganiami testowanej sieci szkieletowej. Obejmowało to skalowanie obrazów do wymaganej rozdzielczości (np. $256\times256\times3$ dla Densenet i Resnet101; $342\times342\times3$ dla InceptionV3; $232\times232\times3$ dla Resnet152; $384\times384\times3$ dla Regnet). Następnie wartości pikseli znormalizowano do zakresu $[0,1]$. Równolegle przetworzono referencyjne podpisy tekstowe, budując globalny słownik. Każde zdanie uzupełniono o tokeny specjalne oznaczające początek $<$START$>$ i koniec $<$STOP$>$ sekwencji oraz poddano normalizacji, co szczegółowo opisano w Sekcji~\ref{rozdzial:wstepne_przetwarzanie}.

Następnie, w ramach pojedynczej iteracji treningowej, wstępnie przetworzona partia obrazów była przekazywana do \textit{komponentu ekstrakcji cech obrazu} celem wydobycia cech obrazu przez wybraną sieć szkieletową. W rezultacie tego działania obraz wejściowy był przetwarzany na wielowymiarową mapę cech $\mathbf{V}$. Długości wektorów cech składających się na mapę cech $\mathbf{V}$ były zależne od architektury (np. 2048 dla Resnet101/152 i InceptionV3; 3712 dla Regnet; 1024, 2208, 1920 odpowiednio dla Densenet121, Densenet161, Densenet201).

Podczas treningu modelu w każdym kroku czasowym $t$ do dekodera podawane jest słowo referencyjne $y_{t-1}$ ze zbioru treningowego, zamiast słowa wygenerowanego przez model w kroku poprzednim, zgodnie z metodą uczenia z nauczycielem. Stabilizuje to proces uczenia i przyspiesza konwergencję. W każdym kroku $t$, w zależności od badanego wariantu mechanizmu uwagi, dekoder obliczał wektor kontekstu wizualnego $\mathbf{z_t}$, aktualizował stan ukryty $\mathbf{h_t}$ i generował rozkład prawdopodobieństwa dla następnego słowa $p(y_t)$.

Stratę modelu obliczano metodą entropii krzyżowej, a obliczony błąd wykorzystywano do estymacji gradientów. Do aktualizacji wag modelu posłużył optymalizator Adam, skonfigurowany z parametrami $\beta_1 = 0,9$, $\beta_2 = 0,999$ oraz $\epsilon = 1 \times 10^{-8}$ w celu zapewnienia stabilności numerycznej. Uczenie prowadzono w partiach o rozmiarze 10. Bazowy współczynnik uczenia dla dekodera wynosił $4 \times 10^{-4}$, a dla kodera w przypadku jego douczania $1 \times 10^{-4}$.

Po zakończeniu każdej epoki przeprowadzano ewaluację na zbiorze walidacyjnym. Obliczano stratę walidacyjną, dokładność TOP-5 oraz BLEU-4. Model, który osiągnął najwyższą wartość metryki BLEU-4 na zbiorze walidacyjnym, był zapisywany jako punkt kontrolny. 

Zaimplementowano również mechanizmy kontroli przebiegu uczenia. Zastosowano adaptacyjną zmianę współczynnika uczenia, którego wartość była redukowana o 20\% (mnożnik 0,8) w sytuacji, gdy metryka BLEU-4 na zbiorze walidacyjnym nie uległa poprawie przez osiem kolejnych epok. Trening zaplanowano na 50 epok, przy czym mógł on zostać zakończony wcześniej przez mechanizm wczesnego zatrzymania powodujący przerwanie treningu, jeżeli wartość funkcji straty na zbiorze walidacyjnym nie zmniejszyła się przez pięć następujących po sobie epok.

\section{Przebieg testowania}
Procedura weryfikacji wydajności wytrenowanego modelu obejmowała ocenę ilościową, bazującą na standardowych metrykach dziedzinowych, oraz pogłębioną analizę jakościową, ukierunkowaną na interpretację zachowania modelu.

Podstawą oceny ilościowej jest predykcja podpisu dla każdego obrazu ze zbioru testowego. Inferencja rozpoczyna się od załadowania punktu kontrolnego modelu, wyselekcjonowanego podczas treningu, oraz słownika mapującego indeksy słów na ich leksykalne odpowiedniki. Obraz wejściowy poddawany jest serii transformacji, tożsamych z tymi stosowanymi w fazie treningowej, opisanymi w Sekcji~\ref{rozdzial:wstepne_przetwarzanie}, a następnie przetwarzany przez koder na mapę cech obrazu $\mathbf{V}$.

Generowanie podpisu ma charakter iteracyjny. W odróżnieniu od fazy treningowej w każdym kroku czasowym $t$ wejściem do dekodera jest słowo wygenerowane przez model w kroku poprzednim $y_{t-1}$. Proces inicjowany jest przez podanie wektora osadzenia dla tokenu specjalnego $<$START$>$. W każdym kolejnym kroku \textit{komponent predykcji słów} generuje rozkład prawdopodobieństwa na całym słowniku. Rozkład ten jest wejściem do \textit{komponentu przeszukiwania}, który buduje zdanie o szerokości wiązki $k$ zgodnie z algorytmem przeszukiwania wiązkowego. Iteracje są kontynuowane aż do osiągnięcia kryterium terminacji. Finalny podpis jest porównywany z zestawem pięciu podpisów referencyjnych przy użyciu metryk BLEU-1 do BLEU-4, CIDEr oraz ROUGE-L.

Uzupełnieniem dla metryk ilościowych jest ewaluacja jakościowa, która polega na wizualizacji wag pochodzących z mechanizmu uwagi. Dla reprezentatywnych przykładów ze zbioru testowego generowano mapy cieplne i nakładano na reprezentatywne obrazy wejściowe. Intensywność barwy w danym regionie odpowiada wartości wagi uwagi $\boldsymbol{\alpha}_t$, jaką model przypisał temu regionowi podczas generowania słowa $y_t$. W przypadku modelu z uwagą adaptacyjną, wizualizacji podlega również wartość bramki strażnika $\boldsymbol{\beta}_t$, określająca stopień wykorzystania informacji wizualnej względem lingwistycznej. Analiza tych wizualizacji umożliwia wgląd w proces decyzyjny modelu i identyfikację regionów obrazu, które miały największy wpływ na predykcję poszczególnych słów.

Analiza jakościowa opiera się na studium wybranych przypadków. Po pierwsze, badane są przypadki pozytywne, dla których model wygenerował adekwatne podpisy. Wizualizacje uwagi służą w tej sytuacji do weryfikacji, czy model prawidłowo lokalizuje kluczowe obiekty i ich atrybuty. Po drugie, przeprowadzana jest analiza błędów, obejmująca identyfikację i kategoryzację nieprawidłowości (np. halucynacje obiektów, błędne relacje przestrzenne). W tych przypadkach wizualizacja uwagi pełni rolę narzędzia diagnostycznego. Zastosowane połączenie ewaluacji ilościowej i jakościowej stanowi kompletny schemat badawczy, umożliwiający holistyczną ocenę wydajności predykcyjnej modelu oraz jego wiarygodności.

\section{Rezultaty}
\subsection{Analiza strategii treningowych}
W pierwszym etapie badań przeprowadzono szczegółową analizę wpływu czterech odrębnych strategii treningowych na wydajność modelu automatycznego generowania podpisów do obrazów. Ewaluację oparto na monitorowaniu funkcji straty oraz metryki CIDEr w trakcie uczenia modelu wykorzystującego uwagę miękką oraz sieć szkieletową Densenet201. Wyniki zobrazowano na Rysunkach~\ref{fig:wplyw_strategii_treningu_osadzen_strata} i \ref{fig:wplyw_strategii_treningu_osadzen_cider}. Celem analizy było hierarchiczne określenie wpływu poszczególnych komponentów modelu – sieci szkieletowej oraz warstwy osadzeń słownych – na finalną jakość predykcji.

\input{rezultaty/uwaga/embeddingi_zmiana_strata_cider/wplyw_strategii_treningu_osadzen_strata}
\input{rezultaty/uwaga/embeddingi_zmiana_strata_cider/wplyw_strategii_treningu_osadzen_cider} 
We wszystkich badanych wariantach, zaobserwowano systematyczny spadek wartości funkcji straty (Rysunek~\ref{fig:wplyw_strategii_treningu_osadzen_strata}). Potwierdza to skuteczną optymalizację parametrów modelu. Najbardziej intensywna faza uczenia przypada na pierwsze cztery do sześciu epok, po których krzywa uczenia osiąga \gls{gls:plateu}, sygnalizując konwergencję modelu. Najniższą wartość, a tym samym najlepsze dopasowanie do zbioru treningowego, uzyskano w przypadku modelu, w którym zarówno początkowo losowe osadzenia słów, jak i wagi sieci szkieletowej podlegały treningowi. Umożliwienie dostrajania wag sieci szkieletowej okazało się czynnikiem decydującym. Model z trenowanymi wagami (krzywa szara) osiągnął znacząco niższą wartość straty w porównaniu do jego odpowiednika z zamrożonymi wagami (krzywa żółta) przy tej samej strategii losowych osadzeń.

Zastosowanie wstępnie trenowanych osadzeń GloVe, które podlegały dalszemu treningowi (krzywa czarna), przyniosło drugą w kolejności najniższą wartość funkcji straty. Wynik ten, choć nieznacznie gorszy od najlepszego wariantu, jednoznacznie przewyższa konfiguracje z zamrożonymi wagami sieci szkieletowej. Zgodnie z przewidywaniami, najwyższą wartość funkcji straty, świadczącą o najsłabszej zdolności adaptacyjnej, odnotowano dla strategii, w której zarówno wagi sieci szkieletowej, jak i wstępnie trenowane osadzenia GloVe pozostały zamrożone (krzywa pomarańczowa). W tym scenariuszu proces uczenia ograniczał się wyłącznie do warstw mechanizmu uwagi, co znacząco limitowało potencjał modelu.

Analiza metryki CIDEr (Rysunek~\ref{fig:wplyw_strategii_treningu_osadzen_cider}) pozwoliła ocenić, w jakim stopniu niższa wartość funkcji straty koreluje z jakością semantyczną generowanych podpisów. Wyniki potwierdziły obserwacje poczynione na podstawie funkcji straty, jednocześnie uwydatniając większe zróżnicowanie w wydajności modeli. Wariant, w którym dostrajano wszystkie komponenty (losowo inicjalizowane osadzenia oraz wagi sieci szkieletowej), osiągnął najwyższy wynik CIDEr ($\approx 85$).

Czynnikiem determinującym wysoką wydajność jest dostrajanie wag sieci szkieletowej. Porównanie modelu z dostrajanymi wagami (CIDEr $\approx 85$, krzywa szara) z modelem o zamrożonych wagach (CIDEr $\approx 79$, krzywa żółta), przy losowej inicjalizacji osadzeń, wykazuje wzrost wydajności o około 6 punktów CIDEr. Wskazuje to, że adaptacja ekstraktora cech wizualnych do domeny docelowej jest fundamentalna dla uzyskania wysokiej jakości podpisów. Wpływ wstępnie trenowanych osadzeń GloVe jest zauważalny, lecz drugorzędny. Przy zamrożonych wagach sieci szkieletowej, wykorzystanie dostrajanych osadzeń GloVe (CIDEr $\approx 73$, krzywa niebieska) skutkuje niewielką poprawą (około 2 punkty) w stosunku do wariantu z zamrożonymi osadzeniami (CIDEr $\approx 71$, krzywa pomarańczowa).

Ewaluacja na zbiorze testowym potwierdziła znaczenie dostrajania wag sieci szkieletowej na jakość generowanych podpisów, co jest zgodne z obserwacjami na zbiorze walidacyjnym. Dwa najwyżej ocenione warianty modelu z CIDEr wyższym niż 105 wykorzystywały dostrajanie wag sieci Densenet201.

Analiza wyników na zbiorze testowym ujawniła jednak rozbieżności względem obserwacji na zbiorze walidacyjnym. Wbrew rezultatom uzyskanym na zbiorze walidacyjnym, faworyzującym podejście end-to-end, najwyższą zdolność do generalizacji na zbiorze testowym wykazała strategia dwuetapowa (CIDEr $\approx$ 109). Sugeruje to, że procedura dwuetapowa sprzyja wypracowaniu bardziej generalnych reprezentacji cech, potencjalnie redukując ryzyko przetrenowania. Procedura dwuetapowa obejmuje wstępny trening mechanizmu uwagi przy zamrożonych wagach sieci szkieletowej celem stabilizacji, a następnie symultaniczne dostrajanie wszystkich warstw modelu. 

Wyniki testowe potwierdzają, że wpływ warstwy osadzeń na finalną wydajność jest drugorzędny względem wpływu dostrajania sieci szkieletowej. Dwuetapowa procedura treningowa umożliwiła modelowi z losowymi osadzeniami osiągnięcie wysokiego wyniku CIDEr równego 107. Niemniej najwyższą wydajność (CIDEr = 109) uzyskano w konfiguracji łączącej wstępnie trenowane osadzenia GloVe oraz dwuetapową procedurę uczenia. Wskazuje to, że choć model jest w stanie efektywnie uczyć się reprezentacji słów od podstaw, wykorzystanie wiedzy zawartej w osadzeniach GloVe w połączeniu z optymalną strategią treningową pozwala na maksymalizację jakości generowanych podpisów.

Podsumowując, najwyższą jakość podpisów na zbiorze testowym zapewniła dwuetapowa procedura optymalizacyjna, polegająca na wstępnej specjalizacji mechanizmu uwagi, a następnie wspólnym dostrojeniu całej architektury. Niezależnie od procedury, decydującym warunkiem uzyskania wysokiej wydajności modelu było dostrajanie wag sieci szkieletowej.

\subsection{Analiza porównawcza architektur uwagi}
W oparciu o wnioski dotyczące strategii treningowych, przeprowadzono analizę porównawczą różnych wariantów mechanizmów uwagi oraz ich interakcji z architekturami sieci szkieletowych. Eksperymenty zrealizowano z wykorzystaniem najefektywniejszych strategii,dwuetapowej z osadzeniami GloVe lub strategii end-to-end z losową inicjalizacją osadzeń, w zależności od specyfiki mechanizmu uwagi.


\subsubsection{Analiza wydajności i złożoności obliczeniowej}
\label{sec:analiza_wydajnosci}
\input{rezultaty/uwaga/uwaga_rezultaty_douczanie}
\input{rezultaty/uwaga/zmiana_wartosci_uwagi}
W Tabeli~\ref{tab:uwaga_rezultaty_douczanie} zaprezentowano szczegółowe porównanie wyników uzyskanych dla różnych architektur sieci szkieletowych przy zastosowaniu szerokości wiązki $k=3$. Podstawę analizy stanowiła Tabela~\ref{tab:zmiana_wartosci_uwagi}, gdzie porównano wyniki uzyskane przez modele z różnymi architekturami sieci szkieletowych. Jako modele referencyjne przyjęto dla uwagi adaptacyjnej i przestrzennej architekturę Resnet152, a dla uwagi miękkiej i własnej – Resnet101. 

W przypadku mechanizmu uwagi adaptacyjnej model referencyjny oparty na Resnet152 charakteryzował się wynikiem CIDEr na poziomie 104,48 przy 68,29 miliona parametrów. Wariant wykorzystujący sieć Regnet osiągnął najwyższą wartość metryki CIDEr (106,97). Stanowi to wzrost o 2,38\% w odniesieniu do modelu referencyjnego. Poprawa ta była jednak skorelowana ze znacznym wzrostem liczby parametrów o 34,32\%. Z perspektywy optymalizacji parametrowej architektura InceptionV3 okazała się wysoce efektywnym kompromisem, wykazując niewielki wzrost metryki CIDEr o 0,51\% przy jednoczesnej redukcji liczby parametrów aż o 52,91\%. Z kolei zastosowanie architektur z rodziny Densenet (201, 161, 121) oraz Resnet101 skutkowało obniżeniem wartości metryki CIDEr w zakresie od -1,42\% do -4,73\%. Największą redukcję parametrów (-75,86\%) zaobserwowano przy Densenet121, co wiązało się jednak z spadkiem jakości generowanych podpisów (-4,04\% CIDEr).

Dla uwagi przestrzennej, gdzie model referencyjny z Resnet152 uzyskał wynik CIDEr równy 102,38 przy 68,29 miliona parametrów, zaobserwowano podobne tendencje. Ponownie sieć Regnet uzyskała najwyższą skuteczność (CIDEr 105,89), co stanowiło wzrost o 3,43\%. Wzrosła jednak liczba parametrów o 34,32\%. Co istotne, architektury Densenet201 i InceptionV3 pozwoliły na znaczącą redukcję złożoności (odpowiednio o -58,49\% i -52,91\%) przy jednoczesnym zachowaniu, a nawet marginalnym wzroście metryki CIDEr (odpowiednio +0,78\% i +0,08\%). Modele oparte na Resnet101, Densenet161 i Densenet121 ponownie wykazały spadek skuteczności, z wartościami \% $\Delta$ CIDEr w przedziale od -1,93\% do -2,55\%.

Analiza mechanizmu uwagi miękkiej przyniosła odmienne rezultaty. Model referencyjny z Resnet101 osiągnął CIDEr 104,83 przy 59,33M parametrów. W tym przypadku najkorzystniejszą konfigurację stanowił model z siecią Densenet201, który osiągnął najwyższy wynik CIDEr (108,96, wzrost o 3,94\%), jednocześnie redukując liczbę parametrów o 41,58\%. Istotny wzrost skuteczności zaobserwowano również dla Resnet152 (+3,52\%), InceptionV3 (+3,14\%) oraz Densenet161 (+2,57\%). Należy jednak zaznaczyć, że Resnet152 cechuje się o 21,57\% większą liczbą parametrów niż model odniesienia. Dla uwagi miękkiej zaobserwowano również anomalię wydajnościową. Sieć Regnet, mimo najwyższych wskaźników skuteczności w innych konfiguracjach, w połączeniu z uwagą miękką wykazała drastyczną degradację metryki CIDEr o 11,53\% przy jednoczesnym wzroście liczby parametrów o 43,48\%.

W przypadku mechanizmu uwagi własnej, model referencyjny oparty na Resnet101 charakteryzował się wysokim wynikiem CIDEr (110,66), lecz również bardzo dużą liczbą parametrów równą 129,87 miliona. Jednakże model z siecią Regnet zdołał przewyższyć ten wynik, osiągając CIDEr 117,60 (wzrost o 6,27\%), co wiązało się jednak ze dalszym wzrostem liczby parametrów o 30,08\%. Wszystkie pozostałe badane architektury (Resnet152, rodzina Densenet, InceptionV3) spowodowały znaczące obniżenie skuteczności modelu. Spadki wartości CIDEr były bardzo wyraźne, od -1,57\% dla Resnet152 do aż -23,63\% dla InceptionV3. Mimo że modele te pozwalały na redukcję parametrów (np. -27,47\% dla Densenet121), towarzyszący jej drastyczny spadek jakości (-11,04\% CIDEr) dyskwalifikuje je jako efektywne alternatywy w tej konfiguracji.

W ramach przeprowadzonych badań eksperymentalnych nie zidentyfikowano uniwersalnie optymalnej architektury sieci szkieletowej, która maksymalizowałaby skuteczność wszystkich typów mechanizmów uwagi. Dobór sieci szkieletowej stanowi decyzję projektową, która musi być podejmowana w ścisłym powiązaniu z charakterystyką zaimplementowanego mechanizmu uwagi. W badaniach zaobserwowano złożone interakcje pomiędzy tymi dwoma komponentami, manifestujące się w postaci efektów synergicznych lub antagonistycznych.

Pozytywny efekt synergiczny zidentyfikowano w przypadku połączenia architektur z rodziny Densenet z uwagą miękką, gdzie uzyskano jedne z najwyższych wskaźników jakości generowanych podpisów. W opozycji, zjawisko antagonizmu zilustrowano na przykładzie tej samej konfiguracji z siecią Regnet, która uległa znaczącej degradacji wydajności. Ponadto, analiza mechanizmu uwagi własnej wykazała jego niską kompatybilność z większością testowanych architektur, gdyż jedynie w połączeniu z sieciami Resnet101 oraz Regnet pozwolił na efektywny i stabilny proces treningu.

Wybór architektury jest również nierozerwalnie związany z kompromisem między skutecznością a złożonością. Sieć Regnet konsekwentnie zapewnia najwyższą skuteczność dla uwagi adaptacyjnej, przestrzennej i własnej, jednak jest to osiągane kosztem wysokiej złożoności parametrycznej. Z drugiej strony, architektury takie jak InceptionV3 oraz Densenet201 często stanowią optymalne rozwiązanie w kontekście wskaźnika wydajności do złożoności, umożliwiając znaczną redukcję liczby parametrów przy zachowaniu lub nieznacznej poprawie metryki CIDEr.

Szczególnie wymagający okazał się mechanizm uwagi własnej, który narzuca najbardziej rygorystyczne ograniczenia co do architektury bazowej. Pozytywne lub akceptowalne rezultaty przyniosły jedynie modyfikacje w obrębie rodziny Resnet/Regnet, co sugeruje, że natura cech wyekstrahowanych przez te konkretne sieci jest kluczowa dla prawidłowego funkcjonowania tego mechanizmu. W konkluzji, wyniki wskazują na fundamentalną konieczność przeprowadzania walidacji i doboru sieci szkieletowej specyficznie dla każdego zadania i zastosowanego mechanizmu uwagi, zamiast polegania na ogólnie przyjętych, najnowocześniejszych sieciach bazowych.

\subsubsection{Analiza porównawcza czasu zbieżności}

Analiza uśrednionych wyników (Rysunek~\ref{fig:sredni_czas_zbieznosci}) wykazała istotne zróżnicowanie tempa konwergencji. Uwaga własna osiągała optymalną zbieżność najszybciej, średnio po $\approx 18,9$ epokach. Mechanizm uwagi adaptacyjnej wymagał średnio $\approx 20,9$ epok. Najwolniejszą konwergencją charakteryzowały się mechanizmy uwagi miękkiej ($\approx 22,1$ epok) oraz przestrzennej ($\approx 22,2$ epok). Szybsza zbieżność uwagi własnej jest skorelowana z zastosowaną dla niej odmienną strategią treningową (end-to-end, losowe osadzenia), co sugeruje, że ta procedura przyspiesza proces uczenia w porównaniu do strategii dwuetapowej stosowanej dla pozostałych mechanizmów. Szczegółową analizę interakcji przedstawiono na Rysunku~\ref{fig:wplyw_bazowej_cnn_na_czas_zbieznosci_modelu}.

\input{rezultaty/uwaga/naj_epoka/sredni_czas_zbieznosci}
\input{rezultaty/uwaga/naj_epoka/wplyw_bazowej_cnn_na_czas_zbieznosci_modelu}
Dla uwagi adaptacyjnej, model referencyjny Resnet152 osiągnął zbieżność w 33 epoce. Modele oparte na InceptionV3 oraz Densenet201 uzyskały zbieżność istotnie szybciej, odpowiednio w 15 i 17 epoce, co wskazuje na znaczny potencjał optymalizacji czasu treningu poprzez dobór sieci szkieletowej.

W przypadku uwagi przestrzennej, model referencyjny Resnet152 wymagał 31 epok. Zastosowanie architektury Regnet skróciło czas treningu do 20 epok. Najdłuższy proces uczenia zaobserwowano dla sieci Resnet101 (34 epoki).

Analiza uwagi miękkiej wykazała, że najszybszą zbieżność uzyskano dla sieci Regnet (32 epoki), a najwolniejszą dla Densenet121 (41 epok). Należy jednak zaznaczyć, iż w kontekście analizy wydajności (Sekcja~\ref{sec:analiza_wydajnosci}), konfiguracja Regnet z uwagą miękką charakteryzowała się znaczącą degradacją metryki CIDEr. Szybka konwergencja w tym przypadku oznaczała zatem szybkie osiągnięcie nieoptymalnego minimum lokalnego, co potwierdza antagonistyczną interakcję między tymi komponentami.

Dla uwagi własnej, model referencyjny Resnet101 osiągnął zbieżność w 19 epoce. Najszybszą konwergencję odnotowano dla sieci InceptionV3 (14 epok), a następnie dla Regnet (16 epok) i Densenet201 (18 epok).

Podsumowując, mechanizm uwagi własnej zapewnia najszybszą zbieżność modelu. Jednakże, wybór architektury sieci szkieletowej ma istotny wpływ na tempo uczenia, często przewyższający wpływ samego mechanizmu uwagi. Modele oparte na architekturach InceptionV3, Densenet201 oraz Regnet systematycznie wykazywały najwyższą szybkość zbieżności. Modele referencyjne Resnet152, Resnet101 w większości przypadków nie stanowiły konfiguracji optymalnych pod względem czasu treningu.

\subsubsection{Analiza jakościowa i ograniczenia metryk ewaluacyjnych}
\input{rezultaty/uwaga/analiza/analiza}
\input{rezultaty/uwaga/analiza/analiza_niski_cider}
Przeprowadzono analizę zgodności leksykalnej podpisów wygenerowanych dla przykładowego obrazu kuchni, przedstawionego na Rysunku~\ref{fig:analiza}, przez cztery modele z różnymi mechanizmami uwagi, wykorzystujące sieć szkieletową Resnet152. Wyniki porównano z podpisami referencyjnymi w Tabeli~\ref{tab:analiza}. Wszystkie modele poprawnie zidentyfikowały scenę ("kitchen") oraz centralny obiekt ("stove"). Rozbieżności dotyczyły identyfikacji trzeciego obiektu. Modele wygenerowały "refrigerator", "pot", "microwave" oraz "sink". Żaden z tych lematów nie występuje w podpisach referencyjnych dla tego obrazu. Zjawisko to klasyfikuje się jako halucynację obiektów (\gls{gls:object-hallucination}), będącą manifestacją tendencyjności językowej. Wskazuje to na sytuację, w której wyuczony model językowy dominuje nad sygnałem wizualnym. W konsekwencji model generuje obiekty statystycznie skorelowane z kontekstem w zbiorze treningowym, co prowadzi do powstawania podpisów poprawnych gramatycznie, lecz nieadekwatnych wizualnie.

Metryki oparte na n-gramach (BLEU, ROUGE\_L) okazały się niewystarczająco czułe na ten błąd. Identyczne, wysokie wartości ($BLEU\_1 = 0,875$, $ROUGE\_L = 0,698$) wynikają z poprawnego odtworzenia bazowej struktury zdania ("a kitchen with a..."), która wykazuje wysokie pokrycie n-gramowe z podpisami referencyjnymi. Metryka CIDEr zróżnicowała oceny, przypisując najwyższy wynik (1,043) modelowi z uwagą własną ("sink"). Wyższa ocena wynika wyłącznie z faktu, że lemat "sink" posiada wyższą wagę TF-IDF w kontekście scen kuchennych w korpusie zdań referencyjnych niż pozostałe wygenerowane obiekty. Metryka CIDEr faworyzowała zatem słowo statystycznie istotne dla kontekstu, pomimo jego braku w podpisach referencyjnych. Przykład ten ilustruje specyfikę metryki CIDEr, która premiuje istotność semantyczną w ujęciu całego korpusu, co może odbywać się kosztem wierności wizualnej dla wybranego obrazu.

Drugi przypadek na Rysunku~\ref{fig:analiza_niski_cider} ilustruje błąd polegający na pominięciu elementu definiującego treść sceny wizualnej. Podpisy referencyjne identyfikują narciarza ("skier", "man") oraz interakcję z obiektem zewnętrznym ("parachute", "wires", "cables", "handle"), a obraz przedstawia nietypową aktywność (snowkiting).

Wygenerowane podpisy wykazały ujednoliconą, generyczną strukturę: "a man riding [skis/a snowboard] [down/on top of] a snow covered slope". Wszystkie modele poprawnie zidentyfikowały ogólny kontekst, jednak żaden nie uwzględnił kluczowego obiektu "spadochronu/latawca". Stanowi to istotny błąd semantyczny, polegający na redukcji złożonej sceny do typowego scenariusza jakim jest "zjazd narciarski", co wskazuje na ograniczoną zdolność modeli do kompozycyjnego rozumienia sceny wizualnej. Ponadto, część modeli, głównie opartych na Densenet, błędnie sklasyfikowała sprzęt jako "snowboard".

Wysokie podobieństwo wygenerowanych podpisów sugeruje konwergencję modeli do generycznego rozwiązania, silnie reprezentowanego w danych treningowych. Błędy w identyfikacji obiektów miały bezpośredni wpływ na metryki. W przypadku klasyfikacji sprzętu jako "snowboard", CIDEr obniżyła się do $\approx 13,5$, w porównaniu do $\approx 35,5$ przy poprawnej identyfikacji ("skis"). Chociaż metryki różnicują podpisy na podstawie słów kluczowych, nawet najwyżej ocenione wyniki są semantycznie niekompletne. Podkreśla to rozbieżność między automatyczną ewaluacją opartą na podobieństwie leksykalnym a adekwatnością semantyczną. Nie stwierdzono systematycznej przewagi jednego mechanizmu uwagi, jednak zaobserwowano różnice zależne od kodera wizualnego. Sieć Inception poprawnie identyfikowała narty, w przeciwieństwie do Densenet.

Stwierdzono silną korelację pomiędzy liczbą lematów wspólnych z referencjami a wartościami metryk. Modele z błędnym lematem "snowboard" uzyskały niskie wyniki (CIDEr $\approx 13,46$). Zastąpienie go poprawnym lematem "ski" spowodowało znaczący wzrost (CIDEr $\approx 35,6$). Wzrost ten jest warunkowany poprawną identyfikacją jednego obiektu o wysokiej istotności, czyli wagą TF-IDF.

Przedstawione analizy wskazują, że badane modele wykazują tendencję do generowania podpisów generycznych, odzwierciedlających dominujące wzorce w danych treningowych, przy jednoczesnym pomijaniu unikalnych detali lub nietypowych interakcji. Uwidacznia to ograniczenia w zakresie kompozycyjnego rozumienia sceny. Analizowane przykłady potwierdzają również, że wysokie wartości metryk ewaluacyjnych nie są gwarantem semantycznej poprawności i kompletności wygenerowanego podpisu.



\subsection{Optymalizacja strategii przeszukiwania}
W niniejszym podrozdziale dokonano ewaluacji wpływu parametru szerokości wiązki $k$ algorytmu przeszukiwania wiązkowego na jakość generowanych podpisów, mierzoną metryką CIDEr. Analiza objęła spektrum konfiguracji eksperymentalnych, uwzględniających cztery typy mechanizmów uwagi oraz siedem architektur sieci szkieletowych.

Dla każdej konfiguracji zbadano zmiany wartości metryki CIDEr dla zbioru wartości $k\in\{1,2,3,5,8\}$. Celem była identyfikacja optymalnej wartości parametru $k$ oraz charakterystyka jego wpływu na wydajność modelu w interakcji z komponentami architektury.

\input{rezultaty/uwaga/analiza_beam/dystrybucja_cider_dla_rozmiaru_wiazki}
Analiza dystrybucji wyników CIDEr na Rysunku~\ref{fig:dystrybucja_cider_dla_rozmiaru_wiazki} wykazuje istotną przewagę przeszukiwania wiązkowego nad dekodowaniem zachłannym. Mediana wartości CIDEr wzrasta z około 95 ($k=1$) do niemal 100 dla $k=2$ i $k=3$. Dla wartości parametru k większych od 3 (k=5, k=8) nie zaobserwowano dalszego wzrostu metryki CIDEr. Mediana utrzymuje się na zbliżonym poziomie lub nieznacznie spada. Analiza rozproszenia wyników wykazała, że dla $k=8$ następuje zwiększenie rozstępu międzykwartylowego, co wskazuje na wzrost wariancji i obniżenie stabilności predykcji. Obserwacje te implikują istnienie plateau optymalności dla wąskiego zakresu wartości $k$ (2-3). Zwiększanie szerokości wiązki powyżej wartości optymalnej nie skutkowało poprawą jakości predykcji, powodując jednocześnie wzrost kosztu obliczeniowego inferencji.

\input{rezultaty/uwaga/analiza_beam/porownanie_trendow_cnn}
\input{rezultaty/uwaga/analiza_beam/porownanie_trendow_uwaga}
Szczegółowa analiza ujawniła interakcje parametru $k$ z architekturą modelu. Jak zilustrowano na Rysunku~\ref{fig:porownanie_trendow_uwaga}, wpływ szerokości wiązki jest zróżnicowany w zależności od zastosowanego mechanizmu uwagi.

Mechanizm uwagi własnej wykazał najwyższą efektywność, utrzymując stabilną wydajność dla $k \in \{2, 3, 5\}$. Najwyższą wartość metryki CIDEr w całym badaniu (117,59) uzyskano dla tej konfiguracji przy $k=3$ i sieci szkieletowej Regnet. Mechanizmy uwagi adaptacyjnej i przestrzennej cechowały się porównywalną wydajnością, osiągając maksimum dla $k=3$. Mechanizm uwagi miękkiej konsekwentnie uzyskiwał najniższe wartości metryk. Wyniki wskazują na synergię pomiędzy strategią dekodowania a architekturą uwagi. Modele z uwagą własną najefektywniej wykorzystywały przeszukiwanie wiązkowe do eksploracji przestrzeni hipotez.

Podobne zależności zidentyfikowano w analizie wpływu architektury sieci szkieletowej na Rysunku~\ref{fig:porownanie_trendow_cnn}. Architektura Regnet wykazała istotną przewagę, osiągając najwyższe średnie wartości CIDEr. Szczytową wydajność dla tej sieci odnotowano już przy $k=2$. Modele z rodziny Densenet oraz Resnet101 charakteryzowały się niższym poziomem efektywności, z optimum w przedziale $k \in \{2, 3\}$. Najniższą skuteczność predykcyjną odnotowano dla InceptionV3, co sugeruje najmniejszą adekwatność cech wizualnych ekstrahowanych przez tę architekturę dla badanego zadania.

Wyniki badań empirycznych wskazują, że zwiększenie szerokości wiązki z $k=1$ do $k \in \{2, 3\}$ skutkuje systematycznym wzrostem jakości generowanych podpisów. Dalsze poszerzanie wiązki jest nieefektywne. Najwyższą wartość metryki CIDEr (117,60) osiągnięto dla modelu opartego na mechanizmie uwagi własnej z siecią szkieletową Regnet, przy $k=3$. Wynik ten podkreśla znaczenie synergii pomiędzy komponentami architektury i parametrami inferencji dla maksymalizacji wydajności.

Podsumowując, wyniki badań wskazują, że szerokość wiązki $k=3$ stanowi optymalny kompromis pomiędzy jakością generowanych podpisów a złożonością obliczeniową procesu inferencji.


\chapter{Podsumowanie}

Automatyczne generowanie podpisów do obrazów stanowi interdyscyplinarne wyzwanie badawcze na styku widzenia komputerowego i przetwarzania języka naturalnego, którego celem jest synteza trafnego i lingwistycznie poprawnego opisu sceny wizualnej. Dynamiczny rozwój metod uczenia głębokiego doprowadził do znaczącego postępu w tej dziedzinie. Jednocześnie wzrost skuteczności modeli wiąże się z rosnącą złożonością obliczeniową, co stanowi barierę dla ich praktycznego wdrożenia.

Niniejsza rozprawa doktorska adresuje ten problem, koncentrując się na optymalizacji ugruntowanych architektur neuronowych. Celem rozprawy było opracowanie i weryfikacja metod doskonalenia systemów automatycznego generowania podpisów do obrazów, ukierunkowanych na maksymalizację jakości generowanych podpisów przy jednoczesnej optymalizacji wydajności obliczeniowej. Postawiono hipotezę badawczą zakładającą, że istotną poprawę skuteczności można osiągnąć poprzez systematyczną optymalizację komponentów składowych w ramach klasycznych architektur typu koder-dekoder oraz rozszerzonych o mechanizm uwagi, bez konieczności wprowadzania fundamentalnie nowych topologii sieci.

\section{Realizacja celów i wkład pracy}
W ramach rozprawy zrealizowano postawione cele badawcze, dokonując systematycznej analizy teoretycznej oraz wieloetapowych badań empirycznych. Część teoretyczna obejmowała przegląd ewolucji metod, analizę komponentów składowych systemów, takich jak sieci szkieletowe, dekodery rekurencyjne oraz modeli osadzeń słów. Omówiono także zbiory danych i metryki ewaluacyjne. Część eksperymentalna została zrealizowana w dwóch głównych obszarach badawczych. Wszystkie eksperymenty przeprowadzono na standardowym zbiorze danych Microsoft COCO, a ewaluację oparto na zestawie metryk automatycznych, takich jak BLEU, CIDEr, SPICE.

Praca wnosi wkład w rozwój dziedziny poprzez systematyczną analizę i optymalizację istniejących architektur, dostarczając praktycznych wskazówek dotyczących doboru komponentów i strategii treningowych. Wkład ten obejmuje w szczególności:

\begin{enumerate}
    \item \textbf{Systematyczną optymalizację architektury koder-dekoder.} Przeprowadzono badania porównawcze dwóch metod integracji cech multimodalnych, poprzez fuzję oraz wstrzykiwanie wstępne. Dokonano empirycznej ewaluacji wpływu komponentów składowych modelu, kodera wizualnego, modelu osadzeń słów (GloVe, FastText), strategii fuzji (konkatenacja, dodawanie) oraz typu dekodera rekurencyjnego (LSTM, GRU). Zidentyfikowano optymalne konfiguracje dla obu architektur oraz wykazano wyższość architektury fuzji pod względem jakości generowanych podpisów.
    \item \textbf{Analizę wpływu kodera wizualnego.} Porównano wydajność spektrum wstępnie wytrenowanych sieci szkieletowych (m.in. VGG, ResNet, DenseNet, Xception). Wykazano, że wybór ekstraktora cech wizualnych w koderze ma decydujący wpływ na zdolności modelu do budowy zdań  bogatych w cechy wizualne.
    \item \textbf{Udoskonalenie modeli z mechanizmem uwagi.} Zbadano synergię pomiędzy różnymi architekturami sieci szkieletowych a wariantami mechanizmu uwagi (miękkiej, przestrzennej, adaptacyjnej oraz własnej), weryfikując wpływ konfiguracji na skuteczność tych modeli.
    \item \textbf{Optymalizację procesu inferencji.} Przeanalizowano wpływ strategii dekodowania opartych na przeszukiwaniu wiązkowym, określając optymalne wartości szerokości wiązki dla badanych architektur, stanowiące kompromis między jakością predykcji a kosztem obliczeniowym.
\end{enumerate}

Wyniki badań przeprowadzonych w ramach rozprawy zostały opisane i opublikowane w pięciu artykułach naukowych~\cite{Iwanowski2021Fuzzy,Bartosiewicz2021Generating,Bartosiewicz2024Improving,Bartosiewicz2023Combining,Bartosiewicz2024Optimal}, a szósty został zgłoszony. Artykuły~\cite{Bartosiewicz2023Combining,Bartosiewicz2024Optimal} rozwijają badania przedstawione w Rozdziale~\ref{rozdzial:badania_podstawowej_architektury_koder_dekoder}, a badania opisane w Rozdziale~\ref{rozdzial:badania_mechanizmu_uwagi} stanowią podstawę zgłoszonego artykułu.

\section{Weryfikacja hipotez i kluczowe wnioski}
Przeprowadzone badania pozwoliły na pozytywną weryfikację głównej hipotezy badawczej oraz sformułowanych hipotez szczegółowych. Kluczowe wnioski empiryczne są następujące:
\begin{enumerate}
    \item \textbf{Znaczenie architektury kodera wizualnego.} Potwierdzono, że nowoczesne sieci szkieletowe (np. Xception, DenseNet) dostarczają reprezentacji wizualnej wyższej jakości niż starsze modele, jak VGG. Przekłada się to bezpośrednio na wyższą trafność i szczegółowość podpisów, co mierzono metrykami CIDEr i SPICE. Wykazano, że efektywność ekstrakcji cech zależy od topologii sieci, a nie jedynie od liczby parametrów modelu.
    \item \textbf{Efektywność strategii fuzji i struktury dekodera.} Badania nad architekturą fuzji wykazały jednoznaczną przewagę konkatenacji nad dodawaniem wektorów cech jako metody integracji modalności. W zakresie dekoderów rekurencyjnych wykazano, że sieć GRU, mimo mniejszej złożoności, osiąga wyniki porównywalne z LSTM, oferując jednocześnie wyższą efektywność obliczeniową w kontekście generowania relatywnie krótkich sekwencji tekstowych.
    \item \textbf{Synergia komponentów systemu.} Potwierdzono istnienie efektu synergii pomiędzy komponentami architektury. Optymalna wydajność systemu nie jest sumą wydajności jego najlepszych, odizolowanych elementów. Identyfikacja specyficznych, najlepszych kombinacji (np. sieci szkieletowej i modelu osadzeń słów) okazała się kluczowa dla maksymalizacji jakości generowanych podpisów.
\end{enumerate}

Wyniki badań potwierdzają, że empiryczny dobór i precyzyjne dostrojenie istniejących komponentów w ramach ugruntowanych architektur stanowi efektywną strategię doskonalenia systemów generowania podpisów do obrazów, co stanowi pozytywną weryfikację głównej hipotezy badawczej.

\section{Wnioski końcowe i kierunki dalszych badań}
Niniejsza rozprawa wnosi wkład w rozwój metod automatycznego generowania podpisów do obrazów, demonstrując potencjał optymalizacji istniejących architektur neuronowych oraz dostarczając empirycznych wskazówek dotyczących ich konfiguracji. Praca ma również znaczenie praktyczne, wpływając na rozwój technologii asystujących dla osób z niepełnosprawnością wzroku, semantycznego wyszukiwania w archiwach wizualnych czy projektowania intuicyjnych interfejsów człowiek-komputer. Ponadto analiza architektur multimodalnych, łączących dane wizualne i językowe, dostarcza wskazówek dla innych obszarów sztucznej inteligencji, takich jak analiza wideo, diagnostyka medyczna oparta na obrazach czy robotyka.

Pomimo osiągniętych postępów, analiza jakościowa ujawniła istotne ograniczenia badanych modeli. Zalicza się do nich podatność na tendencyjność wynikającą z dystrybucji danych treningowych, prowadzącą do generowania podpisów nieadekwatnych semantycznie. Istotnym wyzwaniem pozostaje również ograniczona zdolność do generalizacji na danych spoza dystrybucji oraz poprawna interpretacja scen zawierających rzadkie obiekty lub nietypowe konteksty.

Zidentyfikowane ograniczenia wyznaczają kierunki dalszych badań. Przyszłe prace powinny koncentrować się na:
\begin{itemize}
    \item Opracowaniu metod mitygacji tendencyjności językowej i redukcji halucynacji, na przykład poprzez integrację zewnętrznych baz wiedzy.
    \item Zwiększeniu zdolności generalizacyjnych modeli poprzez wykorzystanie wielkoskalowych zbiorów danych oraz technik uczenia transferowego.
    \item Adaptacji opracowanych metod do języków o złożonej morfologii, takich jak język polski, co wymaga rozwiązania problemów związanych z poprawnością fleksyjną i składniową oraz opracowania adekwatnych metod ewaluacji.
\end{itemize}

Na podstawie przeprowadzonych badań można przewidywać, że przyszły rozwój w dziedzinie automatycznego generowania podpisów do obrazów będzie zmierzał w kierunku przezwyciężenia zidentyfikowanych ograniczeń. Zamiast tworzyć generyczne podpisy, modele nowej generacji będą musiały wykazać się głębszym, niemal przyczynowo-skutkowym rozumieniem sceny. Będzie to wymagało nie tylko identyfikacji obiektów, ale również modelowania ich wzajemnych interakcji, prawdopodobnych intencji oraz potencjalnych konsekwencji. Można spodziewać się rozwoju modeli, które potrafią integrować wiedzę zewnętrzną, wykraczającą poza informacje zawarte w zbiorze treningowym, aby tworzyć podpisy bogatsze kontekstowo i semantycznie. Myśl Ludwiga Wittgensteina, że "zdanie stanowi logiczny model faktu", która była inspiracją dla tej pracy, pozostaje aktualna. Eksperymenty te pokazują, jak zaawansowane "językowe odpowiedniki sceny wizualnej" potrafimy tworzyć, ale jednocześnie unaoczniają, jakie wyzwania stoją przed nami na drodze do maszynowej interpretacji, która nie byłaby jedynie nadinterpretacją. Niniejsza rozprawa, zamykając klamrą techniczną analizę zrodzoną z humanistycznej refleksji, stanowi kolejny krok na tej ścieżce.