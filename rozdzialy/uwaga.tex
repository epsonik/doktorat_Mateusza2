\chapter{Badania mechanizmu uwagi}
\label{rozdzial:badania_mechanizmu_uwagi}
Rozdział prezentuje wyniki badań nad optymalizacją modeli do automatycznego generowania podpisów do obrazów ze zintegrowanym mechanizmem uwagi. Celem badań była empiryczna weryfikacja synergii pomiędzy architekturą kodera wizualnego a implementacją mechanizmu uwagi oraz identyfikacja konfiguracji optymalnych pod względem efektywności predykcyjnej i obliczeniowej.

Przyjęta metodologia koncentruje się na doskonaleniu reprezentacji danych wejściowych poprzez dobór sieci szkieletowej i strategii treningowej oraz optymalizacji procesu inferencji poprzez dostrojenie algorytmu przeszukiwania wiązkowego. Analizie poddano mechanizm uwagi miękkiej, przestrzennej, adaptacyjnej oraz własnej, szerzej opisanych w Rozdziale~\ref{rozdzial:mechanizm_uwagi}.

\section{Architektura badań}
Badane architektury, oparte na paradygmacie koder-dekoder, wykorzystują mechanizm uwagi. W każdym kroku czasowym $t$ odpowiada on za dynamiczne dostarczanie dekoderowi najbardziej relewantnych informacji wizualnych. Analizie poddano uwagę miękką~\cite{Xu2015ShowAttendTell} (Rysunek~\ref{fig:uwaga_miekka}), uwagę przestrzenną~\cite{Lu2017KnowingWT} (Rysunek~\ref{fig:uwaga_przestrzenna}), uwagę adaptacyjną~\cite{Lu2017KnowingWT} (Rysunek~\ref{fig:uwaga_adaptacyjna}) oraz uwagę własną~\cite{Huang2019attention} (Rysunek~\ref{fig:uwaga_wlasna}).

\input{wykresy/architektury/rodzaje_badanej_uwagi/rodzaje_uwagi}
Model składa się z kodera, odpowiedzialnego za ekstrakcję cech wizualnych. Funkcję tę pełni sieć szkieletowa w \textit{komponencie ekstrakcji cech obrazu}, która przetwarza obraz wejściowy $I$, generując na wyjściu mapę cech siatkowych $\mathbf{V=\{\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_k\}}$. Każdy wektor $\mathbf{v}_i$ reprezentuje $i$-ty region przestrzenny. Mapa ta jest następnie przetwarzana przez \textit{komponent adaptacyjny} w celu dopasowania wymiarowości do wymagań dekodera. Mapa ta stanowi wejście dla mechanizmu uwagi.

Dekoder odpowiada za generowanie sekwencji wyjściowej słowo po słowie i został zaimplementowany za pomocą sieci LSTM. W jego skład wchodzi \textit{komponent osadzania słów, fuzji, RNN, uwagi i predykcji słów}. \textit{Komponent osadzania słów} transformuje słowo z poprzedniego kroku $y_{t-1}$ na jego osadzenie $\mathbf{e}(y_{t-1})$. 
\textit{Komponent fuzji} przygotowuje wektor wejścia $\mathbf{x_t}$ dla sieci LSTM poprzez agregację cech obrazu $\mathbf{V}$ oraz osadzenia $\mathbf{e}(y_{t-1})$. W kroku czasowym $t$ komórka LSTM w \textit{komponencie RNN} aktualizuje swój stan ukryty $\mathbf{h_t}$ oraz stan komórki $\mathbf{c_t}$ na podstawie wejścia $\mathbf{x_t}$ i stanu poprzedniego $\mathbf{h_{t-1}}$, 
zgodnie z formalizmem opisanym w Sekcji~\ref{rozdzial:siec_LSTM}.

Centralnym komponentem architektury jest \textit{komponent uwagi}, obliczający wektor kontekstu wizualnego $\mathbf{z_t}$. Ostatnim elementem ścieżki dekodera jest \textit{komponent predykcji słów}, czyli warstwa w pełni połączona z funkcją aktywacji softmax, obliczająca rozkład prawdopodobieństwa $p(y_t)$ nad słownikiem.

Zasadniczym elementem różnicującym badane modele jest sposób obliczania oraz integracji wektora kontekstu wizualnego $\mathbf{z_t}$. W przypadku uwagi miękkiej wektor kontekstu jest włączany bezpośrednio w pętlę rekurencyjną. Jest obliczany na podstawie poprzedniego stanu ukrytego dekodera $\mathbf{h_{t-1}}$ oraz mapy cech $\mathbf{V}$ zgodnie z równaniem~\ref{eq:uwaga_miekka_wektor_kontekstu}. Następnie jest on konkatenowany w \textit{komponencie fuzji} z osadzeniem poprzednio wygenerowanego słowa $\mathbf{e(y_{t-1})}$ tworząc wejściowy wektor $\mathbf{x_t}$ do komórki LSTM w \textit{komponencie RNN}. Nowy stan ukryty $\mathbf{h_t}$ wzbogacony o kontekst wizualny $\mathbf{z_t}$ jest wykorzystywany przez \textit{komponent predykcji słów} do wygenerowania słowa $y_t$.

W odróżnieniu od powyższego, wariant uwagi przestrzennej warunkuje wektor kontekstu wizualnego nie na poprzednim stanie ukrytym $\mathbf{h_{t-1}}$, lecz na aktualnym stanie ukrytym $\mathbf{h_t}$. W tym celu sieć LSTM najpierw oblicza nowy stan ukryty $\mathbf{h_t}$ na podstawie poprzedniego stanu ukrytego $\mathbf{h_{t-1}}$ oraz wektora wejściowego $\mathbf{x_t}$.
\begin{equation}
    h_t=LSTM(x_t,h_{t-1}),
\end{equation}
gdzie $\mathbf{x_t}$ jest obliczane zgodnie z \ref{eq:uwaga_przestrzenna_xt}. Dopiero nowy stan ukryty$\mathbf{h_t}$ jest wykorzystywany w \textit{komponencie uwagi} do obliczenia wektora kontekstu $\mathbf{z_t}$ zgodnie z równaniem~\ref{eq:uwaga_przestrzenna_wektor_kontekstu}. Finalna predykcja odbywa się na połączonej reprezentacji $[\mathbf{h_t;z_t}]$ w \textit{komponencie predykcji słów} (por. równanie~\ref{eq:uwaga_przestrzenna_wektor_kontekstu}).

Uwaga adaptacyjna rozszerza mechanizm uwagi przestrzennej, aby sterować przepływem informacji wizualnej. W tym celu wprowadza bramkę uwagi $\boldsymbol{\beta}_t$ oraz wektor strażnika wizualnego $\mathbf{s_t}$. 

Bramka $\boldsymbol{\beta}_t$ decyduje, czy w danym kroku czasowym model powinien skupić się na informacjach z obrazu, czy na wiedzy już zgromadzonej. Decyzja ta podejmowana jest na podstawie poprzedniego stanu ukrytego $\mathbf{h_{t-1}}$, stanu komórki LSTM $\mathbf{c_t}$ oraz wektora $\mathbf{x_t}$ (por. równanie~\ref{eq:uwaga_adaptacyjna_bramka_uwagi}). Równolegle, oprócz wektora kontekstu przestrzennego $\mathbf{\hat{z_t}}$ (zależnego od $\mathbf{h_t}$, obliczonego według~\ref{eq:uwaga_przestrzenna_wektor_kontekstu}), obliczany jest wektor strażnika $\mathbf{s_t}$ zgodnie z równaniem~\ref{eq:uwaga_adaptacyjna_straznik_wizualny}. 

Finalny, adaptacyjny wektor kontekstu $\mathbf{z_t}$ jest kombinacją wektora przestrzennego $\mathbf{\hat{z_t}}$ i wektora strażnika $\mathbf{s_t}$, ważoną przez bramkę $\boldsymbol{\beta}_t$ zgodnie ze wzorem~\ref{eq:uwaga_adaptacyjna_wektor_kontekstu}. Tak uzyskany wektor $\mathbf{z_t}$ jest łączony z wektorem stanu ukrytego $\mathbf{h_t}$ i staje się wejściem do \textit{komponentu predykcji słów}.


Czwarty badany wariant, uwaga własna modyfikuje sposób obliczania kontekstu wizualnego. W każdym kroku czasowym standardowy wielogłowicowy mechanizm uwagi własnej oblicza wektor kontekstu $\hat{\mathbf{z_t}}$ na podstawie wektora stanu ukrytego dekodera $\mathbf{h_{t}}$. Następnie, w celu rafinacji uzyskanego wektora kontekstu $\hat{\mathbf{z_t}}$, równolegle obliczany jest wektor informacji $\mathbf{i}$ oraz wektor bramki $\mathbf{g}$ zgodnie z wzorem~\ref{eq:uwaga_wlasna_tensor_informacji} i \ref{eq:uwaga_wlasna_tensor_bramki_uwagi}. Wektor informacji $\mathbf{i}$ identyfikuje istotne cechy w wektorze kontekstu $\hat{\mathbf{z_t}}$, czyli połączonej reprezentacji obrazu i tekstu, z kolei wektor bramki $\mathbf{g}$ moduluje przepływ informacji poprzez ocenę ogólnej trafności wektora kontekstu $\hat{\mathbf{z_t}}$ względem aktualnego stanu ukrytego dekodera $\mathbf{h_{t}}$. Ostateczny wektor kontekstu $\mathbf{z_t}$ powstaje w wyniku mnożenia element po elemencie wektora informacji $\mathbf{i}$ oraz wektora bramki $\mathbf{g}$ zgodnie z równaniem~\ref{eq:uwaga_własna_wektor_kontekstu}, aby stać się wejściem do \textit{komponentu predykcji słów}.

Po zakończeniu treningu inferencja realizowane jest w \textit{komponencie przeszukiwania} z wykorzystaniem algorytmu przeszukiwania wiązkowego. W ramach eksperymentów analizowano wpływ szerokości wiązki $k\in\{1, 2, 3, 5, 8\}$ na jakość generowanych podpisów.

W celu weryfikacji wydajności przetestowano zróżnicowane implementacje komponentów. Jako \textit{komponent ekstrakcji cech obrazu} wykorzystano sieci Densenet (121, 161, 201), Resnet (101, 152), InceptionV3 oraz Regnet. Jako \textit{komponent osadzania słów} w dekoderze testowano wstępnie trenowane osadzenia GloVe oraz osadzenia trenowane od podstaw, inicjalizowane losowo.

\section{Scenariusz badawczy}
\label{sekcja:badania_uwagi_scenariusz_badawczy}
Przedstawiony scenariusz badawczy został zaprojektowany w celu weryfikacji hipotezy o istnieniu synergii pomiędzy sposobem ekstrakcji cech obrazu a dekoderem językowym. Jego realizacja ma na celu identyfikację optymalnych kombinacji między siecią szkieletową a mechanizmem uwagi.Badania podzielono na cztery etapy.

Pierwszy etap badań poświęcono identyfikacji i walidacji optymalnej strategii treningowej, która ukierunkowała dalsze badania. W tym celu wykonano analizę porównawczą czterech odrębnych scenariuszy treningowych, aby hierarchicznie określić wpływ sieci szkieletowej w \textit{komponencie ekstrakcji cech obrazu} oraz osadzeń słów  w \textit{komponencie osadzania słów}. Analizie poddano strategie inicjalizacji i treningu wag. W przypadku warstwy osadzeń rozważano zamrożone lub dostrajane w trakcie uczenia wektory GloVe oraz wagi osadzeń inicjowane losowo, trenowane od podstaw. Każde z tych rozwiązań testowano w połączeniu z zamrożonymi lub w pełni trenowanymi wagami sieci szkieletowej dla jednego wariantu mechanizmu uwagi.

Na podstawie wyników uzyskanych w pierwszym etapie badawczym, w drugim etapie przeprowadzono systematyczną analizę porównawczą interakcji pomiędzy różnymi sieciami szkieletowymi a mechanizmami uwagi. Weryfikacji poddano siedem architektur sieci szkieletowych: Regnet, InceptionV3, trzy warianty Densenet (201, 161, 121) oraz dwa warianty Resnet (101, 152). Ich współdziałanie oceniano z uwagą miękką, przestrzenną, adaptacyjną oraz własną.

W badaniach zastosowano dwie odmienne strategie uczenia, dobrane adekwatnie do charakteru analizowanych mechanizmów uwagi. Dla modeli z uwagą adaptacyjną, przestrzenną i miękką wdrożono zweryfikowaną procedurę dwuetapową, wykorzystującą wstępnie trenowane osadzenia słów GloVe. W pierwszym etapie (do 30 epok) optymalizowano wyłącznie parametry warstw uwagi, przy zamrożonych wagach sieci szkieletowej i osadzeń. W etapie drugim (do 50 epok) cały model był dostrajany w trybie end-to-end.

Odmienne, holistyczne podejście przyjęto dla uwagi własnej, zgodnie z pracą referencyjną~\cite{Huang2019attention}. Model trenowano od podstaw zgodnie ze strategią end-to-end, z początkowo losowymi wagami osadzeń słów. Wybór tej strategii był motywowany dążeniem do wytworzenia spójnej, multimodalnej przestrzeni reprezentacji, w której cechy wizualne i językowe są wzajemnie skalibrowane. Uczenie osadzeń od podstaw pozwala na ich precyzyjne dopasowanie do ograniczonego słownictwa w zbiorze danych, eliminując potencjalny szum informacyjny z generycznych wektorów GloVe. Jednocześnie dostrajanie sieci szkieletowej od początku treningu pozwala na ekstrakcję cech wizualnych, które są bezpośrednio relewantne dla generowania złożonych podpisów, a nie tylko dla rozpoznawania obiektów.

Ocenę skuteczności poszczególnych kombinacji architektur przeprowadzono, analizując kompromis między wydajnością predykcji a złożonością obliczeniową. Wydajność mierzono za pomocą metryki CIDEr oraz wartością funkcji straty, natomiast złożoność wyrażono liczbą parametrów modelu. Uzupełniająco raportowano również metryki BLEU (1-4) oraz ROUGE-L. Uzyskane wyniki odniesiono do modeli referencyjnych, zdefiniowanych na podstawie literatury wprowadzającej dany mechanizm uwagi: Resnet-152 dla uwagi adaptacyjnej i przestrzennej oraz Resnet-101 dla uwagi miękkiej i własnej.

Trzeci etap badań koncentrował się na analizie dynamiki procesu treningowego, w szczególności na wpływie wyboru sieci szkieletowej i mechanizmu uwagi na szybkość konwergencji modelu. Jako miarę szybkości przyjęto liczbę epok niezbędną do osiągnięcia optymalnej wartości metryki CIDEr na zbiorze walidacyjnym. Dokonano oceny uśrednionej, porównując średnią liczbę epok wymaganą do konwergencji dla każdego z czterech mechanizmów uwagi. Następnie przeprowadzono analizę szczegółową, badając interakcje dla każdej pary mechanizm uwagi–sieć szkieletowa.

Czwarty etap badawczy poświęcono optymalizacji inferencji poprzez analizę metody przeszukiwania wiązkowego. Analizowano wpływ szerokości wiązki $k$ na jakość generowanych podpisów. Badanie przeprowadzono dla dyskretnego zbioru wartości $k \in \{1,2,3,5,8\}$, testując każdą wartość dla wszystkich wcześniej zweryfikowanych kombinacji. Celem było zidentyfikowanie optymalnej wartości parametru $k$, stanowiącej najkorzystniejszy kompromis między jakością predykcji, mierzoną metryką CIDEr, a złożonością obliczeniową inferencji.

\section{Przebieg treningu}
Procedurę treningową rozpoczęto od przygotowania danych wejściowych. Każdy obraz ze zbioru treningowego poddano sekwencji transformacji w celu ujednolicenia formatu wejściowego zgodnie z wymaganiami testowanej sieci szkieletowej. Obejmowało to skalowanie obrazów do wymaganej rozdzielczości (np. $256\times256\times3$ dla Densenet i Resnet101; $342\times342\times3$ dla InceptionV3; $232\times232\times3$ dla Resnet152; $384\times384\times3$ dla Regnet). Następnie wartości pikseli znormalizowano do zakresu $[0,1]$. Równolegle przetworzono referencyjne podpisy tekstowe, zgodnie z procedurą opisaną w Sekcji~\ref{rozdzial:wstepne_przetwarzanie}. Zbudowano globalny słownik, a każdą sekwencję uzupełniono o tokeny specjalne $<$START$>$ i $<$STOP$>$.

Następnie, w ramach pojedynczej iteracji treningowej, wstępnie przetworzona partia 10 obrazów była przekazywana do \textit{komponentu ekstrakcji cech obrazu}, gdzie wybrana sieć szkieletowa przetwarzała obraz na wielowymiarową mapę cech $\mathbf{V}$. Długości wektorów cech składających się na mapę cech $\mathbf{V}$ były zależne od architektury sieci szkieletowej (np. 2048 dla Resnet101/152 i InceptionV3; 3712 dla Regnet; 1024, 2208, 1920 odpowiednio dla Densenet121, Densenet161, Densenet201).

Uczenie modelu oparto na metodzie uczenia z nauczycielem. W każdym kroku czasowym $t$ do dekodera podawano słowo referencyjne $y_{t-1}$ ze zbioru treningowego, zamiast słowa wygenerowanego przez model w kroku poprzednim. Metoda ta stabilizuje uczenie i przyspiesza konwergencję. W kroku $t$, w zależności od badanego wariantu mechanizmu uwagi, dekoder obliczał wektor kontekstu wizualnego $\mathbf{z_t}$, aktualizował stan ukryty $\mathbf{h_t}$ i generował rozkład prawdopodobieństwa kolejnego słowa $p(y_t)$.

Parametry modelu optymalizowano poprzez minimalizację funkcji straty w postaci entropii krzyżowej. Gradienty obliczano metodą propagacji wstecznej. Do aktualizacji wag modelu posłużył optymalizator Adam z parametrami $\beta_1 = 0,9$, $\beta_2 = 0,999$ oraz $\epsilon = 1 \times 10^{-8}$. Bazowy współczynnik uczenia dla dekodera ustalono na $4 \times 10^{-4}$ oraz $1 \times 10^{-4}$ dla douczanego dekodera.

Po zakończeniu każdej epoki przeprowadzano ewaluację na zbiorze walidacyjnym. Obliczano wartość funkcji straty, dokładność TOP-5 oraz metrykę BLEU-4. Model, który osiągnął najwyższą wartość metryki BLEU-4 na zbiorze walidacyjnym, był zapisywany jako punkt kontrolny do dalszej ewaluacji. 

Zaimplementowano również mechanizmy kontroli przebiegu uczenia. Zastosowano adaptacyjną zmianę współczynnika uczenia, redukując jego wartość o 20\% (mnożnik 0,8) jeżeli metryka BLEU-4 na zbiorze walidacyjnym nie uległa poprawie przez osiem kolejnych epok. Trening zaplanowano na 50 epok, przy czym mógł on zostać zakończony wcześniej przez mechanizm wczesnego zatrzymania. Powodował on przerwanie treningu, jeżeli wartość funkcji straty na zbiorze walidacyjnym nie zmniejszyła się przez pięć następujących po sobie epok.

\section{Przebieg testowania}
Procedura weryfikacji wydajności wytrenowanych modeli obejmowała ocenę ilościową, opartą na standardowych metrykach dziedzinowych, oraz pogłębioną analizę jakościową, ukierunkowaną na interpretację zachowania modelu.

Podstawą oceny ilościowej jest predykcja podpisu dla każdego obrazu ze zbioru testowego. Inferencja rozpoczyna się od załadowania punktu kontrolnego modelu, wyselekcjonowanego podczas treningu, oraz słownika mapującego indeksy słów na ich leksykalne odpowiedniki. Obraz wejściowy poddawany jest serii transformacji, które są tożsame z fazą treningową, co opisano w Sekcji~\ref{rozdzial:wstepne_przetwarzanie}. Obraz jest następnie przetwarzany przez sieć szkieleltową na mapę cech obrazu $\mathbf{V}$.

Generowanie podpisu ma charakter iteracyjny. W odróżnieniu od fazy treningowej, opartej na uczeniu z nauczycielem, w każdym kroku czasowym $t$ wejściem do dekodera jest słowo wygenerowane przez model w kroku poprzednim $y_{t-1}$. Proces inicjowany jest przez podanie wektora osadzenia dla tokenu $<$START$>$. W każdym kolejnym kroku \textit{komponent predykcji słów} generuje rozkład prawdopodobieństwa nad słownikiem, który jest wejściem dla \textit{komponentu przeszukiwania}. Komponent ten buduje zdanie stosując algorytm przeszukiwania wiązkowego z szerokością wiązki $k$. Iteracje są kontynuowane aż do wygenerowania tokenu $<$STOP$>$ lub osiągnięcia maksymalnej długości. Finalny podpis jest porównywany z zestawem pięciu podpisów referencyjnych przy użyciu metryk BLEU-1 do BLEU-4, CIDEr oraz ROUGE-L.

Uzupełnieniem dla metryk ilościowych jest ewaluacja jakościowa, która polega na wizualizacji wag pochodzących z mechanizmu uwagi. Dla reprezentatywnych przykładów ze zbioru testowego generowano mapy cieplne i nakładano je na obrazy wejściowe. Intensywność barwy w danym regionie odpowiada wartości wagi uwagi $\boldsymbol{\alpha}_t$, jaką model przypisał temu regionowi podczas generowania słowa $y_t$. W przypadku modelu z uwagą adaptacyjną, wizualizacji podlega również wartość bramki strażnika $\boldsymbol{\beta}_t$, określająca stopień wykorzystania informacji wizualnej względem lingwistycznej. Analiza tych wizualizacji umożliwia wgląd w proces decyzyjny modelu i identyfikację regionów obrazu, które miały największy wpływ na predykcję poszczególnych słów.

Analiza jakościowa opiera się na studium wybranych przypadków. Po pierwsze, badane są przypadki pozytywne, dla których model wygenerował adekwatne podpisy. Wizualizacje uwagi służą w tej sytuacji do weryfikacji, czy model prawidłowo lokalizuje kluczowe obiekty i ich atrybuty. Po drugie, przeprowadzana jest analiza błędów, obejmująca identyfikację i kategoryzację nieprawidłowości (np. halucynacje obiektów, błędne relacje przestrzenne). W tych przypadkach wizualizacja uwagi pełni rolę narzędzia diagnostycznego. Zastosowane połączenie ewaluacji ilościowej i jakościowej stanowi kompletny schemat badawczy, umożliwiający holistyczną ocenę wydajności predykcyjnej oraz wiarygodności modelu.

\section{Rezultaty}
\subsection{Analiza strategii treningowych}
\label{sekcja:analiza_strategii_treningowych}
W pierwszym etapie badań zgodnie ze scenariuszem~\ref{sekcja:badania_uwagi_scenariusz_badawczy} przeprowadzono analizę porównawczą wpływu czterech strategii treningowych. Celem była identyfikacja optymalnej metody uczenia, którą następnie zastosowano w dalszych badaniach. Ewaluację oparto na modelu wykorzystującym mechanizm uwagi miękkiej oraz sieć szkieletową Densenet201. Analizowano wpływ strategii inicjalizacji i dostrajania wag \textit{komponentu ekstrakcji cech obrazu} oraz \textit{komponentu osadzania słów}. 

% Wyniki zobrazowano na Rysunkach~\ref{fig:wplyw_strategii_treningu_osadzen_strata} i \ref{fig:wplyw_strategii_treningu_osadzen_cider}. Celem analizy było hierarchiczne określenie wpływu poszczególnych komponentów modelu – sieci szkieletowej oraz warstwy osadzeń słownych – na finalną jakość predykcji.

\input{rezultaty/uwaga/embeddingi_zmiana_strata_cider/wplyw_strategii_treningu_osadzen_strata}
\input{rezultaty/uwaga/embeddingi_zmiana_strata_cider/wplyw_strategii_treningu_osadzen_cider} 
Przebieg procesu uczenia monitorowano na zbiorze walidacyjnym, co zilustrowano na Rysunku~\ref{fig:wplyw_strategii_treningu_osadzen_strata} i \ref{fig:wplyw_strategii_treningu_osadzen_cider}.
We wszystkich wariantach zaobserwowano systematyczny spadek wartości funkcji straty (Rysunek~\ref{fig:wplyw_strategii_treningu_osadzen_strata}) potwierdzający skuteczną optymalizację parametrów modelu. Najszybsza konwergencja następowała przez pierwsze cztery do sześciu epok, po których krzywe uczenia osiągały fazę \gls{gls:plateu}. Najniższą wartość straty, wskazującą na najlepsze dopasowanie do danych treningowych, uzyskano dla strategii end-to-end. W tej strategii zarówno wagi sieci szkieletowej, jak i losowo inicjalizowane osadzenia podlegały treningowi (krzywa szara). Umożliwienie dostrajania wag sieci szkieletowej okazało się czynnikiem decydującym. Model z trenowanymi wagami (krzywa szara) osiągnął znacząco niższą wartość straty w porównaniu do jego odpowiednika z zamrożonymi wagami (krzywa żółta) przy tej samej strategii losowych osadzeń.

Zastosowanie wstępnie trenowanych osadzeń GloVe, które podlegały dalszemu treningowi (krzywa czarna), przyniosło drugą w kolejności najniższą wartość funkcji straty. Wynik ten, choć nieznacznie gorszy od najlepszego wariantu, jednoznacznie przewyższa konfiguracje z zamrożonymi wagami sieci szkieletowej. Zgodnie z przewidywaniami, najwyższą wartość funkcji straty, świadczącą o najsłabszej zdolności adaptacyjnej, odnotowano dla strategii, w której zarówno wagi sieci szkieletowej, jak i wstępnie trenowane osadzenia GloVe pozostały zamrożone (krzywa pomarańczowa). W tym scenariuszu proces uczenia ograniczał się wyłącznie do warstw mechanizmu uwagi, co znacząco limitowało potencjał modelu.

Analiza metryki CIDEr (Rysunek~\ref{fig:wplyw_strategii_treningu_osadzen_cider}) pozwoliła ocenić korelację między dopasowaniem do zbioru treningowego a jakością semantyczną podpisów. Wyniki potwierdziły obserwacje z analizy funkcji straty. Najwyższą skuteczność, wynoszącą CIDEr $\approx 85$, osiągnęła strategia pełnego dostrajania losowych osadzeń oraz wag sieci szkieletowej end-to-end (krzywa szara).

Czynnikiem determinującym wysoką wydajność okazało się dostrajanie wag sieci szkieletowej. Porównanie modelu z dostrajanymi wagami (CIDEr $\approx 85$, krzywa szara) z modelem o zamrożonych wagach (CIDEr $\approx 79$, krzywa żółta), przy tej samej losowej inicjalizacji osadzeń, wykazuje wzrost wydajności o około 6 punktów CIDEr. Wpływ wstępnie trenowanych osadzeń GloVe był drugorzędny. Przy zamrożonych wagach sieci szkieletowej, ich dostrajanie (krzywa niebieska) przyniosło jedynie niewielką poprawę o ok. 2 punkty CIDEr względem wariantu z zamrożonymi osadzeniami (krzywa pomarańczowa).

Ewaluacja na zbiorze testowym potwierdziła znaczenie dostrajania wag sieci szkieletowej. Dwa warianty modelu o najwyższym CIDEr większym niż 105 wykorzystywały dostrajanie wag sieci Densenet201. Zaobserwowano jednak istotną rozbieżność względem wyników ze zbioru walidacyjnego. Wbrew rezultatom uzyskanym na zbiorze walidacyjnym, faworyzującym podejście end-to-end, najwyższą zdolność do generalizacji na zbiorze testowym wykazała strategia dwuetapowa (CIDEr $\approx$ 109). Procedura ta obejmowała wstępny trening mechanizmu uwagi przy zamrożonych wagach kodera i osadzeń, a dopiero w drugim etapie symultaniczne dostrajanie wszystkich komponentów modelu. Sugeruje to, że procedura dwuetapowa sprzyja wypracowaniu bardziej generalnych reprezentacji cech i redukuje ryzyko przeuczenia.

Wyniki testowe potwierdziły, że wpływ warstwy osadzeń jest drugorzędny względem strategii dostrajania wag sieci szkieletowej. Dwuetapowa procedura treningowa umożliwiła modelowi z losowymi osadzeniami osiągnięcie wysokiego wyniku CIDEr równego 107. Niemniej najwyższą wydajność (CIDEr = 109) uzyskano w konfiguracji łączącej wstępnie trenowane osadzenia GloVe, również dostrajane oraz dwuetapową procedurę uczenia. Wskazuje to, że choć model jest w stanie efektywnie uczyć się reprezentacji słów od podstaw, wykorzystanie wiedzy zawartej w osadzeniach GloVe w połączeniu z optymalną strategią treningową pozwala na maksymalizację jakości generowanych podpisów.

Podsumowując, najwyższą jakość podpisów na zbiorze testowym zapewniła dwuetapowa procedura optymalizacyjna. Niezależnie od procedury, dostrajanie wag sieci szkieletowej okazało się decydującym warunkiem uzyskania wysokiej wydajności modelu. Strategia ta, tj. dwuetapowe uczenie z osadzeniami GloVe, została przyjęta jako procedura badawcza w drugim etapie badań. 

\subsection{Analiza porównawcza architektur uwagi}
W etapie drugim na podstawie wniosków dotyczących strategii treningowych (por. Sekcja~\ref{sekcja:analiza_strategii_treningowych}) przeprowadzono analizę porównawczą różnych wariantów mechanizmów uwagi oraz ich interakcji z architekturami sieci szkieletowych. Eksperymenty zrealizowano z wykorzystaniem najefektywniejszych, wyłonionych wcześniej strategii. Odpowiednio strategii end-to-end dla uwagi własnej oraz dwuetapowej z osadzeniami GloVe dla pozostałych mechanizmów uwagi.


\subsubsection{Analiza wydajności i złożoności obliczeniowej}
\label{sec:analiza_wydajnosci}
\input{rezultaty/uwaga/uwaga_rezultaty_douczanie}
\input{rezultaty/uwaga/zmiana_wartosci_uwagi}
W Tabeli~\ref{tab:uwaga_rezultaty_douczanie} zaprezentowano szczegółowe porównanie wyników uzyskanych dla różnych kombinacji architektur sieci szkieletowych i mechanizmu uwagi, przy szerokości wiązki $k=3$. Analiza ta bazuje na zagregowanych danych w Tabeli~\ref{tab:zmiana_wartosci_uwagi}. Jako modele referencyjne dla uwagi adaptacyjnej i przestrzennej przyjęto Resnet152, a dla uwagi miękkiej i własnej - Resnet101. 

Dla uwagi adaptacyjnej model referencyjny oparty na Resnet152 uzyskał CIDE 104,48 przy 68,29 miliona parametrów. Najwyższą skuteczność osiągnęła sieć Regnet (CIDEr 106,97), notując wzrost o 2,38\% względem modelu referencyjnego, lecz kosztem znacznego wzrostu złożoności (+34,32\% parametrów). Z perspektywy optymalizacji parametrów architektura InceptionV3 okazała się najefektywniejszym kompromisem, wykazując marginalny wzrost CIDEr o 0,51\% przy jednoczesnej redukcji liczby parametrów o 52,91\%. Z kolei zastosowanie architektur z rodziny Densenet oraz Resnet101 skutkowało obniżeniem wartości metryki CIDEr w zakresie od -1,42\% do -4,73\%. Największą redukcję parametrów (-75,86\%) zaobserwowano przy Densenet121, co wiązało się jednak ze spadkiem jakości generowanych podpisów (-4,04\% CIDEr).

W przypadku uwagi przestrzennej model referencyjny Resnet152 uzyskał wynik CIDEr 102,38 przy 68,29 miliona parametrów. Ponownie sieć Regnet uzyskała najwyższą skuteczność (CIDEr 105,89), przy analogicznym wzroście złożoności o +34,32\%. Co istotne, architektury Densenet201 i InceptionV3 pozwoliły na znaczącą redukcję złożoności, odpowiednio o -58,49\% i -52,91\% przy jednoczesnym zachowaniu lun marginalnym wzroście metryki CIDEr (odpowiednio +0,78\% i +0,08\%). Modele oparte na Resnet101, Densenet161 i Densenet121 ponownie wykazały spadek skuteczności w przedziale od -1,93\% do -2,55\%.

Analiza uwagi miękkiej (model referencyjny: Resnet101, CIDEr 104,83) przyniosła odmienne rezultaty. Wykazano synergię z siecią Densenet201, gdzie model osiągnął najwyższy wynik CIDEr (108,96, wzrost o 3,94\%), jednocześnie redukując liczbę parametrów o 41,58\%. Istotny wzrost skuteczności zaobserwowano również dla Resnet152 (+3,52\%), InceptionV3 (+3,14\%) oraz Densenet161 (+2,57\%). Należy jednak zaznaczyć, że Resnet152 cechuje się o 21,57\% większą liczbą parametrów niż model odniesienia. Dla uwagi miękkiej zaobserwowano anomalię wydajności. Sieć Regnet, dotychczas najskuteczniejsza uległa degradacji (spadek CIDEr o 11,53\%) przy jednoczesnym wzroście liczby parametrów (+43,48\%).

Dla uwagi własnej model referencyjny oparty na Resnet101 charakteryzował się wysokim wynikiem CIDEr (110,66) i bardzo dużą złożonością równą 129,87 miliona. Model z Regnet zdołał przewyższyć ten wynik, osiągając CIDEr 117,60 (wzrost o 6,27\%), leczy przy dalszym wzrostem liczby parametrów o 30,08\%. Wszystkie pozostałe badane architektury (Resnet152, rodzina Densenet, InceptionV3) spowodowały znaczące obniżenie skuteczności modelu. Spadki wartości CIDEr były bardzo wyraźne, od -1,57\% dla Resnet152 do aż -23,63\% dla InceptionV3. Mimo że modele te pozwalały na redukcję parametrów (np. -27,47\% dla Densenet121), towarzyszący jej drastyczny spadek jakości (-11,04\% CIDEr) dyskwalifikuje je jako efektywne alternatywy dla tej konfiguracji.

W toku badań nie zidentyfikowano uniwersalnie optymalnej sieci szkieletowej. Wyniki potwierdzają istnienie złożonych interakcji między koderem wizualnym a mechanizmem uwagi, manifestujących się jako efekty synergiczne lub antagonistyczne.


Synergię zaobserwowano dla połączenia architektur Densenet z uwagą miękką. Zjawisko antagonizmu zilustrowano na przykładzie sieci Regnet, która w połączeniu z uwagą miękką uległa degradacji, mimo iż w pozostałych trzech konfiguracjach zapewniała najwyższą skuteczność przy wysokiej złożoności.

Mechanizm uwagi własnej okazał się najbardziej restrykcyjny, wykazując niską kompatybilność z większością architektur i osiągając akceptowalne rezultaty jedynie z sieciami z rodziny Resnet/Regnet. Architektury InceptionV3 oraz Densenet201 często stanowiły optymalne rozwiązanie pod względem kompromisu między wydajnością a złożonością, umożliwiając redukcję parametrów przy zachowaniu wysokiej jakości.

Uzyskane wyniki wskazują na konieczność walidacji i doboru sieci szkieletowej specyficznie dla każdego zastosowanego mechanizmu uwagi, zamiast polegania na architekturach uznawanych za ogólnie najnowocześniejsze.

\subsubsection{Analiza jakościowa i ograniczenia metryk ewaluacyjnych}
\input{rezultaty/uwaga/analiza/analiza}
\input{rezultaty/uwaga/analiza/analiza_niski_cider}


Przeprowadzono analizę zgodności leksykalnej podpisów wygenerowanych dla obrazu kuchni, przedstawionego na Rysunku~\ref{fig:analiza}, przez cztery modele z różnymi mechanizmami uwagi, wykorzystujące sieć szkieletową Resnet152. Wyniki porównano z podpisami referencyjnymi w Tabeli~\ref{tab:analiza}. 

Wszystkie modele poprawnie zidentyfikowały scenę ("kitchen") oraz centralny obiekt ("stove"). Rozbieżności dotyczyły identyfikacji trzeciego obiektu, generując słowa "refrigerator", "pot", "microwave" oraz "sink". Żaden z tych lematów nie występuje w podpisach referencyjnych dla analizowanego obrazu. Zjawisko to stanowi halucynację obiektów (por.~\ref{sekcja:typologia_bledow}), będącą manifestacją tendencyjności językowej. Wyuczony model językowy dominuje nad sygnałem wizualnym. W konsekwencji model generuje obiekty statystycznie skorelowane z kontekstem. Finalnie powstają podpisy poprawne gramatycznie, lecz nieadekwatne wizualnie.

Metryki oparte na n-gramach (BLEU, ROUGE\_L) okazały się niewystarczająco czułe na ten błąd. Uzyskały one identyczne, wysokie wartości ($BLEU\_1 = 0,875$, $ROUGE\_L = 0,698$) dzięki poprawnemu odtworzeniu bazowej struktury zdania ("a kitchen with a..."), która ma wysokie pokrycie n-gramowe z podpisami referencyjnymi. Metryka CIDEr, choć zróżnicowała oceny, również okazała się myląca, przypisując najwyższy wynik (1,043) halucynacji "sink". Wynika to faktu, iż lemat "sink" posiada wyższą wagę TF-IDF w korpusie dla scen związanych z kuchnią. CIDEr faworyzował zatem słowo statystycznie istotne dla kontekstu, a nie wizualnie wierne treści obrazu. Ilustruje to ograniczenie metryki CIDEr, premiującej istotność semantyczną na poziomie korpusu kosztem wierności wizualnej.

Drugi przypadek na Rysunku~\ref{fig:analiza_niski_cider} ilustruje \textbf{błąd pominięcia istotnego obiektu} na obrazie. Obraz przedstawia nietypową aktywność (snowkiting), a podpisy referencyjne identyfikują narciarza ("skier") oraz kluczowy obiekt ("parachute", "cables"). Wygenerowane podpisy wykazały ujednoliconą, generyczną strukturę, np. "a man riding [skis/a snowboard] on a snow covered slope". Wszystkie warianty uwagi poprawnie identyfikowały ogólny kontekst (śnieg, narciarz), ale pomijały ważny obiekt ("spadochron"). Stanowi to błąd semantyczny - \textbf{nadmiernej ogólnikowości}, gdzie złożona, atypowa scena jest redukowana do najbardziej prawdopodobnego, typowego scenariusza "zjazd narciarski". Wskazuje to na ograniczoną zdolność modeli do kompozycyjnego rozumienia sceny. Dodatkowo, część modeli głównie opartych na Densenet błędnie sklasyfikowała sprzęt jako "snowboard".

Wysokie podobieństwo wygenerowanych podpisów sugeruje konwergencję modeli do generycznego rozwiązania, silnie reprezentowanego w danych treningowych. Błędy te miały bezpośredni wpływ na metryki. W przypadku klasyfikacji sprzętu jako "snowboard" CIDEr obniżył się do $\approx 13,5$, w porównaniu do $\approx 35,5$ przy poprawnej identyfikacji ("skis"). Wzrost ten jest jednak warunkowany wyłącznie poprawną identyfikacją jednego lematu o wysokiej wadze TF-IDF. Nawet najwyżej ocenione podpisy ($CIDEr \approx 35,5$) pozostają semantycznie niekompletne, gdyż pomijają kluczowy obiekt ("parachute").

Analiza potwierdza tendencję badanych modeli do generowania podpisów generycznych, odzwierciedlających dominujące rozkłady statystyczne w danych, kosztem unikalnych detali i atypowych interakcji. Przedstawione przykłady demonstrują, że wysokie wartości automatycznych metryk ewaluacyjnych nie gwarantują semantycznej poprawności ani kompletności wygenerowanego opisu.

\input{rezultaty/uwaga/uwaga_podpisy_zestawienie_leksyka/uwaga_podpisy_zestawienie_leksyka}
Analiza jakościowa pozwala na identyfikację specyficznych wzorców błędów charakteryzujących poszczególne mechanizmy uwagi oraz zrozumienie ich wpływu na proces generowania podpisów.


\input{rezultaty/uwaga/mapy_ciepla/spatial_Regnet16_decoder_dim_512_fine_tune_encoder_false_fine_tune_embeddings_false-epoch-20/COCO_val2014_000000123415_spatial_Regnet16_decoder_dim_512_fine_tune_encoder_false_fine_tune_embeddings_false-epoch-20}
Uwaga przestrzenna koncentruje się na określonych regionach obrazu, determinując lokalizację istotnych cech wizualnych. W analizowanym przykładzie na Obrazie~\ref{fig:uwaga_podpisy_zestawienie_leksyka_a} model wygenerował podpis "A couple of elephants standing next to each other", podczas gdy podpisy referencyjne wskazywały na obecność dorosłego i małego słonia. Ta rozbieżność ilustruje ograniczenie uwagi przestrzennej. Mimo skuteczności w identyfikacji głównych obiektów wykazuje ona tendencję do fiksacji na elementach dominujących wizualnie i ignorowania mniej wyrazistych szczegółów. W rezultacie model pominął mniejszy obiekt, co skutkowało \textbf{błędem liczebności} oraz uniemożliwiło adekwatne opisanie relacji między obiektami np. rodzicielskiej, prowadząc do niepełnej \textbf{interpretacji kontekstu} sceny.
Mapa ciepła na Rysunku~\ref{fig:COCO_val2014_000000123415_spatial_Regnet16_decoder_dim_512_fine_tune_encoder_false_fine_tune_embeddings_false-epoch-20}

\input{rezultaty/uwaga/mapy_ciepla/att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33/COCO_val2014_000000123321_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}
Uwaga miękka przyjmuje podejście globalne, analizując obraz poprzez przypisanie wag wszystkim regionom. W analizowanym przykładzie na Obrazie~\ref{fig:uwaga_podpisy_zestawienie_leksyka_b} model wygenerował podpis " close up of a bowl of soup with broccoli", w kontraście do podpisu referencyjnego "A bowl of broccoli with sauce over it.". Ewidentnie uwaga miękka poprzez holistyczne ujęcie sceny redukuje ryzyko halucynacji obiektów. Głównym ograniczeniem jest jednak niska precyzja wynikająca z braku mechanizmu selekcji cech wizualnych, co w przykładzie doprowadziło do \textbf{błędów generalizacji} i użycia "food" zamiast konkretnego "broccoli". Obserwuje się również \textbf{błędy w kategoryzacji obiektów}, gdzie pomylono "bowl" z "plate". Pominięto także atrybut "sauce", co wskazuje na trudności w precyzyjnym określaniu \textbf{relacji między obiektami i interpretacji kontekstu}.
\ref{fig:COCO_val2014_000000123321_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}

\input{rezultaty/uwaga/mapy_ciepla/regnet_aoanet/COCO_val2014_000000001448_regnet_aoanet}
Uwaga własna analizuje zależności pomiędzy różnymi elementami w obrębie obrazu w celu zrozumienia jego struktury kompozycyjnej. W przypadku obrazu z żyrafą na Rysunku~\ref{fig:uwaga_podpisy_zestawienie_leksyka_c}  model wygenerował "A giraffe is standing in a grassy field". Podpisy referencyjne precyzowały jednak atrybuty "young giraffe" oraz akcję "bending down to graze. Model pominął atrybut wieku oraz popełnił \textbf{błąd relacyjny}, opisując statyczną postawę "standing" zamiast dynamicznej akcji. Mechanizm ten okazał się efektywny w modelowaniu zależności długodystansowych i poprawnie zinterpretował ogólny kontekst sceny. Wykazał jednakże trudności w precyzyjnej interpretacji złożonych lub specyficznych działań, generując 
\textbf{błędy relacji}.
\ref{fig:COCO_val2014_000000001448_regnet_aoanet}

\input{rezultaty/uwaga/mapy_ciepla/att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33/COCO_val2014_000000121031_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}
Uwaga adaptacyjna dynamicznie decyduje pomiędzy wykorzystaniem informacji wizualnych a kontekstem językowym podczas generowania kolejnych słów. W analizowanym przykładzie na Rysunku~\ref{fig:uwaga_podpisy_zestawienie_leksyka_d} wygenerowano podpis "A man riding a horse through a river". Odbiega to od informacji w podpisach referencyjnych, gdzie za istotnych uznano jeźdźców. Chociaż uwaga adaptacyjna sprzyja generowaniu płynnych językowo podpisów, jej wadą jest ryzyko nadmiernego polegania na modelu językowym i ignorowania sygnału wizualnego. W przykładzie model drastycznie zaniżył liczbę obiektów (\textbf{błąd liczebności}) i nie zidentyfikował akcji grupowej (\textbf{błąd relacji obiektów}). \textbf{Halucynacja obiektów} wystąpiła we frazie "next to a horse", co dodatkowo wskazuje na znaczące zaburzenie równowagi między modalnością wizualną a językową.
\ref{fig:COCO_val2014_000000121031_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}

\input{rezultaty/uwaga/porownanie_z_klasycznym/porownanie_z_klasycznym}
Analiza porównawcza wskazuje na fundamentalne różnice w typologii błędów generowanych przez klasyczne modele koder-dekoder oraz z uwagą.

W podpisach dla Obrazu~\ref{fig:porownanie_z_klasycznym} zaobserwowano, że modele w podstawowej architekturze koder-dekoder wykazują znacznie większą podatność na błędy w interpretacji sceny. Zarówno w wariancie z fuzją jak i wstrzykiwaniem wstępnym wystąpiły \textbf{błędy faktograficzne}, polegające na \textbf{pominięciu istotnych obiektów} "park" i "grass" oraz \textbf{nieprawidłowym określeniu liczebności} osób. Metoda z wstrzykiwaniem wstępnym wykazała szczególnie niską skuteczność, generując podpis obarczony \textbf{błędami płynności językowej} oraz \textbf{spójności semantycznej}. Wystąpiły powtórzenia "man a and man a" oraz \textbf{błędy gramatyczne} w użyciu przedimków i spójników, które czynią podpis nieczytelnym. Podpis ten zawierał również \textbf{błędy relacyjne}, nie określając interakcji między człowiekiem, a latawcem, ani ich relacji ze środowiskiem.

Modele wyposażone w mechanizmy uwagi zademonstrowały wyższą precyzję w zakresie detekcji i opisu elementów sceny. W analizowanych wariantach nie zaobserwowano krytycznych \textbf{błędów faktograficznych} dotyczących obecności i liczebności kluczowych obiektów. Świadczy to o przewadze metod wykorzystujących uwagę w zadaniach wymagających dokładnej identyfikacji i kwantyfikacji obiektów oraz modelowania ich wzajemnych interakcji.

Należy jednak zaznaczyć, że zastosowanie mechanizmu uwagi nie eliminuje wszystkich kategorii błędów. Warianty z uwagą przestrzenną i adaptacyjną, mimo poprawnej identyfikacji kluczowych obiektów, dokonały błędnej kategoryzacji tła sceny, używając leksemu "field" zamiast "park". Sugeruje to, że nawet przy poprawnej analizie detali modele te mogą mieć trudności z adekwatną oceną globalnego kontekstu wizualnego. Warianty z uwagą miękką oraz własną wygenerowały podpisy pozbawione tego błędu w analizowanym przypadku.


\subsection{Analiza porównawcza czasu zbieżności}
W trzecim etapie badań przeanalizowano dynamikę treningu, mierzoną liczbą epok wymaganą do osiągnięcia optymalnej wartości metryki CIDEr na zbiorze walidacyjnym.

Analiza uśrednionych wyników na Rysunku~\ref{fig:sredni_czas_zbieznosci} wykazała istotne zróżnicowanie tempa konwergencji. Uwaga własna osiągała optymalną zbieżność najszybciej, średnio po $\approx 18,9$ epokach. Mechanizm uwagi adaptacyjnej wymagał średnio $\approx 20,9$ epok. Najwolniejszą konwergencją charakteryzowały się mechanizmy uwagi miękkiej ($\approx 22,1$ epok) oraz przestrzennej ($\approx 22,2$ epok). Szybsza zbieżność uwagi własnej jest skorelowana z zastosowaną dla niej odmienną strategią treningową (end-to-end, losowe osadzenia). Sugeruje to, że ta procedura przyspiesza proces uczenia w porównaniu do strategii dwuetapowej stosowanej dla pozostałych rodzajów uwagi. Szczegółową analizę interakcji przedstawiono na Rysunku~\ref{fig:wplyw_bazowej_cnn_na_czas_zbieznosci_modelu}.

\input{rezultaty/uwaga/naj_epoka/sredni_czas_zbieznosci}
\input{rezultaty/uwaga/naj_epoka/wplyw_bazowej_cnn_na_czas_zbieznosci_modelu}
Rysunek~\ref{fig:wplyw_bazowej_cnn_na_czas_zbieznosci_modelu} potwierdza, że wybór sieci szkieletowej ma dominujący wpływ na tempo uczenia. Dla uwagi adaptacyjnej model referencyjny Resnet152 osiągnął zbieżność w 33 epoce. Zastosowanie InceptionV3 (15 epok) oraz Densenet201 (17 epok) skróciło ten czas niemal dwukrotnie. Wskazuje to na wysoki potencjał optymalizacji czasu treningu.

W przypadku uwagi przestrzennej model referencyjny Resnet152 wymagał 31 epok. Najszybsza okazała się architektura Regnet (20 epok), a najwolniejsza Resnet101 (34 epoki).

Analiza uwagi miękkiej wykazała dużą wariancję, od 32 epok z Regnet do 41 epok z Densenet121. Należy jednak zaznaczyć, że szybka konwergencja (32 epoki) konfiguracji z Regnet jest wynikiem mylącym. Jak wykazano w Sekcji~\ref{sec:analiza_wydajnosci}, model ten charakteryzował się znaczącą degradacją metryki CIDEr. Szybka zbieżność oznaczała w tym przypadku konwergencję do nieoptymalnego minimum lokalnego, co potwierdza antagonistyczną interakcję tych komponentów.

Dla uwagi własnej model referencyjny Resnet101 osiągnął zbieżność w 19 epoce. Najszybszą konwergencję odnotowano dla sieci InceptionV3 (14 epok), a następnie dla Regnet (16 epok) i Densenet201 (18 epok).

Podsumowując, mechanizm uwagi własnej, trenowany strategią end-to-end, zapewnia najszybszą średnią zbieżność. Wybór architektury sieci szkieletowej ma decydujący wpływ na tempo uczenia, często przewyższający wpływ samego typu uwagi. Modele oparte na InceptionV3, Densenet201 oraz Regnet systematycznie wykazywały tendencję do szybszej konwergencji. Potwierdzono, że modele referencyjne Resnet152, Resnet101 w większości przypadków nie stanowiły konfiguracji optymalnych pod względem czasu wymaganego do treningu.


\subsection{Optymalizacja strategii przeszukiwania}
W czwartym etapie badań zbadano wpływ parametru szerokości wiązki $k$ algorytmu przeszukiwania wiązkowego (\gls{gls:beam-search}) na jakość generowanych podpisów, mierzoną metryką CIDEr. Badanie przeprowadzono dla dyskretnego zbioru wartości $k \in \{1, 2, 3, 5, 8\}$. Analiza objęła wszystkie przetestowane wcześniej kombinacje architektur, tj. cztery mechanizmy uwagi i siedem sieci szkieletowych. Celem była identyfikacja optymalnej wartości $k$ oraz charakterystyka jej interakcji z komponentami modelu.

\input{rezultaty/uwaga/analiza_beam/dystrybucja_cider_dla_rozmiaru_wiazki}
Analiza dystrybucji wyników CIDEr na Rysunku~\ref{fig:dystrybucja_cider_dla_rozmiaru_wiazki} wykazuje istotną przewagę przeszukiwania wiązkowego nad dekodowaniem zachłannym. Mediana wartości CIDEr wzrasta z około 95 ($k=1$) do niemal 100 dla $k=2$ i $k=3$. Dla $k$ większego od 3 ($k=5$, $k=8$) nie zaobserwowano dalszej poprawy, mediana utrzymuje się na zbliżonym poziomie. Ponadto analiza rozproszenia wyników wykazała, że dla $k=8$ następuje zwiększenie rozstępu międzykwartylowego, co wskazuje na wzrost wariancji i obniżenie stabilności predykcji. Obserwacje te implikują istnienie plateau optymalności dla wąskiego zakresu $k \in \{2,3\}$. Dalsze poszerzanie wiązki nie skutkuje poprawą jakości, generuje jedynie dodatkowy, nieuzasadniony koszt obliczeniowy inferencji.

\input{rezultaty/uwaga/analiza_beam/porownanie_trendow_cnn}
\input{rezultaty/uwaga/analiza_beam/porownanie_trendow_uwaga}
Szczegółowa analiza na Rysunku~\ref{fig:porownanie_trendow_uwaga} potwierdziła, że wpływ szerokości wiązki $k$ jest zróżnicowany i zależy od zastosowanego mechanizmu uwagi.

Mechanizm uwagi własnej wykazał najwyższą uśrednioną skuteczność, utrzymując stabilną, wysoką wydajność dla $k \in \{2, 3, 5\}$. Najwyższą wartość metryki CIDEr w całym badaniu (117,59) uzyskano właśnie dla tej konfiguracji przy $k=3$ i sieci szkieletowej Regnet. Mechanizmy uwagi adaptacyjnej i przestrzennej cechowały się porównywalną, niższą wydajnością, osiągając optimum dla $k=3$. Mechanizm uwagi miękkiej konsekwentnie notował najniższe wyniki. Wskazuje to na synergię między strategią dekodowania a typem uwagi. Model z uwagą własną najefektywniej wykorzystuje przeszukiwanie wiązkowe do eksploracji przestrzeni hipotez.

Podobne zależności zidentyfikowano w analizie wpływu architektury sieci szkieletowej na Rysunku~\ref{fig:porownanie_trendow_cnn}. Architektura Regnet wykazała istotną przewagę, osiągając najwyższe średnie wartości CIDEr. Szczytową wydajność dla tej sieci odnotowano już przy $k=2$. Modele z rodziny Densenet oraz Resnet101 charakteryzowały się niższym poziomem efektywności, z optimum w przedziale $k \in \{2, 3\}$. Najniższą skuteczność predykcyjną odnotowano dla InceptionV3, co sugeruje najmniejszą adekwatność cech wizualnych ekstrahowanych przez tę architekturę dla badanego zadania.

Podsumowując, wyniki badań empirycznych wskazują, że zwiększenie szerokości wiązki z $k=1$ do $k \in \{2, 3\}$ skutkuje systematycznym wzrostem jakości podpisów. Dalsze poszerzanie wiązki jest nieefektywne, nie przynosi poprawy metryk i zwiększa wariancję wyników. Najwyższą wartość metryki CIDEr (117,60) osiągnięto dla modelu opartego na mechanizmie uwagi własnej z siecią szkieletową Regnet, przy $k=3$. Wartość $k=3$ zostaje zatem zidentyfikowana jako optymalny kompromis pomiędzy jakością generowanych podpisów a złożonością obliczeniową procesu inferencji dla badanych architektur.

