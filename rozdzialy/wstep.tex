\chapter{Wstęp}
Automatyczne generowanie podpisów do obrazów jest zadaniem interdyscyplinarnym, łączącym obszary widzenia komputerowego oraz przetwarzania języka naturalnego. Jego celem jest synteza zdania adekwatnego do zawartości wizualnej. Proces ten stanowi obliczeniową próbę symulacji ludzkiej zdolności do semantycznej interpretacji i opisu sceny wizualnej. Wymaga to nie tylko identyfikacji obiektów, lecz również rozpoznania ich atrybutów oraz zrozumienia ich wzajemnych relacji przestrzennych i semantycznych.

Problematyka ta ma korzenie filozoficzne, odnoszące się do fundamentalnej relacji między obrazem a słowem. Zgodnie z teorią przedstawioną przez Ludwiga Wittgensteina, "zdanie stanowi logiczny model faktu"~\cite{Wittgenstein1997traktat}. W tym ujęciu zadanie automatycznego generowania podpisów do obrazów staje się próbą stworzenia językowego odpowiednika sceny wizualnej. 

Podejście do analizowanego problemu można pogłębić, traktując go w kategoriach semiotycznych, gdzie obraz jest postrzegany nie jako prosta kopia rzeczywistości, ale jako złożony system znaków wizualnych~\cite{Burzynska2006teorie}. Proces generowania podpisu staje się wówczas tłumaczeniem wizualnego systemu semiotycznego na system lingwistyczny~\cite{Eco1972Pejzaz}. Również fenomenologia dostarcza inspiracji, postulując, że patrzenie na obraz nie jest procesem pasywnym, lecz intencjonalnym aktem poznawczym~\cite{Ingarden1970Studia}. Ludzki umysł aktywnie selekcjonuje istotne elementy sceny wizualnej, a następnie syntetyzuje ich właściwości. Dla sztucznej inteligencji implikuje to konieczność symulacji tego procesu.

Wyzwaniem staje się zachowanie wierności semantycznej. Wykorzystując analogię do koncepcji granic interpretacji~\cite{Eco2008Interpretacja}, obraz jako dzieło sam narzuca ograniczenia co do tego, jak może być rozumiany. Model generujący podpisy pełni rolę "czytelnika" obrazu, a jego sukces zależy od zdolności do działania w granicach wyznaczonych przez dane. Poprawnie wygenerowany podpis jest zatem formą trafnej interpretacji, podczas gdy błędy, takie jak generowanie nieistniejących obiektów, stanowią przykład nadinterpretacji. Problem badawczy pracy koncentruje się zatem na stworzeniu modeli zdolnych do wiarygodnej interpretacji, a nie niekontrolowanej nadinterpretacji.

Współczesne badania nad sztuczną inteligencją są zdominowane przez nurty koneksjonistyczne i ucieleśnione (\gls{gls:embodied-ai}), które mimo znaczących różnic w praktyce się uzupełniają. Koneksjonizm naśladuje strukturę mózgu za pomocą głębokich sieci neuronowych~\cite{Lacey2002dictionary}, natomiast ucieleśniona AI zakłada, że rozwój sztucznej inteligencji wymaga, aby wchodziła ona w fizyczną interakcję ze środowiskiem~\cite{Lin2023EmbeddedAI}. Próbą matematycznej symulacji ludzkiej percepcji stał się mechanizm uwagi, który pozwala maszynie selektywnie wybierać, na które fragmenty danych powinna zwrócić uwagę. Model przetwarza obraz holistycznie, ale w trakcie syntezy kolejnych słów dynamicznie alokuje zasoby obliczeniowe, koncentrując się na regionach obrazu najbardziej relewantnych w danym momencie~\cite{Stefanini2021Show}. Istotnym celem rozprawy jest ocena skuteczności modeli typu koder-dekoder oraz analiza wpływu, jaki wywiera na nią rozszerzenie o mechanizm uwagi.

Podstawowym zadaniem automatycznego generowania podpisów do obrazów jest transformacja surowej macierzy pikseli w semantycznie spójny podpis do obrazu. Zgodnie z funkcjonalnym podejściem do języka, inspirowanym późną filozofią Wittgensteina, proces ten można interpretować jako nadawanie obrazowi konkretnego kontekstu użycia~\cite{Biggs2021WittPictureInv}. Tworząc podpis, system zamienia pasywną reprezentację wizualną w aktywne, weryfikowalne stwierdzenie o rzeczywistości. Problematyka badawcza tej pracy koncentruje się zatem na projektowaniu i optymalizacji architektur neuronowych zdolnych do niezawodnego przeprowadzania tej transformacji.

Postęp w tej dziedzinie, napędzany przez rozwój coraz bardziej zaawansowanych architektur, prowadzi do systematycznej poprawy jakości generowanych podpisów. Jednakże wzrost skuteczności modeli jest związany z gwałtownym wzrostem ich złożoności obliczeniowej i liczby parametrów. Tworzy to istotną barierę dla praktycznych wdrożeń, szczególnie na platformach o ograniczonych zasobach. Prowadzi to do rosnącej luki między teoretycznymi możliwościami modeli a ich realną użytecznością.

Niniejsza rozprawa doktorska, osadzona w przedstawionych ramach teoretycznych, adresuje ten problem. Głównym celem badawczym jest optymalizacja i udoskonalenie istniejących architektur neuronowych, tj. modeli koder-dekoder oraz wariantów z mechanizmem uwagi. Zadanie polega na maksymalizacji wierności i trafności generowanych podpisów, przy jednoczesnym uwzględnieniu ograniczeń związanych ze złożonością obliczeniową.  Znaczenie tych badań wynika z szerokiego spektrum potencjalnych zastosowań, obejmujących technologie asystujące dla osób z niepełnosprawnością wzroku, usprawnianie semantycznego wyszukiwania informacji w zbiorach wizualnych oraz budowanie bardziej intuicyjnych interfejsów człowiek-komputer. Zgodnie z technicznym obrazem świata Jean-Paula Sartre'a, działanie inżynieryjne nie jest celem samym w sobie, lecz aktem ukierunkowanym na konkretną użyteczność~\cite{Sartre1998TechniczyObraz}, co nadaje pracy głębszy wymiar humanistyczny i społeczny.


\section{Cel rozprawy}
Celem rozprawy jest opracowanie i weryfikacja  metod doskonalenia systemów służących do automatycznego generowania podpisów do obrazów. Cel badawczy jest realizowany poprzez maksymalizację jakości generowanych podpisów oraz optymalizację wydajności obliczeniowej modeli. W aspekcie jakościowym badania koncentrują się na maksymalizacji wartości metryk jakościowych stosowanych w zadaniu automatycznego generowania podpisów do obrazów, takich jak BLEU-1 do BLEU-4, CIDEr czy SPICE. Równolegle, w wymiarze wydajnościowym praca adresuje problem złożoności obliczeniowej na dwa sposoby. Pierwszym jest minimalizacja rozmiaru modelu neuronowego przy zachowaniu jego zdolności predykcyjnych. Drugim jest skrócenie czasu treningu, ewaluowanego za pomocą liczby epok niezbędnych do osiągnięcia zbieżności.

Badania są realizowane dwutorowo. Pierwszy kierunek badań koncentruje się na analizie i modyfikacji architektur neuronowych typu koder-dekoder. W ramach drugiego kierunku badawczego badane są modele wzbogacone o mechanizm uwagi, gdzie każde słowo wiązane jest z konkretnym fragmentem obrazu.

\section{Hipoteza badawcza} 
Główna hipoteza badawcza zakłada, że systematyczna optymalizacja komponentów składowych w ramach ugruntowanych architektur koder-dekoder oraz modeli z mechanizmem uwagi pozwala na osiągnięcie istotnej poprawy jakości generowanych podpisów do obrazów. Postuluje się, że poprawa ta jest porównywalna z efektami wprowadzania fundamentalnie nowych topologii sieci. Klucz do zwiększenia skuteczności leży zatem nie w opracowywaniu nowatorskich architektur, lecz w empirycznym doborze i precyzyjnym dostrojeniu istniejących komponentów. W celu weryfikacji powyższego założenia sformułowano cztery hipotezy szczegółowe. 

(H1) Wybór sieci szkieletowej w koderze wizualnym ma decydujące znaczenie dla jakości semantycznej generowanych podpisów. Nowoczesne sieci szkieletowe oparte na sieciach splotowych, takie jak Xception czy Densenet dostarczają bogatszej i bardziej relewantnej reprezentacji wizualnej niż starsze modele jak VGG. Przekłada się to bezpośrednio na wyższą trafność i szczegółowość podpisów mierzonych metrykami CIDEr i BLEU.

(H2) Metoda fuzji tekstu z obrazem oraz struktura dekodera językowego warunkują finalną skuteczność modelu. Zakłada się, że strategia łączenia cech wizualnych i tekstowych oparta na konkatenacji (\gls{gls:concatenation}) wektorów jest skuteczniejsza od ich sumowania, ponieważ zapobiega utracie informacji i pozwala modelowi na naukę bardziej złożonych interakcji.

(H3) Architektury rekurencyjne o zredukowanej złożoności, jak GRU, mogą osiągnąć wyniki porównywalne z bardziej złożonymi modelami LSTM przy jednoczesnym obniżeniu kosztów obliczeniowych. Efekt ten jest oczekiwany w zadaniu generowania stosunkowo krótkich sekwencji tekstowych, jakim jest tworzenie podpisów automatycznych.

(H4) Istnieje efekt synergii pomiędzy architekturą kodera wizualnego a konfiguracją dekodera językowego. Optymalna wydajność systemu nie jest jedynie sumą wydajności jego najlepszych, odizolowanych komponentów. Istnieje specyficzna, optymalna kombinacja sieci szkieletowej (\gls{gls:backbone-network}), modelu osadzeń słów, metody fuzji modalności oraz struktury sieci rekurencyjnej. Jej identyfikacja umożliwia maksymalizację jakości generowanych podpisów.

Weryfikację hipotez przedstawiono w rozdziałach eksperymentalnych, począwszy od Rozdziału~\ref{rozdzial:badania_podstawowej_architektury_koder_dekoder}. Badania te obejmą systematyczne porównanie wydajności różnych konfiguracji modelu na ugruntowanym zbiorze danych Microsoft COCO, z wykorzystaniem ugruntowanego zestawu metryk ewaluacyjnych.

\section{Zakres pracy}

Rozprawa doktorska koncentruje się na analizie, optymalizacji i weryfikacji empirycznej modeli uczenia głębokiego przeznaczonych do podpisywania obrazów. Zakres pracy obejmuje aspekty teoretyczne oraz szczegółowe badania eksperymentalne, realizowane w ramach dwóch głównych paradygmatów architektonicznych. Klasycznych modeli typu koder-dekoder oraz modeli wzbogaconych o mechanizm uwagi.
Szczegółowy zakres pracy obejmuje:
\begin{itemize}
    \item  \textbf{Przegląd literatury i podstawy teoretyczne:} Systematyzacja wiedzy dotyczącej ewolucji metod automatycznego podpisywania obrazów, od podejść kompozycyjnych po zaawansowane architektury neuronowe. Szczegółowe omówienie komponentów systemów, w tym koderów wizualnych opartych na sieciach szkieletowych, dekoderów językowych zbudowanych z rekurencyjnych sieci neuronowych oraz modeli osadzeń słów oraz wariantów mechanizmu uwagi takich jak uwaga miękka, przestrzenna, adaptacyjna, uwaga własna.
    
    \item \textbf{Metodologia badań i ewaluacji:} Charakterystyka wykorzystywanych zbiorów danych, ze szczególnym uwzględnieniem referencyjnego zbioru Microsoft COCO. Analiza i dobór metryk ewaluacji automatycznej, takich jak BLEU, ROUGE, METEOR, CIDEr, SPICE oraz omówienie roli oceny ludzkiej w tym typologii błędów w weryfikacji jakości semantycznej i lingwistycznej generowanych podpisów.
    \item \textbf{Badania podstawowej architektury koder-dekoder:} Empiryczna weryfikacja wpływu doboru komponentów składowych na jakość generowanych podpisów i złożoność obliczeniową modelu. Zakres badań obejmuje analizę porównawczą różnych sieci szkieletowych, m.in. VGG, Resnet, Densenet, Xception, metod fuzji modalności poprzez wstrzykiwanie wstępne i fuzję przez dodawanie lub konkatenację oraz struktur sieci rekurencyjnej w dekoderze językowym, jak LSTM, GRU i modeli osadzeń GloVe, FastText.
    
    \item \textbf{Badania modeli z mechanizmem uwagi:} Analiza i implementacja zaawansowanych mechanizmów uwagi w architekturach koder-dekoder. Weryfikacja skuteczności modeli wykorzystujących uwagę przestrzenną, adaptacyjną oraz własną w kontekście poprawy trafności i szczegółowości generowanych podpisów. 
    
    \item \textbf{Analiza porównawcza i walidacja:} Systematyczne porównanie wydajności opracowanych modeli na podstawie zdefiniowanych metryk jakościowych i wydajnościowych. Analiza jakościowa generowanych podpisów, w tym kategoryzacja błędów, takich jak halucynacje obiektów, błędy w liczeniu oraz ocena zdolności do generalizacji na danych spoza dystrybucji treningowej.
\end{itemize}
Praca ogranicza się do analizy obrazów statycznych i generowania podpisów w formie pojedynczych zdań denotatywnych. Poza zakresem badań pozostają zagadnienia generowania opisów wideo, generowania podpisów narracyjnych oraz optymalizacja modeli z wykorzystaniem metod uczenia ze wzmocnieniem.

\section{Struktura pracy}
Rozprawa składa się z siedmiu rozdziałów, uzupełnionych o bibliografię oraz wykaz stosowanych skrótów i symboli.

Rozdział 1 stanowi wprowadzenie do problematyki automatycznego generowania podpisów do obrazów. Przedstawiono w nim tło teoretyczne i motywację badawczą. Sformułowano cel pracy, skoncentrowany na optymalizacji jakościowej i wydajnościowej modeli, postawiono hipotezy badawcze dotyczące doskonalenia istniejących architektur oraz określono zakres pracy.

Rozdział 2 zawiera systematyczny przegląd literatury przedmiotu. Dokonano analizy ewolucji metod, począwszy od podejść kompozycyjnych, poprzez paradygmat koder-dekoder, aż po modele wykorzystujące mechanizm uwagi i architekturę transformatorową. Rozdział kończy identyfikacja luki badawczej.

Rozdział 3 przedstawia podstawy teoretyczne i komponenty składowe systemów do automatycznego generowania podpisów. Szczegółowo omówiono koder wizualny w tym sieci szkieletowe oraz dekoder językowy, gdzie omówiono metody reprezentacji słów i sieci rekurencyjne. Przedstawiono strategie integracji danych multimodalnych i warianty mechanizmu uwagi.

Rozdział 4 poświęcony jest metodyce ewaluacji i charakterystyce wykorzystywanych zbiorów danych. Dokonano przeglądu referencyjnych zbiorów danych oraz krytycznej analizy automatycznych metryk oceny jakości podpisów maszynowych (m.in. BLEU, CIDEr, SPICE). Omówiono również rolę oceny ludzkiej w tym typologię błędów oraz teoretyczną analizę wyzwań związanych z językami fleksyjnymi, na przykładzie języka polskiego.

Rozdział 5 rozpoczyna część eksperymentalną, realizując pierwszy kierunek badawczy. Prezentuje wyniki badań nad optymalizacją podstawowej architektury koder-dekoder. Przeanalizowano wpływ doboru komponentów modelu, w tym sieci szkieletowej, osadzeń słów, typu sieci RNN oraz strategii integracji modalności poprzez fuzję i wstrzykiwanie wstępne na skuteczność i wydajność obliczeniową modelu.

Rozdział 6 realizuje drugi kierunek badawczy. Zawiera wyniki badań nad modelami koder-dekoder, które wzbogacono o mechanizm uwagi. Skoncentrowano się na analizie empirycznej i optymalizacji synergii między komponentem wizualnym a językowym w celu poprawy trafności semantycznej generowanych podpisów.

Rozdział 7 stanowi podsumowanie rozprawy. Zawiera syntezę uzyskanych wyników, weryfikację postawionych hipotez badawczych, wnioski końcowe oraz wskazanie kierunków dalszych badań.