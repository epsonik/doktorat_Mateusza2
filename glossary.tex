\newacronym{SVM}{SVM}{Support Vector Machine}
\newacronym{MRF}{MRF}{Markov Random Field}
\newacronym{SIFT}{SIFT}{Scale-invariant feature Transform}
\newacronym{LSTM}{LSTM}{Long Short-term Memory}
\newacronym{GRU}{GRU}{Gated Recurrent Units}
\newacronym{HOG}{HOG}{histogram of oriented gradients}
\newacronym{VDR}{VDR}{visual dependency representations}
\newacronym{KICA}{KICA}{kernel independent component analysis}
\newacronym{CNN}{CNN}{Convolutional Neural Network}
\newacronym{GAP}{GAP}{Global Average Pooling}
\newacronym{RNN}{RNN}{Recurrent Neural Networks}
\newacronym{NMT}{NMT}{Neural Machine Translation}
\newacronym{relu}{ReLU}{Rectified Linear Unit}
\newacronym{mle}{MLE}{Maximum Likelihood Estimator}
\newacronym{lcs}{LCS}{Longest Common Subsequence}
\newacronym{bow}{BoW}{Bag-of-Words}
\newacronym{ocr}{OCR}{Optyczne Rozpoznawanie Obrazów}

\newglossaryentry{gls:word-embeddings}{
    name={word embeddings},
    description={osadzenia słów}
}
\newglossaryentry{gls:osadzenia-slow}{
    name={osadzenia słów},
    description={Osadzenia słów}
}

\newglossaryentry{gls:early-stopping}{ name={early stopping}, description={wczesne zatrzymanie }}

\newglossaryentry{gls:one-hot-encoding}{name={one-hot encoding},description={kodowanie gorącojedynkowe}}
\newglossaryentry{gls:gradient-clipping}{name={gradient clipping},description={obcinanie gradientu}}
\newglossaryentry{gls:soft-attention}{name={soft attention}, description={uwaga miękka}}
\newglossaryentry{gls:hard-attention}{name={hard attention}, description={uwaga twarda}}
\newglossaryentry{gls:attention-mechanism}{name={attention-mechanism}, description={mechanizm uwagi}}
\newglossaryentry{gls:spatial-attention}{name={spatial attention}, description={uwaga przestrzenna}}
\newglossaryentry{gls:adaptive-attention}{name={adaptive attention}, description={uwaga adaptacyjna}}
\newglossaryentry{gls:aoa}{name={Attention on Attention (AoA)}, description={uwaga na uwadze}}
\newglossaryentry{gls:relu}{name={ReLU}, description={Rectified Linear Unit}}
\newglossaryentry{gls:self-attention}{name={self attention}, description={uwaga własna}}
\newglossaryentry{gls:transfer-learning}{name={transfer learning}, description={transfer wiedzy}}
\newglossaryentry{gls:inferencja}{name={inferencja}, description={generowanie zdania po wytrenowaniu modelu do automatycznego podpisywania obrazów}}
\newglossaryentry{gls:bottleneck}{name={bottleneck}, description={wąskie gardło}}

\newglossaryentry{gls:max-pooling}{name={max pooling}, description={agregacja maksimum}}

\newglossaryentry{gls:average-pooling}{name={average pooling}, description={agregacja maksimum}}
\newglossaryentry{gls:batch-normalization}{name={batch normalization}, description={normalizacja wsadowa}} 
\newglossaryentry{gls:embodied-ai}{name={embodied AI}, description={ucieleśnione AI}}
\newglossaryentry{gls:factorization}{name={factorization},description={rozkład na czynniki}}
\newglossaryentry{gls:translation-invariance}{name={translation invariance}, description={niezmienności względem lokalnych translacji }}

\newglossaryentry{gls:multimodal}{name={multimodal}, description={międzydziedzinowy}}
\newglossaryentry{gls:bilinear-pooling}{name={bilinear pooling}, description={redukcja dwuliniowa}}
\newglossaryentry{gls:depthwise-separable-convolutions}{name={depthwise separable convolutions},description={sploty odseparowane wgłębnie}}  
\newglossaryentry{gls:residual-connection}{name={residual connection}, description={połączenia szczątkowe}}
\newglossaryentry{gls:depthwise-convolution}{name={depthwise convolution}, description={splot wgłębny}}
\newglossaryentry{gls:depthwise-separable-convolution}{name={depthwise separable convolution}, description={splot odseparowany wgłębnie}}
\newglossaryentry{gls:pooling-layer}{name={pooling layer}, description={warstwa agregacji}}
\newglossaryentry{gls:smoothing}{name={smoothing}, description={smoothing}}

\newglossaryentry{gls:concatenation}{name={concatenation}, description={konkatenacja}}
\newglossaryentry{gls:addition}{name={addition}, description={dodawanie}}
\newglossaryentry{gls:end-to-end}{name={end-to-end}, description={model jednolity}}
\newglossaryentry{gls:end-to-end-learning}{name={end-to-end-learning}, description={jednolite uczenie modelu}}
\newglossaryentry{gls:end-to-end-training}{name={end-to-end-training}, description={jednolity trening modelu}}
\newglossaryentry{gls:residual-learning}{name={residual-learning}, description={uczenie rezydualne}}

\newglossaryentry{symb:odot}{name={$\odot$}, description={iloczyn Hadamarda, element po elemencie}}
% ; Polega na pomnożeniu odpowiadających sobie elementów, ale bez ich sumowania.;wyjściem jest macierz

\newglossaryentry{symb:cdot}{name={$\cdot$}, description={iloczyn skalarny wektorów;powstaje skalar}}
\newglossaryentry{gls:pre-training}{name={pre-training}, description={trenowanie wstępne} }
\newglossaryentry{gls:element-wise}{name={element wise}, description={element po elemencie }}
\newglossaryentry{gls:greedy-search}{name={greedy search}, description={przeszukiwanie zachłanne}}
\newglossaryentry{gls:beam-search}{name={beam search}, description={przeszukiwanie wiązkowe}}
\newglossaryentry{gls:visual-sentinel}{name={visual sentinel}, description={strażnik wizualny}}
\newglossaryentry{gls:sentinel-gate}{name={sentinel gate}, description={bramka strażnika}}
\newglossaryentry{gls:fully-connected-layer}{name={Fully-connected layer (FC)}, description={warstwa w pełni połączona}}
\newglossaryentry{gls:ood}{name={Out of Distribution, (OOD)}, description={dane spoza dystrybucji zbioru treningowego }}

\newglossaryentry{gls:halucynacja-kategoryczna}{name={halucynacja kategoryczna},description={halucynacja kategoryczna}}
\newglossaryentry{gls:substytucja-semantyczna}{name={substytucja semantyczna},description={substytucja semantyczna}}
\newglossaryentry{gls:overfitting}{name={overfitting}, description={przeuczenie}}
\newglossaryentry{gls:language-bias}{name={language bias}, description={tendencyjność modelu}}
\newglossaryentry{gls:oov}{name={Out-of-Vocabulary, (OOV)}, description={problem słów spoza słownika}}
\newglossaryentry{gls:plateu}{name={plateau}, description={zjawisko występujące, gdy funkcja straty w modelu przestaje się zmniejszać podczas treningu}}
\newglossaryentry{gls:object-hallucination}{name={object-hallucination}, description={halucynacja obiektów}}
\newglossaryentry{gls:wcd}{name={wcd}, description={Word Centroid Distance, (WCD)}}
\newglossaryentry{gls:rwmd}{name={RWMD}, description={Relaxed Word Mover's Distance, (RWMD)}}
\newglossaryentry{gls:bounding-box}{name={bounding box}, description={najmniejsza możliwa ramka otaczająca kompletny obiekt na obrazie}}
\newglossaryentry{gls:eps}{name={epsilon}, description={mała wartość dodawana w obliczeniach (np. w mianowniku) w celu zapewnienia stabilności numerycznej i uniknięcia dzielenia przez zero}}
\newglossaryentry{gls:weight-decay}{name={weight decay}, description={technika regularyzacji, która zapobiega przeuczeniu modelu poprzez dodawanie kary za zbyt duże wartości wag.}}
\newglossaryentry{gls:teacher-forcing}{name={teacher-forcing}, description={uczenie z nauczycielem}}
\newglossaryentry{gls:cross-entropy-loss}{name={cross-entropy loss}, description={strata entropii krzyżowej}}
\newglossaryentry{gls:learning-rate}{name={learning-rate}, description={współczynik uczenia}}
\newglossaryentry{gls:backbone-network}{name={backbone-network}, description={sieć szkieletowa}}

\newglossaryentry{gls:fine-tuning}{name={fine-tuning}, description={dostrajanie}}
\newglossaryentry{gls:convolutional-layer}{name={convolutional layer}, description={warstwa splotowa}}
\newglossaryentry{gls:preprocessing}{name={preprocessing},description={wstępne przetwarzanie danych}}

\newglossaryentry{gls:tokenizacja}{name={tokenizacja}, description={segmentacja ciągów znaków na fundamentalne jednostki analizy – tokeny}}
\newglossaryentry{gls:lematyzacja}{name={lematyzacja}, description={proces sprowadzania form fleksyjnych wyrazu do jego formy podstawowej, zwanej lematem}}
\newglossaryentry{gls:stemming}{name={stemming},description={stemowanie - proces sprowadzania form fleksyjnych wyrazu do jego formy podstawowej zwanej stemem, ale w oparciu na analizie morfologicznej i kontekstowej}}

\newglossaryentry{gls:stop-words}{name={stop-words}, description={słowa funkcyjne - powszechnie występujące jednostki językowe o niskiej wartości semantycznej, takie jak "i", "w", "się" dla języka polskiego czy "and", "a", "the" dla angielskiego~\cite{Fox1989StopWords, Sarica2021StopWords} }}


\newglossaryentry{gls:backpropagation}{name={backpropagation}, description={propagacja wsteczna}}
\newglossaryentry{gls:cross-entropy}{name={cross-entropy}, description={entropia krzyżowa}}
\newglossaryentry{gls:tf-idf}{name={TF-IDF (Term Frequency-Inverse Document Frequency)}, description={TF-IDF (Term Frequency-Inverse Document Frequency)}}

\newglossaryentry{gls:checkpoint}{name={checkpoint}, description={punkt kontrolny}}

\newglossaryentry{gls:cross-attention}{name={cross-attention}, description={uwaga krzyżowa}}
\newglossaryentry{gls:mlm}{name={Maskowany Model Językowy, (MLM)}, description={Masked Language Model, (MLM)}}
\newglossaryentry{gls:fidelity-errors}{name={fidelity errors}, description={błędy faktograficzne}}

\newglossaryentry{gls:relevance-errors}{name={relevance errors}, description={błędy relacyjne}}
\newglossaryentry{gls:bias_and_social_harms}{name={bias and social harms}, description={}}
\newglossaryentry{gls:fluency-errors}{name={fluency-errors}, description={błędy płynności językowej}}

\newglossaryentry{gls:pleonazm}{name={pleonazmów}, description={\cite{Andrzej2005kultura}}}