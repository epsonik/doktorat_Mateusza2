\subsubsection{Analiza jakościowa i ograniczenia metryk ewaluacyjnych}
\input{rezultaty/uwaga/analiza/analiza}
\input{rezultaty/uwaga/analiza/analiza_niski_cider}


Przeprowadzono analizę zgodności leksykalnej podpisów wygenerowanych dla obrazu kuchni, przedstawionego na Rysunku~\ref{fig:analiza}, przez cztery modele z różnymi mechanizmami uwagi, wykorzystujące sieć szkieletową Resnet152. Wyniki porównano z podpisami referencyjnymi w Tabeli~\ref{tab:analiza}. 

Wszystkie modele poprawnie zidentyfikowały scenę ("kitchen") oraz centralny obiekt ("stove"). Rozbieżności dotyczyły identyfikacji trzeciego obiektu, generując słowa "refrigerator", "pot", "microwave" oraz "sink". Żaden z tych lematów nie występuje w podpisach referencyjnych dla analizowanego obrazu. Zjawisko to stanowi halucynację obiektów (por.~\ref{sekcja:typologia_bledow}), będącą manifestacją tendencyjności językowej. Wyuczony model językowy dominuje nad sygnałem wizualnym. W konsekwencji model generuje obiekty statystycznie skorelowane z kontekstem. Finalnie powstają podpisy poprawne gramatycznie, lecz nieadekwatne wizualnie.

Metryki oparte na n-gramach (BLEU, ROUGE\_L) okazały się niewystarczająco czułe na ten błąd. Uzyskały one identyczne, wysokie wartości ($BLEU\_1 = 0,875$, $ROUGE\_L = 0,698$) dzięki poprawnemu odtworzeniu bazowej struktury zdania ("a kitchen with a..."), która ma wysokie pokrycie n-gramowe z podpisami referencyjnymi. Metryka CIDEr, choć zróżnicowała oceny, również okazała się myląca, przypisując najwyższy wynik (1,043) halucynacji "sink". Wynika to faktu, iż lemat "sink" posiada wyższą wagę TF-IDF w korpusie dla scen związanych z kuchnią. CIDEr faworyzował zatem słowo statystycznie istotne dla kontekstu, a nie wizualnie wierne treści obrazu. Ilustruje to ograniczenie metryki CIDEr, premiującej istotność semantyczną na poziomie korpusu kosztem wierności wizualnej.

Drugi przypadek na Rysunku~\ref{fig:analiza_niski_cider} ilustruje \textbf{błąd pominięcia istotnego obiektu} na obrazie. Obraz przedstawia nietypową aktywność (snowkiting), a podpisy referencyjne identyfikują narciarza ("skier") oraz kluczowy obiekt ("parachute", "cables"). Wygenerowane podpisy wykazały ujednoliconą, generyczną strukturę, np. "a man riding [skis/a snowboard] on a snow covered slope". Wszystkie warianty uwagi poprawnie identyfikowały ogólny kontekst (śnieg, narciarz), ale pomijały ważny obiekt ("spadochron"). Stanowi to błąd semantyczny - \textbf{nadmiernej ogólnikowości}, gdzie złożona, atypowa scena jest redukowana do najbardziej prawdopodobnego, typowego scenariusza "zjazd narciarski". Wskazuje to na ograniczoną zdolność modeli do kompozycyjnego rozumienia sceny. Dodatkowo, część modeli głównie opartych na Densenet błędnie sklasyfikowała sprzęt jako "snowboard".

Wysokie podobieństwo wygenerowanych podpisów sugeruje konwergencję modeli do generycznego rozwiązania, silnie reprezentowanego w danych treningowych. Błędy te miały bezpośredni wpływ na metryki. W przypadku klasyfikacji sprzętu jako "snowboard" CIDEr obniżył się do $\approx 13,5$, w porównaniu do $\approx 35,5$ przy poprawnej identyfikacji ("skis"). Wzrost ten jest jednak warunkowany wyłącznie poprawną identyfikacją jednego lematu o wysokiej wadze TF-IDF. Nawet najwyżej ocenione podpisy ($CIDEr \approx 35,5$) pozostają semantycznie niekompletne, gdyż pomijają kluczowy obiekt ("parachute").

Analiza potwierdza tendencję badanych modeli do generowania podpisów generycznych, odzwierciedlających dominujące rozkłady statystyczne w danych, kosztem unikalnych detali i atypowych interakcji. Przedstawione przykłady demonstrują, że wysokie wartości automatycznych metryk ewaluacyjnych nie gwarantują semantycznej poprawności ani kompletności wygenerowanego opisu.

\input{rezultaty/uwaga/uwaga_podpisy_zestawienie_leksyka/uwaga_podpisy_zestawienie_leksyka}
Analiza jakościowa pozwala na identyfikację specyficznych wzorców błędów charakteryzujących poszczególne mechanizmy uwagi oraz zrozumienie ich wpływu na proces generowania podpisów.


\input{rezultaty/uwaga/mapy_ciepla/spatial_Regnet16_decoder_dim_512_fine_tune_encoder_false_fine_tune_embeddings_false-epoch-20/COCO_val2014_000000123415_spatial_Regnet16_decoder_dim_512_fine_tune_encoder_false_fine_tune_embeddings_false-epoch-20}
Uwaga przestrzenna koncentruje się na określonych regionach obrazu, determinując lokalizację istotnych cech wizualnych. W analizowanym przykładzie na Obrazie~\ref{fig:uwaga_podpisy_zestawienie_leksyka_a} model wygenerował podpis "A couple of elephants standing next to each other", podczas gdy podpisy referencyjne wskazywały na obecność dorosłego i małego słonia. Ta rozbieżność ilustruje ograniczenie uwagi przestrzennej. Mimo skuteczności w identyfikacji głównych obiektów wykazuje ona tendencję do fiksacji na elementach dominujących wizualnie i ignorowania mniej wyrazistych szczegółów. W rezultacie model pominął mniejszy obiekt, co skutkowało \textbf{błędem liczebności} oraz uniemożliwiło adekwatne opisanie relacji między obiektami np. rodzicielskiej, prowadząc do niepełnej \textbf{interpretacji kontekstu} sceny.
Mapa ciepła na Rysunku~\ref{fig:COCO_val2014_000000123415_spatial_Regnet16_decoder_dim_512_fine_tune_encoder_false_fine_tune_embeddings_false-epoch-20}

\input{rezultaty/uwaga/mapy_ciepla/att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33/COCO_val2014_000000123321_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}
Uwaga miękka przyjmuje podejście globalne, analizując obraz poprzez przypisanie wag wszystkim regionom. W analizowanym przykładzie na Obrazie~\ref{fig:uwaga_podpisy_zestawienie_leksyka_b} model wygenerował podpis " close up of a bowl of soup with broccoli", w kontraście do podpisu referencyjnego "A bowl of broccoli with sauce over it.". Ewidentnie uwaga miękka poprzez holistyczne ujęcie sceny redukuje ryzyko halucynacji obiektów. Głównym ograniczeniem jest jednak niska precyzja wynikająca z braku mechanizmu selekcji cech wizualnych, co w przykładzie doprowadziło do \textbf{błędów generalizacji} i użycia "food" zamiast konkretnego "broccoli". Obserwuje się również \textbf{błędy w kategoryzacji obiektów}, gdzie pomylono "bowl" z "plate". Pominięto także atrybut "sauce", co wskazuje na trudności w precyzyjnym określaniu \textbf{relacji między obiektami i interpretacji kontekstu}.
\ref{fig:COCO_val2014_000000123321_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}

\input{rezultaty/uwaga/mapy_ciepla/regnet_aoanet/COCO_val2014_000000001448_regnet_aoanet}
Uwaga własna analizuje zależności pomiędzy różnymi elementami w obrębie obrazu w celu zrozumienia jego struktury kompozycyjnej. W przypadku obrazu z żyrafą na Rysunku~\ref{fig:uwaga_podpisy_zestawienie_leksyka_c}  model wygenerował "A giraffe is standing in a grassy field". Podpisy referencyjne precyzowały jednak atrybuty "young giraffe" oraz akcję "bending down to graze. Model pominął atrybut wieku oraz popełnił \textbf{błąd relacyjny}, opisując statyczną postawę "standing" zamiast dynamicznej akcji. Mechanizm ten okazał się efektywny w modelowaniu zależności długodystansowych i poprawnie zinterpretował ogólny kontekst sceny. Wykazał jednakże trudności w precyzyjnej interpretacji złożonych lub specyficznych działań, generując 
\textbf{błędy relacji}.
\ref{fig:COCO_val2014_000000001448_regnet_aoanet}

\input{rezultaty/uwaga/mapy_ciepla/att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33/COCO_val2014_000000121031_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}
Uwaga adaptacyjna dynamicznie decyduje pomiędzy wykorzystaniem informacji wizualnych a kontekstem językowym podczas generowania kolejnych słów. W analizowanym przykładzie na Rysunku~\ref{fig:uwaga_podpisy_zestawienie_leksyka_d} wygenerowano podpis "A man riding a horse through a river". Odbiega to od informacji w podpisach referencyjnych, gdzie za istotnych uznano jeźdźców. Chociaż uwaga adaptacyjna sprzyja generowaniu płynnych językowo podpisów, jej wadą jest ryzyko nadmiernego polegania na modelu językowym i ignorowania sygnału wizualnego. W przykładzie model drastycznie zaniżył liczbę obiektów (\textbf{błąd liczebności}) i nie zidentyfikował akcji grupowej (\textbf{błąd relacji obiektów}). \textbf{Halucynacja obiektów} wystąpiła we frazie "next to a horse", co dodatkowo wskazuje na znaczące zaburzenie równowagi między modalnością wizualną a językową.
\ref{fig:COCO_val2014_000000121031_att2all_Resnet152_decoder_dim_512_fine_tune_encoder_true_fine_false_embeddings_true-epoch-33}

\input{rezultaty/uwaga/porownanie_z_klasycznym/porownanie_z_klasycznym}
Analiza porównawcza wskazuje na fundamentalne różnice w typologii błędów generowanych przez klasyczne modele koder-dekoder oraz z uwagą.

W podpisach dla Obrazu~\ref{fig:porownanie_z_klasycznym} zaobserwowano, że modele w podstawowej architekturze koder-dekoder wykazują znacznie większą podatność na błędy w interpretacji sceny. Zarówno w wariancie z fuzją jak i wstrzykiwaniem wstępnym wystąpiły \textbf{błędy faktograficzne}, polegające na \textbf{pominięciu istotnych obiektów} "park" i "grass" oraz \textbf{nieprawidłowym określeniu liczebności} osób. Metoda z wstrzykiwaniem wstępnym wykazała szczególnie niską skuteczność, generując podpis obarczony \textbf{błędami płynności językowej} oraz \textbf{spójności semantycznej}. Wystąpiły powtórzenia "man a and man a" oraz \textbf{błędy gramatyczne} w użyciu przedimków i spójników, które czynią podpis nieczytelnym. Podpis ten zawierał również \textbf{błędy relacyjne}, nie określając interakcji między człowiekiem, a latawcem, ani ich relacji ze środowiskiem.

Modele wyposażone w mechanizmy uwagi zademonstrowały wyższą precyzję w zakresie detekcji i opisu elementów sceny. W analizowanych wariantach nie zaobserwowano krytycznych \textbf{błędów faktograficznych} dotyczących obecności i liczebności kluczowych obiektów. Świadczy to o przewadze metod wykorzystujących uwagę w zadaniach wymagających dokładnej identyfikacji i kwantyfikacji obiektów oraz modelowania ich wzajemnych interakcji.

Należy jednak zaznaczyć, że zastosowanie mechanizmu uwagi nie eliminuje wszystkich kategorii błędów. Warianty z uwagą przestrzenną i adaptacyjną, mimo poprawnej identyfikacji kluczowych obiektów, dokonały błędnej kategoryzacji tła sceny, używając leksemu "field" zamiast "park". Sugeruje to, że nawet przy poprawnej analizie detali modele te mogą mieć trudności z adekwatną oceną globalnego kontekstu wizualnego. Warianty z uwagą miękką oraz własną wygenerowały podpisy pozbawione tego błędu w analizowanym przypadku.

